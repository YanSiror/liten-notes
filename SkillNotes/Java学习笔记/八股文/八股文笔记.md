





---

基础篇

---

# 1 List

## 1.1 ArrayList

### 1) 扩容机制

- `ArrayList()` 会使用长度为零的数组
- `ArrayList(int initialCapacity) `会使用指定容量的数组
- `public ArrayList(Collection<? extends E> c)` 会使用 c 的大小作为数组容量 `add(Object o)` 首次扩容为10，再次扩容为上次容量的1.5倍
- `addAll(Collectior,c)` 没有元素时，扩容为 `Math.max(10,实际元素个数)`，有元素时为 `Math.max(原容量1.5倍,实际元素个数)`
- JDK1.7 的时候是初始化就创建一个容量为 10 的数组; JDK1.8 后是初始化先创建一个空数组，第一次add时才扩容为10



### 2) FailSafe 和 FailFast

#### a. fail-fast（快速失败）机制

ex: `ArrayList`

- 指的是当遍历集合的过程中，如果集合的结构发生了改变，例如进行了put操作或是扩容操作，那么程序就会抛出Concurrent Modification Exception。java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。



#### b. fail-safe（安全失败）机制

ex: **CopyOnWriterArrayList**

- 是指任何对集合结构的修改都会在一个复制的集合上进行修改，因此不会抛出ConcurrentModificationException。java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。但是fail-safe机制有两个问题：

  - 需要复制集合，产生大量的无效对象，开销大

  - 无法保证读取的数据是目前原始数据结构中的数据，因为复制操作执行后，集合可能会发生改变



### 3) ArrayList vs LinkedList

- **ArrayList**
  - 基于数组，需要连续内存
  - 随机访问快（指根据下标访问)
  
  - 尾部插入、删除性能可以，其它部分插入、删除都会移动数据，因此性能会低可以利用cpu缓存，局部性原理
  
- **LinkedList**

  - 基于双向链表，无需连续内存
  - 随机访问慢（要沿着链表遍历)③头尾插入删除性能高
  - 占用内存多



# 1 HashMap

## 1.1 存储结构

### 1) HashMap 的底层数据结构是什么?

- JDK 1.7

  - **"数组+链表"**	

    数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的。

- JDK 1.8

  - **"数组+ 链表|红黑树"**	

    当链表过长，则会严重影响 HashMap 的性能，红黑树搜索时间复杂度是 O(logn)，而链表是糟糕的 O(n)。因此，JDK1.8 对数据结构做了进一步的优化，引入了红黑树，链表和红黑树在达到一定条件会进行转换：

    - 当链表长度超过 8 且数据总量超过 64 才会转红黑树。
    - 将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树，以减少搜索时间。



### 2) 为什么在解决 hash 冲突的时候，不直接用红黑树？而选择先用链表，再转红黑树?

因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于 8 个的时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于 8 个的时候， 红黑树搜索时间复杂度是 $O(log_2 n)$，而链表是 $O(n)$，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了。

因此，如果一开始就用红黑树结构，元素少，新增效率又比较慢，无疑这是浪费性能的。



### 3) 不用红黑树，用二叉查找树可以么?

可以。但是二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。



### 4) 为什么链表改为红黑树的阈值是 8?

理想情况下使用随机的哈希码，容器中节点分布在 hash 桶中的频率遵循 **泊松分布** ，按照泊松分布的计算公式计算出了桶中元素个数和概率的对照表，可以看到链表中元素个数为 8 时的概率已经非常小，再多的就更少了，所以原作者在选择链表元素个数时选择了 8，是根据概率统计而选择的。



### 5) HashMap 的加载因子是多少? 为什么是 0.75?

0.75 是在在空间占用与查询时间之间取得较好的权衡, 大于这个值，空间节省了，但链表就会比较长影响性能; 小于这个值,冲突减少了，但扩容就会更频繁,空间占用多。



## 1.2 索引计算(Hash 值)

### 1) HashMap 中 key 的存储索引是怎么计算的？

1. 根据 Key 值计算 hashcode 的值 (ASCII a - 97)
2. 根据 hashcode 计算出 hash 值 (hash = )
3. 最后通 过 `hash &（length-1）| hash % length` 计算得到存储的位置



### 2) JDK1.8 为什么要 hashcode 异或其右移十六位的值？

> 为什么要二次 hash?
>
> ​	综合高位数据, 让哈希分布更为均匀。

因为在JDK 1.7 中扰动了 4 次，计算 hash 值的性能会稍差一点点。 从速度、功效、质量来考虑，JDK1.8 优化了高位运算的算法，通过hashCode()的高16位异或低16位实现：(h = k.hashCode()) ^ (h >>> 16)。这么做可以在数组 table 的 length 比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。



### 3) 为什么 hash 值要与 length-1 相与, 而不采用取模？

- 把 hash 值对数组长度取模运算，模运算的消耗很大，没有位运算快。
- 当 length 总是 2 的n次方时，`h & (length-1)` 运算等价于对 length 取模，也就是 `h % length`，但是 & 比 % 具有更高的效率。
- 扩容时 hash & oldCap == 0的元素留在原来位置，否则新位置 = 旧位置 + oldCap(旧容量)。



### 4) HashMap数组的长度为什么是 2 的幂次方？

综合考虑的结果,计算索引时，如果是2的n次幂可以使用位与运算代替取模，效率更高



### 5) Hash 数组扩充

HashMap 构造函数允许用户传入的容量不是 2 的 n 次方，因为它可以自动地将传入的容量转换为 2 的 n 次方。会取大于或等于这个数的 且最近的2次幂作为 table 数组的初始容量，使用`tableSizeFor(int)`方法，如 tableSizeFor(10) = 16（2 的 4 次幂），tableSizeFor(20) = 32（2 的 5 次幂），也就是说 table 数组的长度总是 2 的次幂。JDK1.8 源码如下：

```java
/*
解释：位或( | )
int n = cap - 1; 让cap-1再赋值给n的目的是另找到的目标值大于或等于原值。例如二进制1000，十进制数值为8。如果不对它减1而直接操作，将得到答案10000，即16。显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。
*/
static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```



## 1.3 put 方法

### 1) HashMap 的put方法流程？

简要流程如下：

1. 首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标；
2. 如果数组是空的，则调用 resize 进行初始化；
3. 如果没有哈希冲突直接放在对应的数组下标里；
4. 如果冲突了，且 key 已经存在，就覆盖掉 value；
5. 如果冲突后，发现该节点是红黑树，就将这个节点挂在树上；
6. 如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；否则，链表插入键值对，若 key 存在，就覆盖掉 value。



### 2) JDK1.7 和 JDK1.8 的 put 方法区别是什么？

区别在两处：

- 解决哈希冲突时，JDK1.7 只使用链表，JDK1.8 使用链表+红黑树，当满足一定条件，链表会转换为红黑树。

- 链表插入元素时，JDK1.7 使用头插法插入元素，在多线程的环境下有可能导致环形链表的出现，扩容的时候会导致死循环。因此，JDK1.8 使用尾插法插入元素，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了，但 JDK1.8 的 HashMap 仍然是线程不安全的。



### 3) 多线程下, HashMap 有哪些问题?

- **扩容死链**
  - JDK1.7 使用头插法插入元素，在多线程的环境下有可能导致环形链表的出现，扩容的时候会导致死循环。
- **数据错乱**
  - 线程A和线程B同时操作一个 Hash 表时会造成重复写的问题, 也即 A | B线程会覆盖 B|A 所写的数据。



##  1.4 扩容机制

### 1) HashMap 的扩容方式?

- JDK 1.7 
  - 使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。
- JDK 1.8
  - resize 之后，元素的位置在原来的位置，或者原来的位置 +oldCap (原来哈希表的长度）。不需要像 JDK1.7 的实现那样重新计算hash ，只需要看看原来的 hash 值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成 `原索引 + oldCap`。这个设计非常的巧妙，省去了重新计算 hash 值的时间。
  - 使用尾插法消除 1.7 带来的死链问题。



##  1.5 补充

### 1) 还知道哪些hash算法？

Hash函数是指把一个大范围映射到一个小范围，目的往往是为了节省空间，使得数据容易保存。 比较出名的有MurmurHash、MD4、MD5等等。



### 2) key 可以为 Null 吗?

可以，key 为 Null 的时候，hash算法最后的值以0来计算，也就是放在数组的第一个位置。



### 3) 一般用什么作为 HashMap 的 key?

一般用Integer、String 这种不可变类当 HashMap 当 key，而且 String 最为常用。

- 因为字符串是不可变的，所以在它创建的时候 hashcode 就被缓存了，不需要重新计算。这就是 HashMap 中的键往往都使用字符串的原因。
- 因为获取对象的时候要用到 equals() 和 hashCode() 方法，那么键对象正确的重写这两个方法是非常重要的,这些类已经很规范的重写了 hashCode() 以及 equals() 方法。(`如果以对象为 HashMap 的 key 该对象必须实现 equals() 和 hashCode() 方法`)



### 4) 用可变类当 HashMap 的 key 有什么问题?

hashcode 可能发生改变，导致 put 进去的值，无法 get 出。如下所示

```text
    HashMap<List<String>, Object> changeMap = new HashMap<>();
    List<String> list = new ArrayList<>();
    list.add("hello");
    Object objectValue = new Object();
    changeMap.put(list, objectValue);
    System.out.println(changeMap.get(list));
    list.add("hello world");//hashcode发生了改变
    System.out.println(changeMap.get(list));
```

输出值如下

```text
    java.lang.Object@74a14482
    null
```



# 2 单例模式

