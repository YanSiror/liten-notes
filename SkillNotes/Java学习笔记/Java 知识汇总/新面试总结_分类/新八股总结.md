##  Redis

> Redis 是基于键值对的非关系型数据库。Redis 拥有 string、hash、list、set、zset 等多种数据结构, redis 具有惊人的读写性能, 其优秀的持久化机制是的它在断电和机械故障时也不会发生数据丢失, 可以用于热点数据存放, 还提供了键过期、发布订阅、食物、流水线、LUA脚本等多个高级功能。
>
> **适合**
>
> `缓存` `分布式锁`
>
> 1. 计数器和排行榜：Redis提供了原子递增和递减操作，可以方便地实现计数器和排行榜功能。比如统计网站的页面访问量、点赞数、热门文章等。
> 2. 会话管理：可以将用户的会话信息存储在Redis中，实现分布式的会话管理。这样可以避免使用传统的基于Cookie或Session的会话管理方式带来的状态维护和扩展性的问题。
> 3. 消息队列：Redis提供了发布-订阅机制和列表数据结构，可以用作简单的消息队列。可以将消息发布到Redis中，然后订阅者可以从Redis中获取消息进行处理。
>
> **不适合**
>
> `数据实时性要求高` `数据量小` 
>
> 1. 大规模数据存储：由于Redis的数据存储在内存中，因此对于大规模数据的存储并不适合。如果需要存储大量数据，可能需要考虑其他存储引擎或分布式数据库。
> 2. 复杂查询：Redis 的查询功能相对简单，只支持基于键的查询。如果需要进行复杂的查询操作，可能需要借助其他数据库来完成。
> 3. 持久化要求高：Redis 提供了持久化功能，但相比于传统的关系型数据库，其持久化能力较弱。如果对数据的持久性要求非常高，可能需要考虑其他数据库解决方案。

### 1 Redis 数据结构

- `string`: 最基本数据类型, 可以存放入二进制、序列化数据、JSON对象、图片等数据 

  - 语法:

    ```redis
    set key value   //存储
    	set username super     
    get key			//获取
    	get username
    del key 		//删除
    	del username
    ```

  - 底层实现: `SDS(Simple Dynamic String) - 动态字符串 `

    可修改字符串, 采用预分配冗余空间的方式减少内存的频繁分配。与Java中的ArrayList比较类似, 实质上也是在空间不足时触发扩容机制, 如果 SDS 值大小< 1M , 则增加一倍；反之如果>1M , 则当前空间加1M作为新的空间。

    <img src="imgs/654033f8e1b493432bee3543d2af8dbc-16932970960013.png" alt="在这里插入图片描述" style="zoom:50%;" />

    ```java
    struct sdshdr{
    	//记录buf数组中已使用字节的数量//等于SDS保存字符串的长度4byte
        int len;
    	//记录 buf数组中未使用字节的数量 4 byte
        int free;
    	//字节数组，用于保存字符串字节\0结尾的字符串占用了1byte
        char buf[];
    }
    ```
  
- `list`:   字符串列表, 按照插入的顺序排序, 元素可以重复, 底层由 `链表` 实现。

  - 语法:

    ```redis
    lpush key value			//元素加入左列表
    	lpush username super
    rpush key value			//元素加入右列表
    	rpush username super
    lrange key start end		//范围获取
    	lrange person 0 -1			//获取全部
    lpop person				//删除列表最左边的元素，并将元素返回
    	lpop person
    rpop key				//删除列表最右边的元素，并将元素返回
    	rpop person
    ```

  - 底层实现: `ZIPList| LinkedList(双向链表)` 

    当元素字符串的长度小于64字节而且元素个数小于512时，采用 zipList；否则采用linkedList；

    - `ZIPList - 压缩列表`: 由连续内存块组成且用于存储小型有序集合或哈希集合的数据结构。主要参数包括: 整个列表占用字节数、偏移量、元素个数、内容列表、结束标志。 **优点: 节省空间**

      <img src="imgs/8b092e16d4504bb4a5c42b8fe2c04e46tplv-k3u1fbpfcp-zoom-in-crop-mark1512000-16932970979244.jpg" alt="image.png" style="zoom:50%;" />

      ```c++
      struct ziplist<T> {
          int32 zlbytes; // 整个压缩列表占用字节数
          int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点
          int16 zllength; // 元素个数
          T[] entries; // 元素内容列表，挨个挨个紧凑存储
          int8 zlend; // 标志压缩列表的结束，值恒为 0xFF
      }
      ```

- `hash`:   string 类型 field 和 value 的集合, 适合存放对象

  - 语法:

    ```redis
    hset key field value 		//存储
    	hset person username super
    hget person username		//获取
    	hget person username
    hgetall key					//获取所有的key : value
    	hgetall person	
    hdel key field				//删除
    	hdel person username
    ```

  - 底层实现: `ZIPList | HashTable` 

    当hash对象的键与值的长度都小于64字节时而且键值对的个数小于512个，采用zipList，其它情况，采用hashTable

    - `ZIPLIST: 参考上述`

    - `HashTable - 哈希表`

      ① 数组 + 链表  ②数组+红黑树(树化方便查找)

      <img src="imgs/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkZmdlZ2VmZGc=,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述" style="zoom:50%;" />

      根据Key value而直接进行访问的数据结构。它通过**把关键码值映射到表中一个位置来访问记录**（类似索引），以加快查找的速度。这个映射函数叫做**散列函数**，存放记录的数组叫做散列表。

- `set`:    无序不重复的集合

  - 语法

    ```redis
    sadd key value		//存储
    	sadd person a
    smembers key 		/获取所有
    	smembers person
    srem key value		//删除元素
    	srem person a	
    ```

    

  - 底层实现: `INTSet | HashTable`

    当保存的元素都是整形数字，而且元素个数小于配置范围的时候，则使用intset，否则使用hash表。

    - `INTSet - 整数集合`

      可变长度的整型数组 - 基于整数数组来实现，并且具备长度可变、有序等特征, 包含: 编码方式、长度、内容等主要属性(可以选择不同位数的整数存储)。

      <img src="imgs/723e89ef8e9542c6a098ea7460e91877.png" alt="在这里插入图片描述" style="zoom:67%;" />

      ```c
      typedef struct intset {
          uint32_t encoding; /* 编码方式，支持存放16位、32位、64位整数 */
          uint32_t length;  /* 元素个数 */
          int8_t contents[];  /* 整数数组，保存集合数据 */
      } intset;
      ```

- `zset`:   与 set 一样都是 String 类型元素的集合, 且不允许重复, 但 zset 每个元素都会关联一个分数, Redis通过分数来为集合汇总的成员进行从小到大的排序。

  - 语法

    ```redis
    zadd key score value		//存储
    	zadd person 30 math
    zrange key start end		//获取
    	zrange person 0 -1   	 //获取所有
    zrem key value				//删除
    	zren person math	   
    ```

  - 底层实现: `ZIPList| SKIPList`

    - `ZIPList: 参考上述`

    - `SKIPList`: 

      一种有序的数据结构，通过在每个节点维护多个指针，从而达到快速访问的目的。 **优点: 实现简单、内存消耗少** **缺点: 不适合范围查询**

      <img src="imgs/9c092a10e6fa4da0ae3bd2ea036fa7a7tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.jpg" alt="image.png" style="zoom:50%;" />

      跳跃表 - 跳跃表节点结构定义

      ```c
      typedef struct zskiplist{
          // 表头节点和表尾节点
          struct zskiplist *header,*tail;
          // 表节点个数
          unsigned long length;
          // 表节点最大层数
          int level;
      }zskiplist；
      ```

      ```c
      typedef struct zskiplistNode{
           // 层
          struct zskiplistLevel{
              // 前进指针
              struct zskiplistNode *forward;
              // 跨度
              unsigned int span;
              
          }level[];
          // 后退指针
          struct zskiplistNode *backward;
          // 分值
          double score;
          // 成员对象
          robj *robj;
      }zskiplistNode;
      ```

- 四种特殊数据类型: 1）bitmap 2）hyperloglog 3）geo 4）stream

**zset 与 set 的区别**

- set -  *无序*   zset - *有序*

- 底层

  set   *INTSet*  *HashTable*
  
  zset  *ziplist*  *skiplist*



### 2 Key 过期策略

- `定期删除 ` - `过期 Key 保存在字典, 定期随机抽取20个Key, 删除其中过期的, 如果比例超过1/4, 重复删除步骤。`

  redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定期遍历这个字典来删除到期的 key。

  Redis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。

  1.从过期字典中随机 20 个 key；

  2.删除这 20 个 key 中已经过期的 key；

  3.如果过期的 key 比率超过 1/4，那就重复步骤 1；

  redis默认是每隔 100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载。

- `惰性删除` - `访问时发现 Key 过期, 直接删除不返回任何值`

  在客户端访问这个key的时候，redis对key的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。

  定期删除可能会导致很多过期key到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，即当你主动去查过期的key时,如果发现key过期了,就立即进行删除,不返回任何东西。



### 3 内存淘汰策略

> 数据的淘汰策略: 当Redis中的内存不够用时，此时在向Redis中添加新的key，那么Redis就会按照某一种规则将内存中的数据删除掉，这种数据的删除规则被称之为内存的淘汰策略。
>
> LFU: 最近最少使用(频次)   LRU: 最近最久未用(使用记录: 最近使用的放在前边（最左边），最近没用的放到后边（最右边） 

- noeviction:      不淘汰任何key，但是内存满时不允许写入新数据，默认策略。

- volatile-TTL:    对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰。

- allkeys -RANDOM: 对全体key，随机进行淘汰。
- volatile-RANDOM: 对设置了TTL的key，随机进行淘汰。
- alkeys  -LRU:    对全体key，基于LRU算法进行淘汰
- volatile-LRU:    对设置了TTL的key，基于LRU算法进行淘汰

- allkeys -LFU:    对全体key，基于LFU算法进行淘汰

- volatile-LFU:    对设置了TTL的key，基于LFU算法进行淘汰



### 4 主从同步机制 | 持久化机制

- **全量同步 - RDB(快照)**

  一般发生在第一次连接时, 原理为将当前数据写入到 RDB文件 后发送给从机读取到丛机的内存中。

  优点: *恢复速度快* *占用大小更小* 

  缺点: *最后一次保存后宕机丢失数据* *实时性差*

  触发机制: *手动触发* 使用 SAVE(同步) 或 BGSAVE(异步) 命令; 

  ​		*自动触发* 配置 save 参数, 如设置在900秒内至少有1个键被更改时生成快照  `save time(s) key_modify_times`

- **增量同步 - AOF(命令)**

  一般发生在第一次之后的链接时, 主机同步期间发生的数据变化会以命令的形式写入缓存中, 当校验到正确的从机ID时获取从机的偏移量,然后从偏移量记录的命令开始将未同步的数据操作命令发送给从机执行, 进而完成数据同步。

  优点: *可读性好* *安全性高* : Redis意外崩溃或断电，也可以通过重新执行AOF文件中的命令来恢复数据

  缺点: *占用空间大* *恢复时间长* *额外的写入IO开销*

  触发机制: *always - 默认*:  立即追加;  *everysec:* 每秒钟将写命令追加到AOF文件中，可以通过配置appendfsync参数进行设置; *no* : 从不同步



### 5 Redis 分布式锁

- **SETNX（SET if Not eXists）**

  通过在 Redis 中设置一个特定的键值对来表示锁的状态。使用 SETNX 指令可以确保只有一个客户端能够成功设置该键，其他客户端会得到失败的返回值。通过设置适当的超时时间，可以避免锁被永久占用。  *无法指定过期时间 - 可通过LUA脚本设置*

  如果返回值为 1，则表示获取到了锁；如果返回值为 0，则表示锁已经被其他客户端占用。

  ```redis
  SETNX lock_key 1
  ```

- **SET + NX + EX|PX**

  使用 SET + NX + EX 指令结合 EX（过期时间）, 但在设置锁时，同时设置一个适当的过期时间。这样即使锁没有被主动释放，也能保证一段时间后自动释放，避免死锁。

  下述代码中，锁的过期时间被设置为 10 秒，10 秒后锁会自动释放。

  ```cmd
  SET lock_key 1 EX 10 NX
  ```

- **其它**

  `Redlock` `Redisson` `Lua 脚本`

- **问题**

  - 确保锁的唯一性：使用一个全局唯一的键来表示锁，避免不同客户端之间的冲突。
  - 避免死锁：设置适当的超时时间或过期时间，确保即使锁没有被主动释放，也能够自动释放。
  - 处理异常情况：在获取锁和释放锁的过程中，需要处理异常情况，确保锁的正常使用。
  - 考虑锁的可重入性：根据具体需求，决定是否支持同一个客户端多次获取同一把锁。
  
- **集群分布式锁**

  1. 定义一个全局唯一的键名作为锁的标识，例如`my_lock`。

  2. 当需要获取锁时，使用`SET`命令尝试在Redis集群的大多数节点上设置键名为 `my_lock` 的值，并设置一个适当的超时时间和 `NX`

     （只在键不存在时设置）选项。

     - 如果成功在大多数节点上设置了锁，则表示成功获取到锁，可以执行需要加锁的操作。
     - 如果设置锁的成功节点数小于大多数节点的数量，则表示没有成功获取到锁，需要等待一段时间后重新尝试获取锁。

  3. 在执行完需要加锁的操作后，使用`DEL`命令在Redis集群的所有节点上删除键名为`my_lock`的值，释放锁。




### 6 LUA 脚本 | SETNX PX EX

- **LUA**

  Lua是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放。其设计目的就是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。

  `C语言编写 `的脚本语言, 在 Redis 默认 `支持原子操作` , 即所有的操作要么都完成, 要么都不完成。

  \- EVAL
  \- EVALSHA
  \- SCRIPT LOAD - SCRIPT EXISTS
  \- SCRIPT FLUSH
  \- SCRIPT KILL

  ```c
  // 释放锁时，先比较锁对应的 value 值是否相等，避免锁的误释放
  if redis.call("get",KEYS[1]) == ARGV[1] then
      return redis.call("del",KEYS[1])
  else
      return 0
  end
  ```

- **NX PX EX**

  3者都是SET命令的参数, 用于设置键的值和过期时间。

  - NX(if Not eXists)  

    表示只有在键不存在时才设置键的值。如果键已经存在，则设置操作会被忽略，不会对键进行任何修改。

  - EX(Expire) | PX

    过期时间 **秒** | 过期时间 **毫秒**

  Example: 如果 lock_key 键不存在，则设置它的值为1，同时设置过期时间为`10`秒。如果`lock_key`键已经存在，则不做任何操作，同时返回`NULL`表示设置失败。

  ```cmd
  SET lock_key 1 EX 10 NX
  ```

  

### 6 数据库与缓存双写一致性

`更新 | 写入才存在`  `读取时先更数据库, 再删缓存`

四种同步策略: 

- 先更新数据库再更新缓存

  多线程并发会出现数据不一致情况

- 先更缓存再更数据库

  每次数据变化可以及时更新缓存, 但是消耗大、性能不高。

- **先删除缓存再更新数据库 + 延时双删**

  也可能导致数据不一致情况(Redis删除两次 - 中间间隔一定时间)

  ```java
  //一致性策略: 先删缓存, 再更新数据库 + 延时双删
  redisUtils.delete("staffCache::" + object.getId());
  //更新数据库
  staffService.save(object);
  //延时
  Thread.sleep(200);
  redisUtils.delete("staffCache::" + object.getId());
  ```

- 先更新数据库再删除缓存

  也可能导致数据不一致情况, 最优方案: 出错时可以使用重试机制来异步重新处理。



### 7 缓存穿透、击穿、雪崩的区别

- **缓存穿透**  *访问空*

  客户端访问不存在的数据, 请求直接发送到数据库, 导致数据库负荷过大宕机。

  解决方式: 缓存 `NULL` 值, 直接返回 `NULL`; 使用布隆过滤器, 访问缓存时先经过过滤器拦截, 如果请求的数据不存在直接返回空。

- **缓存击穿**  *单个KEY*

  某个热点数据在其过期的瞬间, 访问量特别大, 导致大量请求发送到数据库造成宕机。 

  解决方式: `互斥锁` `永不过期, 不设置过期时间` `随机逼退, 查询失败随机睡眠一段时间` 

- **缓存雪崩**  *大量KEY*

  a. 设置相同过期时间, 大量数据同时到期;    *大量KEY*

  ​	解决方式: `设置随机过期时间`  `永不过期` `互斥锁` 

  b. 某个 `Redis` 节点故障导致服务不可用, 所有的数据请求直达数据库造成数据库宕机。
  
  ​	解决方式: `降级和熔断措施` `主从|集群保证高可用`
  
  *降级: 降级指系统将某些业务或者接口的功能降低，可以是只提供部分功能，也可以是完全停掉所有功能。降级的核心思想就是丢车保帅，优先保证核心业务。*



### 8 Redis 主从复制 | 集群 | 哨兵 | 选举

- **主从复制**

  数据写放在主服务器上, 从服务器负责同步数据。缺点: 当主服务器挂掉, 不能切换到从服务器上。优点:一定程度上可以分担主服务器读的压力。

- **哨兵模式**

  构建多个哨兵节点监视主服务器, 当主服务器挂掉则自动将对应的从服务器设为主服务器。

  优点: 自动切换、可用性高。  缺点: 主从服务器存储数据一致, 内存可用性较差, 还需要维护哨兵系统比较麻烦。

- **集群模式**

  采用无中心节点的方式实现, 多个服务器相连, 主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。Redis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 0～16383 个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。

  优点: 可用性更高
  
- **哨兵模式的选举(主节点挂掉)**

  从节点和主节点通信失败, 所有从节点参与竞争选举。向其它所有节点广播FAILOVER_AUTH_REQUEST, 其它没挂的主节点收到广播给第一个发送广播的从节点回复FAILOVER_AUTH_ACK。从节点收到确认之后采用过半机制统计, 收到超过一半的主节点发送确认则成为新的主节点。  *gossip 通信协议* *保证了最好的节点可以收到信息*



### 9 Redis 的单线程架构 | 持久化 | 主从复制策略?

- **单线程架构**

  Redis 采用了 单线程 + IO 复用技术, 这里的单线程指Redis读写操作和网络IO使用一个线程完成, 其他操作如持久化、异步删除等依赖于其他线程执行。

- **持久化 | 主从复制策略**

  - **RDB** redis database 快照机制

    `将某一时刻的内存快照数据以二进制方式写入磁盘` Redis 要求在指定的时间隔内将内存中数据快照写入磁盘, 文件名为 dump.rdb, 适合大规模数据恢复, 对数据库完整性和读写一致性要求不是很高, 一定时间间隔备份一次。出现意外故障时, 数据无法恢复。

  - **AOF** append only file 文件追加机制

    `将所有的操作命令按顺序记录下来，追加到特殊的文件中` 以日志的形式记录每次写操作, 只允许追加而不允许修改文件, Redis 启动都会读取该文件, 从头到尾执行一次来恢复数据。但对磁盘IO较多, 性能比较差, 但安全性高, 一般也推荐使用 AOF 格式。
    
  - **混合机制**
  
    二者混合



### 10 布隆过滤器

**位数组（二进制数组）+ 多个无偏hash函数**

布隆过滤器提供了两个参数，分别是预计加入元素的大小n，运行的错误率f。布隆过滤器中有算法根据这两个参数会计算出二进制数组的大小l，以及无偏hash函数的个数k。

- 错误率越低，位数组越长，控件占用较大
- 错误率越低，无偏hash函数越多，计算耗时较长

`添加`

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

`查询`

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。



### 11 脑裂

> 概念: Redis 主从集群(哨兵)中出现两个主节点的情况。
>
> 原因: 当前主库突然出现暂时性 “失联”，而并不是真的发生了故障，此时监听的哨兵会自动启动主从切换机制。当这个原始的主库从假故障中恢复后，又开始处理请求，但是哨兵已经选出了新的主库，这样一来，旧的主库和新主库就会同时存在，这就是**脑裂现象**。

- **影响**

  客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据, 脑裂会进一步导致数据丢失。等到哨兵让原主库和新主库做全量同步后,原主库需要清空本地的数据后加载新主库发送的RDB 文件,原主库在切换期间保存的数据就丢失了。

- **解决办法**

  `min-slaves-to-write 3`  *最小从服务器数* 主库最少得有 N 个健康的从库存活才能执行写命令
  `min-slaves-max-lag 10`  *从连接的最大延迟时间*   从库和主库进行数据复制时的 ACK 消息延迟的最大时间

  解释: 要求至少3个slave节点，且数据复制和同步的延迟不能超过10秒，否则的话master就会拒绝写请求，配置了这两个参数之后，如果发生集群脑裂，原先的master节点接收到客户端的写入请求会拒绝，就可以减少数据同步之后的数据丢失。  *防止原先的主库依旧接受请求导致的数据丢失情况*



### 12 Redis 为什么快 | 用单线程

- **为什么快** (10w读写/s)

  `基于内存(内存数据读写本身很快)` `单线程减少上下文切换，同时保证原子性` `IO多路复用` `高级数据结构（如 SDS、Hash以及跳表等）`

  Redis 快的原因在于, 其使用`单线程`避免了线程切换和锁竞争带来的消耗; 将操作放在 `内存中执行` ; 采用 `IO多路复用`, 实现在网络IO中处理大量并发请求, 实现高吞吐率。

- **为何使用单线程**
  因为 Redis 是基于内存的操作，CPU 不会成为 Redis 的瓶颈，而最有可能是机器内存的大小或者网络带宽, 既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。



### 13 Redis 库 | 槽 | 分片

Redis 默认支持 `16 `个库, 共有`16384`个槽

- **分片**

  Redis 使用分片（sharding）来实现数据的水平分布，将数据分散存储在多个节点上。每个节点负责管理一部分数据。 *分片在Redis里面就是分槽*

- **槽**

  槽是 Redis 中**数据分区的最小单位**，一个 Redis 集群被分为多个槽，每个槽可以存储一个键值对。采用虚拟哈希槽分区，所有的键根据哈希函数映射到 0 ~ 16383 整数槽内，每个key通过CRC16校验后对16384取模来决定放置哪个槽(Slot)，每一个节点负责维护一部分槽以及槽所映射的键值数据。



### 14 Redis 内存碎片

**原因**

- 1、Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。

- 2、频繁修改 Redis 中的数据也会产生内存碎片。

  当 Redis 中的某个数据删除时，Redis 通常不会轻易释放内存给操作系统。

**清理**

Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。

直接通过 `config set` 命令将 `activedefrag` 配置项设置为 `yes` 即可。

```bash
config set activedefrag yes
```

具体什么时候清理需要通过下面两个参数控制：

```bash
# 内存碎片占用空间达到 500mb 的时候开始清理
config set active-defrag-ignore-bytes 500mb
# 内存碎片率大于 1.5 的时候开始清理
config set active-defrag-threshold-lower 50
```

通过 Redis 自动内存碎片清理机制可能会对 Redis 的性能产生影响，我们可以通过下面两个参数来减少对 Redis 性能的影响：

```bash
# 内存碎片清理所占用 CPU 时间的比例不低于 20%
config set active-defrag-cycle-min 20
# 内存碎片清理所占用 CPU 时间的比例不高于 50%
config set active-defrag-cycle-max 50
```

另外，重启节点可以做到内存碎片重新整理。如果你采用的是高可用架构的 Redis 集群的话，你可以将碎片率过高的主节点转换为从节点，以便进行安全重启



### 15 一致性哈希

> **概念**: 将哈希值域组成一个虚拟的圆环，然后将数据和服务节点映射到这个圆环上。存储时依据哈希值映射到圆环上, 然后顺时针查找第一个节点，并将数据存储在这个节点上。如果在这个节点发生故障时，可以通过顺时针查找的方式找到下一个节点并将数据存储在该节点上。因此，一致性哈希算法在节点变更时，只需要移动少量的数据即可完成数据迁移，从而大大减小了系统的负载和影响。是一种用于分布式系统中数据分片的算法。它的主要目的是为了在系统扩容和缩容时最小化缓存数据的迁移量，从而减小系统的负载和影响，保证系统的高可用性。

**问题**

- **数据倾斜**

  由于哈希计算的随机性，导致一致性哈希算法存在一个致命问题：数据倾斜，，也就是说大多数访问请求都会集中少量几个节点的情况。特别是节点太少情况下，容易因为节点分布不均匀造成数据访问的冷热不均。

  `解决`: *虚拟节点机制* 对每一个物理服务节点映射多个虚拟节点，将这些虚拟节点计算哈希值并映射到哈希环上，当请求找到某个虚拟节点后，将被重新映射到具体的物理节点。 



### 16 Redis 设置过期时间 | 定时过期

**设置过期时间**

SET key value EXPIRE key time

`EXPIRE key seconds`　//将key的生存时间设置为 ttl 秒

`PEXPIRE key milliseconds`　//将key的生成时间设置为 ttl 毫秒

`EXPIREAT key timestamp`　//将key的过期时间设置为 timestamp 所代表的的秒数的时间戳

`PEXPIREAT key milliseconds-timestamp`　//将key的过期时间设置为 timestamp 所代表的的毫秒数的时间戳

1、2两种方式是设置一个过期的时间段，就是咱们处理验证码最常用的策略，设置三分钟或五分钟后失效，把分钟数转换成秒或毫秒存储到Redis中。
3、4两种方式是指定一个过期的时间 ，比如优惠券的过期时间是某年某月某日，只是单位不一样。

**定时过期**

1. 使用 Java 中的日历类(Calendar) | LocalDateTime包获取到定期时间相差的秒数, 然后使用 EXPIRE 命令即可
2. 使用 Java 包将定期时间转换为时间戳, 然后使用 Expireat | PExpireat 命令设置即可



### 17 Redis 限流

- **固定窗口**

  `setnx` 设置时间间隔 T, 在固定的时间间隔内使用 setnx 添加key, 同时设置过期时间为 T。 这时每次请求时通过访问 key 来计数, 如果达到了 MaxConnection 则拒绝。

- **滑动窗口**

  `zset` 每次请求设置不同value的值进入 zset, 对应value的score字段使用访问时间的时间戳表示(用于计算间隔时间内有多少请求), 如果达到了 MaxConnection 则拒绝。 *zrange*

  ```java
  public Response limitFlow(){
      Long currentTime = new Date().getTime();
      System.out.println(currentTime);
      if(redisTemplate.hasKey("limit")) {
          Integer count = redisTemplate.opsForZSet().rangeByScore("limit", currentTime -  intervalTime, currentTime).size();        // intervalTime是限流的时间 
          System.out.println(count);
          if (count != null && count > 5) {
              return Response.ok("每分钟最多只能访问5次");
          }
      }
      redisTemplate.opsForZSet().add("limit",UUID.randomUUID().toString(),currentTime);
      return Response.ok("访问成功");
  }
  ```

- **令牌桶**

  `list` 通过维护list, 往list内定时push固定的value(令牌), 每次获取令牌就是 pop 一个value出来, 这样在 pop 不为空则拿到令牌执行, pop = null 则拒绝。

  ```java
  // List 的 leftPop 输出令牌
  public Response limitFlow2(Long id){
      Object result = redisTemplate.opsForList().leftPop("limit_list");
      if(result == null){
          return Response.ok("当前令牌桶中无令牌");
      }
      return Response.ok(articleDescription2);
  }
  
  //依靠Java的定时任务，定时往List中rightPush令牌，当然令牌也需要唯一性，所以我这里还是用UUID进行了生成
  // 10S的速率往令牌桶中添加UUID，只为保证唯一性
  @Scheduled(fixedDelay = 10_000,initialDelay = 0)
  public void setIntervalTimeTask(){
      redisTemplate.opsForList().rightPush("limit_list",UUID.randomUUID().toString());
  }
  ```

  



## 计算机网络

### 1 OSI 七层模型 | TCP与UDP | 响应状态码

- OSI 模型

  <img src="imgs/v2-1578921092d775e024345fa8a531a85e_b.webp" alt="img" style="zoom: 67%;" />

  - 应用层: 提供用户与应用程序和网络之间的服务接口，完成用户希望在网络上完成的各种工作。

    `HTTP` `SMTP` `FTP` `DNS`

  - 表示层: 负责数据格式的转换，将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能处理的格式。

  - 会话层: 建立和管理应用程序之间的通信。 

  - 传输层: 监控数据传输服务的质量，保证报文的正确传输。  `报文`  `TCP | UDP`

  - 网络层: 通过路由选择算法，为报文通过通信子网选择最适当的路径。 `数据报` `IP | ICMP | ARP | RARP`

  - 数据链路层: 过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。 `帧` `MAC`

  - 物理层: 解决硬件通信的问题 `比特`

- **响应状态码**

  `200`  请求成功

  `400`  客户端请求报文中存在语法错误，服务器无法理解

  `401`  未验证, 需要进行身份验证

  `403`  服务器拒绝执行

  `404`  请求资源不存在
  
  `405`  方法不允许，服务器没有该方法
  
  `500`  服务器错误, 无法完成请求(参数错误、请求方式错误无法响应)



### 2 HTTP 请求的过程 | HTTP 与 HTTPS 的区别

- **流程**

  1. 浏览器根据域名解析IP地址(DNS 解析)
  2. 浏览器与服务器建立 TCP 链接(三次握手: 确保双方都同意链接, 防止失效的请求再次发送到服务器)
  3. 浏览器与服务器建立 HTTP 链接
  4. 服务器响应请求, 返回 Response
  5. 浏览器解析 Response 并请求资源
  6. 结束关闭 TCP 链接, 浏览器展示页面(四次挥手: 确保正确的关闭 TCP 链接, 保证数据完整性和可靠性)

- **HTTP 与 HTTPS 的区别**

  HTTP 与 HTTPS 都是位于应用层的数据传输协议, 它们最大的区别在于 HTTPS 对数据的安全性给予保障。

  - 安全性

    HTTP 明文传输未经过加密, 不需要使用证书; HTTPS 使用 SSL | TLS 协议进行加密, 通过证书授权来验证身份进而实现通信加密

  - 连接方式

    HTTP 是无状态协议, 服务端不保存请求信息; HTTPS 是基于安全连接的, 服务端会保存客户端的会话状态。



### 3 三次握手 | 四次挥手

- **三次握手**

  <img src="imgs/640.png" alt="图片" style="zoom:50%;" />

  客户端向服务端发送 SYN 包, 如果服务端同意返回 SYN+ACK 确认, 客户端收到后再发送 ACK , 服务端收到后即可建立连接。

  `举例`: A 与 B 隔着墙丢沙包, A说: "你可以听到我说话吗?"; B 说: "可以听到"; A 再说: "那我开始丢沙包了"

  - **问题**

    **1) 为什么不能两次握手?**

      `为了防止已经失效的请求再次请求服务器` - 客户端挂掉的请求再次发送(历史连接), 会导致服务端建立连接耗费资源。

       `为了确定双方都具有收发信息的能力`

    **2) 可以四次握手吗?**

    ​	理论上是可以的, 但是三次握手就可以确保双方都拥有收发信息的能力, 4次多余了一次做了无用功。

- **四次挥手**

  <img src="imgs/640-16922603973363.png" alt="图片" style="zoom:50%;" />

  已经传输数据完毕的客户端和服务端断开连接时, 客户端发送 FIN 报文标识要关闭连接, 服务端收到后发送 ACK 报文询问是否关闭并进入关闭等待状态(资源整理关闭的时间), 在处理等待完之后再次发送 FIN 字段标志服务端已经准备好关闭了, 此时客户端发送确认到服务端, 服务端关闭服务, 客户端进入超时等待。

  `举例`: A 和 B 打电话，通话即将结束后，A 说 “我没啥要说的了”，B 回答 “我知道了”，于是 A 向 B 的连接释放了。但是 B 可能还会有要说的话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，于是 B 向 A 的连接释放了，这样整个通话就结束了。

- **问题**

  **1) 为什么不可以三次挥手?**

  ​	三次挥手一般指的是将服务端发送 ACK+FIN 报文的过程合并为一次, 这时服务端就无法保证服务端数据是否发送完毕。  `与下面的问题等价↓`

  **2) 为什么连接的时候是三次握手，关闭的时候却是四次握手？**

  ​	在建立连接时服务端收到客户端的SYN连接报文后, 服务端发送SYN用于同步, ACK报文用于应答, 这时并没有数据处理过程自然也不需要等待。但是关闭连接时服务端收到FIN报文时, 很可能还需要发送数据, 这时服务端就会先发送 ACK 报文应答, 然后等待服务端数据发送完毕再发送FIN字段标志发送完毕。

  **3) 为什么客户端要等待超时时间 2MSL？**

  ​	①*保证客户端发送的最后一个ACK报文段能够到达服务器*。 ②*避免上一次TCP连接的数据包影响到下一次的TCP连接*  防止已经失效的连接请求报文段出现在本连接中(客户端在发送完最后一个ACK报文段后，再经过时间2MSL。就可以使本连接持续的时间内所产生的所有报文段都在网络中消失。这样就可以在下一个新的连接中不会出现这种旧的连接请求报文段)。



### 4 JWT 为什么比 cookie 和 session 安全

- `Cookie`

  是以键值对的形式储存在浏览器中，而且在浏览器中可以直接看到数据。

  - 优点：
    1. 结构简单。cookie是一种基于文本的轻量结构，包含简单的键值对。
    2. 数据持久。虽然客户端计算机上cookie的持续时间取决于客户端上的cookie过期处理和用户干预，cookie通常是客户端上持续时间最长的数据保留形式。

  - 缺点：
    1. 大小受到限制。大多数浏览器对 cookie 的大小有 4096 字节的限制，尽管在当今新的浏览器和客户端设备版本中，支持 8192 字节的 cookie 大小已愈发常见。
    2. 非常不安全。cookie将数据裸露在浏览器中，这样大大增大了数据被盗取的风险，所有我们不应该将中要的数据放在cookie中，或者将数据加密处理。
    3. 容易被csrf攻击。可以设置csrf_token来避免攻击。

- `Session`

  session 存储在服务器中，然后发送一个cookie存储在浏览器中，cookie中存储的是session_id，之后每次请求服务器通过session_id可以获取对应的session信息

  - 优点：
    1. session的信息存储在服务端，相比于cookie就在一定程度上加大了数据的安全性；相比于jwt方便进行管理，也就是说当用户登录和主动注销，只需要添加删除对应的session就可以，这样管理起来很方便。

  - 缺点：
    1. session存储在服务端，这就增大了服务器的开销，当用户多的情况下，服务器性能会大大降低。
    2. 因为是基于cookie来进行用户识别的, cookie如果被截获，用户就会很容易受到跨站请求伪造的攻击。
    3. 用户认证之后，服务端做认证记录，如果认证的记录被保存在内存中的话，这意味着用户下次请求还必须要请求在这台服务器上,这样才能拿到授权的资源，这样在分布式的应用上，会限制负载均衡和集群水平拓展的能力。

- `JWT`

  JWT 存储在浏览器的 storage 或者 cookie 中。由服务器产生加密的json数据包括：header，payload和signature三部分组成。header中通常来说由token的生成算法和类型组成；payload中则用来保存相关的状态信息；signature 部分由 header，payload，secret_key 三部分加密生成。 注意，不要在 JWT 的 payload 或 header 中放置敏感信息，除非它们是加密的。

  - 优点：
    1. 因为json的通用性，jwt可以支持跨语言请求，像 JAVA,JavaScript,PHP 等很多语言都可以使用。
    2. 因为有了payload部分，所以JWT可以在自身存储一些其他业务逻辑所必要的非敏感信息。
    3. 便于传输，JWT的构成非常简单，字节占用很小，所以它是非常便于传输的。
    4. 不需要在服务端保存会话信息, 利于服务器横向拓展。

  - 缺点：
    1. 登录状态信息续签问题。比如设置token的有效期为一个小时，那么一个小时后，如果用户仍然在这个web应用上，这个时候当然不能指望用户再登录一次。目前可用的解决办法是在每次用户发出请求都返回一个新的token，前端再用这个新的token来替代旧的，这样每一次请求都会刷新token的有效期。但是这样，需要频繁的生成token。另外一种方案是判断还有多久这个token会过期，在token快要过期时，返回一个新的token。
    2. 用户主动注销。JWT并不支持用户主动退出登录，客户端在别处使用token仍然可以正常访问。为了支持注销，我的解决方案是在注销时将该token加入到服务器的redis黑名单中。

 

### 5 IO 通信模型

Socket 是一种网络通信的编程接口，它提供了一种机制，使得不同计算机上的程序可以通过网络进行通信。以下的 BIO、AIO、NIO 都是 Socket 通信模型的一种。

- BIO - Blocked IO(阻塞IO)。 当用户线程发送请求后会一直阻塞线程直到数据准备完毕。 `阻塞IO`  

  场景: *连接数较小且每个连接的数据交互量较大*

- NIO - Nonblocking IO(非阻塞IO)。用户进程发送请求后可做其他工作并不断访问内核数据, 但在数据复制阶段, 用户线程依旧阻塞。 `非阻塞IO`

  场景: *处理大量并发连接* *需要实现高性能网络通信*

- AIO - Asynchronous IO(异步IO) 。当用户线程发送请求后, 内核返回回调函数, 该回调函数不包含数据, 用户线程可以处理其他操作, 当数据准备完成后内核将数据发送给用户线程, 而不像同步IO那样由用户线程自己读取。

  场景: *高并发、高吞吐量的异步操作* - 大规模文件操作、高性能网络编程

- IO 多路复用: 单个线程同时处理多个客户端请求。基于 `select`、`poll`、`epoll`三个操作。`select`: 查询多少个文件描述符需要IO, 底层为数组, 因此文件描述符个数有上限, 线性遍历扫描大量文件描述符。 `poll`: 与select基本一致线性遍历扫描大量文件描述符, 只是底层为链表, 因此文件描述符个数没有上限。 `epoll`: 更高效, 使用红黑树+链表, 通过回调函数的方式处理就绪的文件描述符, 只返回就绪的文件描述符，减少了遍历的开销，提高了效率。

  `poll` 和 `select` 都为轮询方式, 区别在于 `poll` 使用了链表, 因此文件描述符没有上限; `epoll` 则采用**回调方式**, 它将文件描述符加入到红黑书树, 当每个IO就绪之后直接返回数据, 而不需要多次复制操作。 (同时检测多个文件描述符是否执行IO)

  场景: *线程数少且并发要求高* - 大规模并发连接处理

- Java NIO: 同步非阻塞IO



### 6 TCP 粘包和拆包

- **粘包**

  TCP协议中，发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。 *多个包粘在一起, 接收端分不清界限* 

- **拆包**

  TCP 协议发送包过大进行拆分发送(TCP传输数据上限)。 *大数据包拆分* 

- **原因**

  1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
  2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。
  3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
  4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

- **解决办法** 

  `关键在于给每个数据包添加边界信息`

  1、*发送端给每个数据包添加包首部*，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
  2、*发送端将每个数据包封装为固定长度*（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
  3、*可以在数据包之间设置边界*，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。



### 7 TCP 与 UDP

- **TCP**

  `基于连接` `提供可靠传输` `面向字节流` 适合对网络通讯要求高的场景, 如: 传输文件、发送邮件、浏览网页等。

  - **滑动窗口**

    *发送方与接收方各自维护一个窗口, 窗口的大小代表了可以发送或接收的数据量, 发送方通过滑动窗口大小来控制发送数据的速率，接收方通过滑动窗口大小来告知发送方自己可以接收的数据量。* 

    示例：假设发送方的滑动窗口大小为10个数据包，接收方的滑动窗口大小为5个数据包。发送方可以连续发送10个数据包，然后等待接收方确认收到其中的一部分数据后，再发送新的数据。

  - **流量控制**

    *接收方使用滑动窗口的大小来告知发送方自己的接收能力，发送方根据接收方的窗口大小来控制发送数据的速率，确保不会发送超出接收方处理能力范围的数据。* 流量控制是TCP协议中用于调节发送方发送数据的速率，以避免接收方无法及时处理大量数据或发生数据丢失的情况。

    示例：假设接收方的滑动窗口大小为1000字节，表示接收方还有1000字节的缓冲区可用来接收数据。发送方会根据接收方的窗口大小发送适当数量的数据，以确保接收方能够及时处理和接收数据。

  - **拥塞控制**
    *拥塞控制通过动态调整发送方发送数据的速率，以适应网络的拥塞程度。拥塞控制算法包括慢启动、拥塞避免、快速重传和快速恢复等。*  拥塞控制是TCP协议中用于避免网络拥塞和保持网络性能的机制。

    示例：当网络发生拥塞时，路由器的缓冲区可能已满，导致数据包丢失。TCP通过检测到数据包丢失并接收到重复的确认来判断网络是否发生拥塞。一旦拥塞发生，TCP会减小发送窗口的大小，降低发送速率，以避免进一步加重网络拥塞。

    - **算法**
      1. 慢启动（Slow Start）
         慢启动算法是TCP连接刚开始时的拥塞控制阶段。发送方初始将拥塞窗口（Congestion Window）设置为一个较小的值，然后每收到一个确认确认，拥塞窗口就会加倍。这样，拥塞窗口的增长速率呈指数级增长，从而快速适应网络的带宽。
      2. 拥塞避免（Congestion Avoidance）
         拥塞避免算法在慢启动阶段之后启动。发送方每收到一个确认确认，拥塞窗口的增长速率不再是指数级增长，而是线性增长。这样可以避免快速消耗网络资源，使网络更加稳定。
      3. 快速重传（Fast Retransmit）
         快速重传算法用于快速检测丢失的数据包。当发送方连续收到相同的确认确认时，它会认为有个别数据包丢失。而不是等待超时后再重传，发送方立即重传丢失的数据包，以提高数据传输的效率。
      4. 快速恢复（Fast Recovery）
         快速恢复算法是与快速重传算法结合使用的。当发送方检测到丢失的数据包后，它将拥塞窗口减半，并将拥塞窗口设置为慢启动阈值（Slow Start Threshold）的一半。然后，在每次收到确认确认时，拥塞窗口增加一个数据包大小，而不是线性增长。这样可以更快地恢复到正常的拥塞避免阶段。

- **UDP**

  `非连接` `提供不可靠交付` `面向数据报文` 适合网络通讯要求弱的场景, 如: 视频、语音、直播等



### 8 断点续传

- **断点**

  在下载过程中，将一个下载文件分成了多个部分，同时进行多个部分一起的下载，当某个时间点任务被暂停了，此时下载暂停的位置就是断点了。

- **续传**

  当一个未完成的下载任务再次开始时，会从上次的断点继续传送。

- **思路**

  使用多线程断点续传下载的时候，将下载或上传任务（一个文件或一个压缩包）人为的划分为几个部分，每一个部分采用一个线程进行上传或下载，多个线程并发可以占用服务器端更多资源，从而加快下载速度。
  在下载（或上传）过程中，如果网络故障、电量不足等原因导致下载中断，这就需要使用到断点续传功能。下次启动时，可以从记录位置（已经下载的部分）开始，继续下载以后未下载的部分，避免重复部分的下载。断点续传实质就是能记录上一次已下载完成的位置。

- **过程**

  1. 在下载过程中记录每条线程的下载进度。

  2. 每次下载开始之前先读取数据库，查询是否有未完成的记录，有就继续下载，没有则创建新记录插入数据库。

  3. 在每次向文件中写入数据之后，在数据库中更新下载进度。

  4. 下载完成之后删除数据库中下载记录。



### 9 HTTP 和 TCP 长连接的区别

- HTTP

  Keep-Alive，是由应用层（用户态）实现的，称为 HTTP 长连接；  *实质上还是依赖 TCP 保证长连接建立*

  短连接: `建立 TCP -> 请求资源 -> 响应资源 -> 释放连接(不加 Keep-Alive 参数, 资源响应完毕自动断开连接)`

  长连接: `请求-应答模式 - 设置Keep-Alive参数保证客户和服务器端持有同一个TCP链接通信且均不断开连接, 直到某一方提出断开请求` 

- TCP

  Keepalive，是由TCP 层（内核态）实现的，称为 TCP 保活机制；

  `TCP保活机制 - 内核TCP协议栈发送探测报文, 如果及时收到回复则保活; 否则多次未收到回复则判定TCP链接死亡`



### 10 全连接和半连接

- 全连接

  `双向连接`  通信的两个端点之间建立了一个完整的双向连接, 这意味着双方都可以发送和接收数据，彼此之间的通信是完全开放的。

- 半连接

  `单方可发`  连接的一方已经发送了连接请求（SYN包），但另一方尚未完成连接的确认（ACK包）。在半连接状态下，一方可以发送数据，但另一方暂时无法接受或发送数据。半连接通常用于实现一些网络协议中的特定机制，例如TCP三次握手过程中的中间状态。



### 11 IO 零拷贝

零拷贝（Zero-copy）是一种优化技术，旨在减少数据在内核空间和用户空间之间的复制操作，以提高数据传输的效率。在传统的数据传输过程中，通常涉及多次数据拷贝，其中包括从磁盘读取数据到内核缓冲区，再从内核缓冲区拷贝到用户缓冲区，最后再将数据写入网络或其他设备。而零拷贝技术通过减少或消除这些拷贝操作，以减少CPU和内存的开销，提高数据传输的性能。

在实现零拷贝时，涉及以下几个主要的技术：

1. 文件描述符传递（File Descriptor Passing）：零拷贝技术利用文件描述符传递的特性，将数据直接从磁盘读取到用户空间的缓冲区，避免了数据在内核空间和用户空间之间的复制。
2. 直接内存访问（Direct Memory Access）：零拷贝技术使用直接内存访问技术，使得数据可以直接从内核缓冲区传输到网络或其他设备，而无需经过用户空间的中间缓冲区。
3. 零拷贝网络传输：在网络传输过程中，零拷贝技术可以通过使用操作系统提供的零拷贝套接字（Zero-copy Sockets）或者使用专用的网络硬件来实现数据的直接传输，避免了数据在用户空间和内核空间之间的复制。

通过使用零拷贝技术，可以显著提高数据传输的效率，降低CPU和内存的开销，以及减少数据传输的延迟。这在处理大规模数据、高并发网络传输等场景下特别有益，例如文件传输、网络服务器、数据存储系统等。然而，实施零拷贝技术需要深入了解操作系统和硬件的特性，并且需要开发者在代码层面进行相应的优化。



### 12 Restful 风格

> 概念: RESTFUL是一种网络应用程序的设计风格和开发方式, 一种软件架构风格，用于设计网络应用程序的分布式系统。`基于 HTTP`，可使用 XML 或 JSON 格式定义。最常用的数据格式是 JSON, 由于 JSON 能直接被JavaScript读取，所以，使用JSON 格式的 REST风格的 API 具有简单、易读、易用的特点。

|     请求方式     |                 含义                 |
| :--------------: | :----------------------------------: |
|  GET（SELECT）   |    从服务器取出资源（一项或多项）    |
|  POST（CREATE）  |         在服务器新建一个资源         |
|  PUT（UPDATE）   |   在服务器更新资源（更新完整资源）   |
| PATCH（UPDATE）  | 在服务器更新资源， PATCH更新个别属性 |
| DELETE（DELETE） |           从服务器删除资源           |

**常用注解**

- `@RequestMapping`    设置当前控制器方法请求访问路径

  ```java
   @RequestMapping(value = "/users", method = RequestMethod.GET)
   @ResponseBody
   public String save()
  {
     System.out.println("save user");
     return " '{'module': 'user save' }' ";
  }
  ```

- `@PathVariable`    绑定路径参数与处理器方法形参间的关系，要求路径参数名与形参名一一对应

  ```java
  @RequestMapping(value = "users/{id}", method = RequestMethod.DELETE)
  @ResponseBody
  public String delete(@PathVariable Integer id) // PathVariable 路径参数 id对应路径中的id
  {
      System.out.println("delete user");
      return "'{'module': 'user delete'}'";
  }
  ```

- `@RestControll`   设置当前控制器类为RESTful风格，等同于 @Controller 与 @ResponseBody两个注解的组合功能

  ```java
  @RestController
  public class UserController
  {
      @RequestMapping(value = "/users",method = RequestMethod.GET)
      public String save()
      {
          System.out.println("save user");
          return " '{'module': 'user save' }' ";
      }
  ```

- `@GetMapping @PostMapping @PutMapping @DeleteMapping`  设置当前控制器方法请求访问路径与请求动作，每种对应一个请求动作

- `RequestParam` 用于接收URL地址传参或表单传参

- `RequestBody`  用于接收JSON数据

- `@ResponseBody`  将java对象转为json格式的数据, 写入到response对象的body区，通常用来返回JSON数据或者是XML数据。





## 操作系统

### 1 用户态和内核态

- `用户态 `   User Mode

  运行用户程序, 只能执行一些非特权指令。

- `内核态 `   Kernel Mode

  运行操作系统程序，操作硬件, 能够执行特权指令, 调用IO设备。

- **区别**

  处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的; 处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占。
  
- **切换方式**  用户态 -> 内核态

   `系统调用`  应用程序需要访问操作系统提供的服务或执行特权操作

   `异常和中断处理`  当发生异常（如除零错误、缺页错误等）或外部中断（如硬件中断、时钟中断等）时

   `信号处理`  当应用程序收到信号时（如SIGINT、SIGTERM等）, 需要执行函数时

   `进程切换`  当操作系统需要进行进程切换时



### 2 进程与线程与协程 | 进程通信 | 线程同步

- 进程通信

  - `管道（Pipe）`：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系进程间的通信，允许一个进程和另一个与它有共同祖先的进程之间进行通信。（半双工：数据传输指数据可以在一个信号载体的两个方向上传输，但是不能同时传输。）

  - `有名管道（named pipe）`： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。命名管道在文件系统中有对应的文件名。命名管道通过命令 mkfifo 或系统调用 mkfifo 来创建。
  - `信号（Signal）`：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生。

  - `消息（Message）队列`：消息队列是消息的链接表。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
  - `共享内存`：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。
  - `内存映射（mapped memory）`：内存映射允许任何多个进程间通信，每一个使用该机制的进程通过把一个共享的文件映射到自己的进程地址空间来实现它。
  - `信号量（semaphore）`：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
  - `套接口（Socket）`：更为一般的进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。可用于不同机器之间的进程间通信。

- **进程 - 线程 - 协程**

  - 进程: 操作系统的执行单元, 具有独立的内存空间和资源, 进程之间独立运行。

  - 线程: 进程内的一个执行单元, 共享进程的内存空间和资源, 多个线程可以并发执行。

  - 协程: 用户级的轻量级线程, 调度完全由用户控制。切换开销很小, 更适合高并发和IO密集型服务。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此，协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态。这个过程完全由程序控制，不需要内核进行调度。  `轻量级并发 - 开销更小` `异步编程 - IO等待而不阻塞, 异步操作` `并发简化 - 不需要考虑竞争锁和细节`

  - **区别**

    `线程 - 协程`:  协程是用户态的轻量级线程，不受内核调度；线程是任务调度和系统执行的最小单位，需要内核调度; 协程不需要内核调度, 系统开销更小; 进程和线程都可以拥有多个协程; 线程与进程都是同步机制, 协程是异步机制; 线程是抢占式的, 协程是非抢占式的, 因此需要用户主动释放。
    
    `进程 - 线程`: *进程有独立的内存空间和资源, 线程则共享进程的资源*; *进程是操作系统资源分配的基本单位*, *线程是处理器调度的基本单位*; *进程切换的资源开销大于线程*; *一个进程包含多个线程*; *进程崩溃不影响其他进程, 线程崩溃则整个进程都故障*。

- **线程同步**

  线程同步（Thread Synchronization）是指在多线程环境下对共享资源的访问进行协调和控制，以避免并发访问造成的数据不一致性或竞争条件问题。当多个线程并发地访问共享资源时，如果没有适当的同步机制，可能会导致数据的不确定性或错误的结果。  `synchronized 和 Lock`

  **线程同步机制**

  `互斥锁` `条件变量` `信号量`   保证在给定的时刻只有一个线程可以访问共享资源，或者在满足特定条件之前线程需要等待。



### 3 死锁 | 产生条件 | 解决办法

- 死锁

  两个或两个以上进程互相争枪对方的资源且不释放自己的资源。

- 原因

  `互斥`: 一个资源在同一时刻只可被一个线程执行

  `请求和保持`: 一个线程在请求资源时, 不释放自己持有的资源

  `不可剥夺`: 资源在使用过程中无法被其它进程强行剥夺, 只能自行释放。

  `环路等待`: 线程资源需求形成了一条环路, 都无法执行。

- 解决方法

  破坏死锁产生的条件。 如: 资源可剥夺、主动释放等



### 4 JAVA 进程和线程的状态有哪些

- 进程的状态

  `创建`、`就绪`、`运行`、`阻塞`、`销毁`

  new 一个线程时为创建状态, 执行 start() 方法后为就绪状态, 当线程获取CPU资源后执行 run() 进入运行状态, 调用 sleep() 进入阻塞状态, 进程执行完或抛出异常进入销毁状态。

- 线程的状态: Java线程一共有6种状态。

  `NEW`: 新建状态，还没调用 start 方法。

  `Runnable`: 运行状态，线程正在JVM中执行，也可能在等待操作系统的调度。

  `BLOCKED`：阻塞状态，线程正在等待获取锁。

  `WAITING`: 等待状态，线程正在等待其他线程的通知或中断。

  `TIMED_WAITING`: 超时等待状态，在WAITING的基础上增加了超时时间，即超出时间自动返回。

  `TERMINATED`：终止状态，线程已执行完毕。 



## 数据结构

### 1 B | B+ | 红黑树 | 平衡二叉树 | MySQL 索引

![image-20231027105032125](imgs/image-20231027105032125.png)



<img src="imgs/image-20230817142411489.png" alt="image-20230817142411489" style="zoom: 67%;" />



- **B 树**: 平衡的多路搜索树，每个节点可以存储多个键值对。数据存放在叶子结点和非叶子结点上, 所有的叶子结点独立。

- **B+ 树**: 非叶子结点只存放 Key, 叶子结点存放数据, 所有的叶子结点之间通过**双向链表**进行连接。 **B+ 树比 B 树更加稳定**

- **红黑树**:  一种 *自平衡的二叉查找树* , 能够在 $O(logN)$ 时间内完成查询、增加、删除操作。

  - `性质`

    结点是红色 | 黑色

    根和叶子都是黑色

    从每个叶子到根的所有路径上不能有两个连续的红色节点 - 父子不能同时为红

    从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点（简称黑高）

    ​      以上的性质是为了 `红黑树退化为链表`

  - `特点`: 通过 变色、左旋和右旋 实现自平衡和保持红黑树特征; 插入或者删除节点时旋转次数少

  - `左旋`

    指的是围绕某个节点向左旋转，也就是逆时针旋转某个节点，使得父节点被自己的右子节点所替代

    <img src="imgs/d5a18f2554f38788bf2043197341b880.png" alt="红黑树和平衡二叉树有什么区别？「建议收藏」" style="zoom: 33%;" />

  - `右旋`

    指的是围绕某个节点向右旋转，也就是顺时针旋转某个节点，此时父节点会被自己的左子节点取代

    <img src="imgs/cf2b2866a23bf406b1b297877fc64975.png" alt="红黑树和平衡二叉树有什么区别？「建议收藏」" style="zoom: 33%;" />

  - `变色`

    对于红黑树来说，如果当前节点的左、右子节点均为红色时，因为需要满足红黑树定义的第四条特征，所以需要执行变色操作

    <img src="imgs/40947cb7e1e6a29e2e51ee5d8bcaee92.png" alt="image" style="zoom: 33%;" />

- **平衡二叉树**: 左右子树的高度差不超过 1 的二叉树

  `性质`:  可以为空树; 左右子树高度差不超过1且左右子树均是平衡二叉树

  `特点`:  通过左旋右旋来调整平衡, 为了保证性质会产生频繁旋转(损耗 O(logn) 的时间) - 见上描述; 适合读操作频繁, 对插入删除操作的要求不是特别严格的情况。

   <img src="imgs/v2-90521aa91ad8fd7677ed7899d586761c_1440w.webp" alt="img" style="zoom: 33%;" />

  

- **MySQL 索引**

  索引是一种帮助快速查找的数据结构, 可以理解为书的目录, 通过索引可以快速找到数据所在的位置。

  为什么不用别的树(红黑树、B树)?

  - 红黑树是二叉树的自平衡二叉树, 它的结构导致它的树高很高, 不利于磁盘I/O操作。 在 `Innodb` 中使用 B+ 树作为索引结构, 相比于二叉树 B+ 树这种多叉树更加矮胖, 能够减少 IO 次数; 同时B+树数据之间的链更适合范围查询。



### 2 堆

> 概念: 堆就是一颗顺序存储的完全二叉树，底层是一个数组

<img src="imgs/heap.png" alt="在这里插入图片描述" style="zoom:50%;" />

**特点**: `完全二叉树` `数组存储` `大根堆-父大于子` `小跟堆-父小于子`

**堆的构建和调整:** 

- 将初始堆从最后一个非叶子结点通过不断的调整转换为(大根堆|小根堆), 每次交换后，都要对下一层的子堆进行递归调整，因为交换后有可能破坏已调整子堆的结构。

  <img src="imgs/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poaXpoZW5nZ3Vhbg==,size_16,color_FFFFFF,t_70-16980570728482.png" alt="img" style="zoom: 80%;" />

**堆排序**

[BOLG](https://blog.csdn.net/weixin_51609435/article/details/122982075?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169805724216800225527639%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169805724216800225527639&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-122982075-null-null.142^v96^pc_search_result_base4&utm_term=%E5%A0%86%E6%8E%92%E5%BA%8F&spm=1018.2226.3001.4187) 

- **思想**

  1 首先将待排序的数组构造成一个大根堆，此时，整个数组的最大值就是堆结构的顶端

  2 将顶端的数与末尾的数交换，此时，末尾的数为最大值，剩余待排序数组个数为n-1
  3 将剩余的n-1个数再构造成大根堆，再将顶端数与n-1位置的数交换，如此反复执行，便能得到有序数组
  注意:升序用大根堆，降序就用小根堆(默认为升序)

- **步骤**

  1. 先 n 个元素的无序序列，构建成大顶堆
  2. 将根节点与最后一个元素交换位置，（将最大元素"沉"到数组末端）
  3. 交换过后可能不再满足大顶堆的条件，所以需要将剩下的 n-1 个元素重新构建成大顶堆
  4. 重复第 2 步、第 3 步直到整个数组排序完成。

  <img src="imgs/v2-af5f3634abf3b828ef8aef6fed546f7e_1440w.webp" alt="img" style="zoom: 67%;" />



## 设计模式

### 1 单例模式

#### 1) 饿汉式

`一开始就生成实例`

```java
public class Singleton {
    private static Singleton instance = new Singleton();

    private Singleton(){};

    private static Singleton getInstance(){
        return instance;
    }
}
```



#### 2) 懒汉式

`用时才生成实例`

```java
public class Singleton {
    private static Singleton instance;

    private Singleton(){};

    private static synchronized Singleton getInstance(){
        if(instance == null){
            instance = new Singleton();
        }
        return instance;
    }
}
```



#### 3) 双重校验

> 双重校验(Double-Checked Locking)是一种在单例模式中实现延迟初始化和线程安全的方式。它通过在获取实例时进行额外的检查来避免不必要的同步开销。

```java
public class Singleton {
    private volatile static Singleton instance;

    private Singleton() {
        // 私有构造函数
    }

    public static Singleton getInstance() {
        if (instance == null) {  // 第一次检查
            synchronized (Singleton.class) {
                if (instance == null) {  // 第二次检查
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

在上面的代码中，`getInstance()`方法是获取单例对象的静态方法。它使用了双重检查来确保只有在实例为null时才进行同步和实例化。具体的步骤如下：

1. 在第一次检查时，如果实例已经存在（非null），则直接返回实例，避免进入同步块。这样可以提高性能并避免不必要的同步操作。
2. 如果实例为null，表示还没有进行初始化，则进入同步块。
3. 在同步块内部，再次检查实例是否为null。这是为了防止在多个线程同时通过了第一次检查后，只有一个线程进入同步块进行实例化，其他线程仍然可以继续创建实例。
4. 在同步块内部，进行实例的创建操作。

这种双重检查的方式可以在多线程环境下保证单例对象的线程安全性，并且只有在第一次获取实例时才会进入同步块进行实例化，避免了每次获取实例都进行同步的开销。



### 2 工厂模式

分为简单工厂、工厂方法、抽象工厂

- 简单工厂

  提供一个统一的工厂类对实现了同一接口的一些类进行实例的创建。如 Animal 生产 Dog、Cat等多个动物。 

  ```java
  interface Sender {
      void Send();
  }
  
  class MailSender implements Sender {
  
      @Override
      public void Send() {
          System.out.println("This is mail sender...");
      }
  }
  
  class SmsSender implements Sender {
  
      @Override
      public void Send() {
          System.out.println("This is sms sender...");
      }
  }
  
  public class FactoryPattern {
      public static void main(String[] args) {
          Sender sender = produce("mail");
          sender.Send();
      }
      public static Sender produce(String str) {
          if ("mail".equals(str)) {
              return new MailSender();
          } else if ("sms".equals(str)) {
              return new SmsSender();
          } else {
              System.out.println("输入错误...");
              return null;
          }
      }
  }
  ```

- 工厂方法

  针对不同的对象提供不同的工厂。如 Animal 分配 DogFactory、CatFactory 生产不同的动物。

- 抽象工厂

  针对不同维度(多个品牌的手机、电脑)的产品提供总的接口, 用于创建不同维度的工厂, 而不需要指定具体类。如: Animal 分为 DogFactory 和 CatFactory, Dog 和 Cat 又分为不同品种, 这时再细分具体的如 OneDog | TwoDog 继承自 DogFactory 实现自己所需的方法。

  工厂方法模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要扩展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？
  那么这就用到了抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。

  ```java
  interface Provider {
      Sender produce();
  }
  
  interface Sender {
      void Send();
  }
  
  class MailSender implements Sender {
  
      public void Send() {
          System.out.println("This is mail sender...");
      }
  }
  
  class SmsSender implements Sender {
  
      public void Send() {
          System.out.println("This is sms sender...");
      }
  }
  
  class SendMailFactory implements Provider {
  
      public Sender produce() {
          return new MailSender();
      }
  }
  
  class SendSmsFactory implements Provider {
  
      public Sender produce() {
          return new SmsSender();
      }
  }
  
  
  public class FactoryPattern {
      public static void main(String[] args) {
          Provider provider = new SendMailFactory();
          Sender sender = provider.produce();
          sender.Send();
      }
  }
  
  ```

  

### 3 策略模式

> 概念: 策略设计模式是一种行为设计模式。*当在处理一个业务时，有多种处理方式，并且需要再运行时决定使哪一种具体实现时，就会使用策略模式。*
>
> **策略模式本质是**：`分离算法，选择实现`
>
> 通俗来讲：策略模式对应于解决某一个问题的一个算法族，允许用户从该算法族中任选一个算法解决某一问题，同时可以方便的更换算法或者增加新的算法。并且由客户端决定调用哪个算法。
>
> **策略模式的宗旨** 就是将各项方法之间连接起来，达到一个新的方法，微服务的宗旨也是防止服务的多次调用，降低代码的耦合度，因此这么看来策略模式和微服务还是比较相像的。

策略模式:

```java
public interface PaymentStrategy {
    public void payment(BigDecimal amount);
}

public class CreditPaymentStrategy implements PaymentStrategy{
    @Override
    public void payment(BigDecimal amount) {
        System.out.println("使用银行卡支付" + amount);
        // 去调用网联接口
    }
}

public class WechatPaymentStrategy implements PaymentStrategy{
    @Override
    public void payment(BigDecimal amount) {
        System.out.println("使用微信支付" + amount);
        // 调用微信支付API
    }
}

public class AlipayPaymentStrategy implements PaymentStrategy {
    @Override
    public void payment(BigDecimal amount) {
        System.out.println("使用支付宝支付" + amount);
        // 调用支付宝支付API
    }
}

public class PaymentService {
    /**
    * 将strategy作为参数传递给支付服务
    */
    public void payment(PaymentStrategy strategy, BigDecimal amount) {
        strategy.payment(amount);
    }
}


public class StrategyTest {
    public static void main(String[] args) {
        PaymentService paymentService = new PaymentService();
        // 使用微信支付
        paymentService.payment(new WechatPaymentStrategy(), new BigDecimal("100"));
        //使用支付宝支付
        paymentService.payment(new AlipayPaymentStrategy(), new BigDecimal("100"));
    }
}
```

**总结**: 策略模式主要是在需要提供多种业务处理逻辑时, 提供任选的接口, 在拓展是只需要扩展新类即可, 而不需要修改原有的类, 满足开闭原则; 遇到工厂模式需要分类处理(if-else)的时候, 增加功能会违反 `开闭原则` , 策略模式则不会。 [Link1](https://www.cnblogs.com/ysocean/p/15635852.html) [Link2](https://mp.weixin.qq.com/s?__biz=MzIwNjg4MzY4NA==&mid=2247507414&idx=2&sn=ee20414b9c8bcfc2505c3a0110e2e583&chksm=971843dda06fcacba299e137e869496e0503bdba9841114f134736eb92fc4afe0a8cccae3e65&scene=21#wechat_redirect) [Link3](https://juejin.cn/post/7030976391596212255)



- JDK中使用策略模式的例子

  在JDK中最经典的使用策略模式的例子就是`Collections.sort(List<T> list, Comparator<? super T> c)`方法，这个方法接受一个比较器`Compartor`参数，客户端在运行时可以传入一个比较器的实现，`sort()`方法中根据不同实现，按照不同的方式进行排序。

- 策略模式使用场景

  在实际工作中，会有很多场景可以使用策略模式，比如上面例子中的多个支付方式，再比如与不同的第三方销售渠道对接等等。

  **总结一下**

  - 如果在一个系统里面有许多类，它们仅仅在行为上有区别，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为；
  - 一个系统需要动态地在几种算法中选择一种；
  - 如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。



### 4 观察者模式

> 观察者模式又称为发布/订阅(Publish/Subscribe)模式,在对象之间定义了一对多的依赖，这样一来，当一个对象改变状态，依赖它的对象会收到通知并自动更新(广播)。
>
> 在 `Java` 中，观察者模式通常由两个接口组成：`Subject` 和 `Observer`。`Subject`是被观察的对象，`Observer` 是观察者。`Subject` 接口定义了一系列方法，用于添加、删除和通知观察者，`Observer` 接口定义了一个 `update()` 方法，当 `Subject` 状态发生改变时，该方法被调用。

**实现**

在这个例子中，我们创建了一个`Subject`类，它包含一个列表`observers`，其中包含所有注册的观察者。`Subject`类还有一个状态`state`，它表示主题状态的变化。当状态改变时，`notifyAllObservers()`方法被调用，通知所有观察者更新它们的状态。

我们还创建了三个具体的观察者：`BinaryObserver`，`OctalObserver`和`HexaObserver`。每个观察者都需要一个`Subject`对象，并注册自己到该对象中。当`Subject`状态改变时，每个观察者都会收到通知并更新自己的状态，其中`update()`方法用于更新观察者状态。在`ObserverPatternDemo`类中，我们创建一个`Subject`对象，并向其注册三个观察者。然后，我们对主题进行两次状态更改，并在控制台输出每个观察者的状态。

@: `抽象类 Observer 与主题类 Subject, 实际观察者 A B C 分别继承抽象类。抽象类包含主题, 主题类包含观察者数组。在实际观察值设定主体的同时会把自身传递到主题类的观察者数组中, 这时就能够实现广播 - 调用更新。`

```java
import java.util.ArrayList;
import java.util.List;

public class Subject {
    private List<Observer> observers = new ArrayList<Observer>();
    private int state;

    public int getState() {
        return state;
    }

    public void setState(int state) {
        this.state = state;
        notifyAllObservers();
    }

    public void attach(Observer observer){
        observers.add(observer);
    }

    public void notifyAllObservers(){
        for (Observer observer : observers) {
            observer.update();
        }
    }
}

public abstract class Observer {
    protected Subject subject;
    public abstract void update();
}

public class BinaryObserver extends Observer{

    public BinaryObserver(Subject subject){
        this.subject = subject;
        this.subject.attach(this);
    }

    public void update() {
        System.out.println( "Binary String: " + Integer.toBinaryString( subject.getState() ) );
    }
}

public class OctalObserver extends Observer{

    public OctalObserver(Subject subject){
        this.subject = subject;
        this.subject.attach(this);
    }

    public void update() {
        System.out.println( "Octal String: " + Integer.toOctalString( subject.getState() ) );
    }
}

public class HexaObserver extends Observer{

    public HexaObserver(Subject subject){
        this.subject = subject;
        this.subject.attach(this);
    }

    public void update() {
        System.out.println( "Hex String: " + Integer.toHexString( subject.getState() ).toUpperCase() );
    }
}

public class ObserverPatternDemo {
    public static void main(String[] args) {
        Subject subject = new Subject();

        new HexaObserver(subject);
        new OctalObserver(subject);
        new BinaryObserver(subject);

        System.out.println("First state change: 15");	
        subject.setState(15);
        System.out.println("Second state change: 10");	
        subject.setState(10);
    }
}
```

**OUT**

```cmd
First state change: 15
Hex String: F
Octal String: 17
Binary String: 1111
Second state change: 10
Hex String: A
Octal String: 12
Binary String: 1010
```

- **优点**
  1. 降低耦合性：观察者模式将主题（`Subject`）和观察者（`Observer`）之间的依赖关系解耦，使得它们可以独立地改变。主题不需要知道哪些观察者正在观察它，观察者也不需要知道主题的细节。
  2. 易于扩展：由于观察者模式是松散耦合的，因此可以很容易地添加或删除观察者，而不会影响主题或其他观察者。这使得代码更加灵活，易于扩展。
  3. 实现了开放/封闭原则：观察者模式遵循开放/封闭原则，即对于扩展是开放的，对于修改是封闭的。这意味着可以通过添加新的观察者来扩展系统的功能，而不必更改现有代码。
  4. 实现了可重用性：观察者模式将主题和观察者分离，使它们可以独立地进行测试和重用。
  5. 提高了灵活性和可维护性：观察者模式使得系统中的对象之间的通信变得更加灵活和可维护。它还使代码更易于理解和维护。
- **缺点**
  1. 内存泄漏：在观察者模式中，观察者需要注册到主题对象，当观察者不再需要时，需要从主题中注销，否则会导致内存泄漏。因为如果观察者对象没有被注销，则主题对象将保留对它的引用，这将防止观察者被垃圾回收。
  2. 性能问题：观察者模式在一些情况下可能会导致性能问题。当主题对象有大量观察者时，每当主题状态发生变化时，所有观察者都会被通知，这可能会导致性能问题。
  3. 并发问题：如果多个线程同时访问主题对象，并且主题对象在处理一个观察者时状态发生了变化，则可能会导致并发问题。因此，在使用观察者模式时需要小心处理并发问题。
  4. 对象的生命周期问题：观察者模式中的主题对象和观察者对象之间可能存在生命周期的问题。如果观察者对象在主题对象的生命周期内保持活动状态，这可能会导致一些不必要的问题



### 5 代理模式

- 静态代理

  `为其它所有对象编写代理类, 提供一种代理以控制对这个对象的访问(可以增强代码) - 外包 | 中介`

  假如一个班的同学要向老师交班费，但是都是通过班长把自己的钱转交给老师。这里，班长就是代理学生上交班费，班长就是学生的代理。

  首先，我们创建一个Person接口。这个接口就是学生（被代理类），和班长（代理类）的公共接口，他们都有上交班费的行为。这样，学生上交班费就可以让班长来代理执行。

  ```php
  /** * 创建Person接口
   * @author Gonjan
   */public interface Person {    
       //上交班费    
       void giveMoney();
   }
  ```

  Student类实现Person接口。Student可以具体实施上交班费的动作。

  ```java
  public class Student implements Person {    
      private String name;    
      public Student(String name) {        
          this.name = name;    
      }
      @Override    
      public void giveMoney() {       
          System.out.println(name + "上交班费50元");    
      }
  }
  ```

  StudentsProxy类，这个类也实现了Person接口，但是还另外持有一个学生类对象，由于实现了Peson接口，同时持有一个学生对象，那么他可以代理学生类对象执行上交班费（执行giveMoney()方法）行为。

  ```java
  /** * 学生代理类，也实现了Person接口，保存一个学生实体，这样既可以代理学生产生行为
   * @author Gonjan
   *
   */public class StudentsProxy implements Person{    
       //被代理的学生    
       Student stu;
      public StudentsProxy(Person stu) {        
          // 只代理学生对象        
          if(stu.getClass() == Student.class) {            
              this.stu = (Student)stu;        
          }    
      }
      //代理上交班费，调用被代理学生的上交班费行为    
       public void giveMoney() {        
           stu.giveMoney();    
       }
   }
  ```

  下面测试一下，看如何使用代理模式：

  ```cpp
  public class StaticProxyTest {    
      public static void main(String[] args) {        
          //被代理的学生张三，他的班费上交有代理对象monitor（班长）完成        
          Person zhangsan = new Student("张三");
              //生成代理对象，并将张三传给代理对象        
          Person monitor = new StudentsProxy(zhangsan);
              //班长代理上交班费        
          monitor.giveMoney();    
  	}
  } 
  ```

- 动态代理

  不事先为每个需要代理的类写代理类, 而是在运行时动态的创建对应的代理类。实质上也就是通过反射技术, 在运行时判断是否需要代理, 如果需要代理的就使用反射获取对应的类再加以控制。



### 6 适配器模式（Adapter Pattern）

一种结构型设计模式，用于将一个类的接口转换成另一个客户端所期望的接口。它允许不兼容的接口之间进行协同工作，使得原本由于接口不匹配而无法合作的类能够一起工作。

适配器模式涉及以下几个角色：

1. 目标接口（Target Interface）：客户端所期望的接口，定义了客户端可以使用的方法。
2. 适配器（Adapter）：适配器是一个实现了目标接口的类。它包装了一个已有的类（被适配者）的实例，并将客户端的请求转发给被适配者。
3. 被适配者（Adaptee）：被适配者是已经存在的类，其接口与目标接口不兼容。适配器通过封装被适配者，将其接口转换为目标接口。

适配器模式的工作流程如下：

1. 客户端通过与目标接口进行交互，调用目标接口中定义的方法。
2. 适配器接收客户端的请求，并将其转发给被适配者。
3. 被适配者执行相应的操作，并将结果返回给适配器。
4. 适配器将被适配者的返回结果转换为客户端期望的格式，并将其返回给客户端。

适配器模式的优点包括：

- 解决接口不兼容问题：适配器模式允许不兼容的接口进行协同工作，使得原本无法合作的类能够一起工作。
- 可以重用现有的类：适配器模式可以重用已经存在的类，而无需修改其源代码。
- 灵活性和扩展性：通过适配器模式，可以灵活地添加新的适配器来适配不同的类和接口，从而提高系统的扩展性。

**使用场景**

1. `Java集合框架` 中的适配器模式：Java提供了一组集合框架接口（如List、Set、Map），以及它们的具体实现类（如ArrayList、HashSet、HashMap）。这些接口和实现类之间存在一定的差异，但通过适配器模式，我们可以使用适配器类（如Arrays.asList()、Collections类中的方法）将一个集合类型转换为另一个集合类型，以满足特定的需求。
2. Java IO中的适配器模式：Java IO库中的InputStream和OutputStream是字节流的抽象类，而Reader和Writer是字符流的抽象类。它们之间的接口不同，但通过适配器模式，我们可以使用InputStreamReader和OutputStreamWriter等适配器类，将字节流适配为字符流，以便处理字符数据。
3. Swing GUI编程中的适配器模式：在Swing中，事件处理是通过监听器（Listener）来实现的。由于监听器通常需要实现多个方法，为了简化使用，Swing提供了适配器类，如WindowAdapter、MouseListenerAdapter等。这些适配器类允许我们只需实现感兴趣的方法，而无需实现其他方法。
4. JDBC中的适配器模式：JDBC（Java Database Connectivity）是Java访问数据库的标准接口。在JDBC中，提供了一组接口以及相关的适配器类，如Connection、Statement、ResultSet等。这些适配器类允许我们通过实现特定的接口方法，与不同的数据库进行交互。
5. ArrayAdapter和BaseAdapter等Android框架中的适配器模式：在Android开发中，适配器模式经常用于将数据适配到列表视图（ListView）、网格视图（GridView）等控件中。Android提供了一些适配器类，如ArrayAdapter和BaseAdapter，用于将数据源适配到列表视图中显示。



### 7 MVC 和 MVVM 的区别

- MVC

  - Model: 通常模型对象负责**在数据库中存取数据**。处理数据的crud
  - View: 处理数据显示和用户输入的部分, 通常依据模型数据创建
  - Controller: 控制器负责从视图读取数据，控制用户输入，并将数据发送给模型。

- MVVM

  - Model: 代表数据模型（Vue的data），**数据和业务逻辑**都在Model层中定义；
  - View: 代表UI视图，负责**数据的展示**（Vue的el）；
  - ViewModel: 一个对象，负责**监听 Model 中数据的改变**并且**控制View视图的更新**，处理用户交互操作；

- 区别

  MVVM 和 MVC都是一种设计思想; MVVM 与 MVC 最大的区别在于, MVVM 数据和模型之间存在绑定关系, 数据会自动刷新。

  其实现了 View 和 Model 的自动同步, 当 Model属性改变时，不用手动操作 Dom 元素去改变 View 的显示, 该属性对应 View 的显示会自动改变, 也即

  <img src="imgs/86732b9278e74d6c857d72ea77995d2dtplv-k3u1fbpfcp-zoom-in-crop-mark1512000.image" alt="image.png" style="zoom:50%;" />



### 8 设计模式七大原则

`单一职责` 一个类只负责一个职责

`开放关闭` 对扩展开放对修改关闭

`里氏替换` 子类可以扩展父类的功能，但不能改变父类原有的功能。

`依赖倒转` 面向接口编程, 建立接口交由前端、后端编写, 不影响进度。

`接口隔离` 避免依赖无用接口, 类对类依赖尽量建立于最小接口之上

`迪米特法则` 只与直接相连的类、对象、接口通信

`组合复用` 尽量使用合成/聚合的方式，而不是使用继承(抽象出接口)



## 数据库

### 1 数据库引擎 innodb 和 myisam 的区别

- **innodb**

  `支持事务` `默认行级锁` `支持外键` `删改性能更优` `innodb 聚簇与非聚簇索引都有 `

  支持MySQL事务，具有提交，回滚和崩溃恢复功能能够更加安全的保护用户数据；支持行级锁，提高多用户并发和性能；支持外键，维护数据完整性。  *应用: 事务、并发要求高、外键约束*

- **myisam**

  `不支持事务` `默认表级锁` `不支持外键` `查询性能更优` `MyisAM 引擎没有聚簇索引`
  
  占用空间较小，支持表级锁，能够限制读写工作的负载的性能，查询效率较高，常用于只读场景。    *应用: 读写操作少、不需要事务、简单数据结构*



### 2 Oracle 与 MySQL 的区别

- **Oracle**

  `商用需要许可证` `功能强、可拓展, 更适合大型企业商用` `需要更高的系统资源` `数据安全性更高` `以设置用户权限、访问权限、读写权限` `成熟的性能诊断调优工具` 

- **MySQL**

  `开源可免费、可商用` `轻量级, 适合中小型企业` `系统资源要求低` 低 无 `主要为慢查询日志`



### 3 MySQL 的执行流程

- 在打开客户端后，最初需要和 SQL服务器建立连接，账号认证和校验权限。

- 认证后，客户端发生查询 SQL脚本 给服务器

- 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段。

- 服务器端进行 SQL解析、预处理，再由优化器生成对应的执行计划。

- MySQL 根据优化器生成的执行计划，再调用存储引擎的API来执行查询。

- 将结果返回给客户端。

<img src="imgs/sql_execute.png" alt="在这里插入图片描述" style="zoom:50%;" />





### 4 事务隔离级别 | 事务的 ACID 特性 | 实现原理

- **问题**
  
  - 脏读: 一个事务读取了另一个事务未提交的数据
  - 不可重复读: 事务两次读取的数据不一致  - 数据不一致
  - 幻读: 事务两次读取数据库，两次读取结果的条数不同(查询到了第一次不存在的数据) - 数目不一致
  
- **事务隔离级别**
  
  - 读未提交: 一个事务可以读到其他事物未提交的数据 
  - 读已提交: 一个事务可以读到其它事务提交的数据  避免 `脏读`
  - 可重复读: 一个事务两次读取到的数据相同  避免 `脏读` `不可重复读`
  - 串行化: 读取时加共享锁, 修改时加排它锁,效率最低。  避免 `脏读` `不可重复读` `幻读`
  
- **ACID 特性**
  
  - A(Atomicity - 原子性): 事务要么做要么不做
  - C(Consistency - 一致性): 事务执行的结果必须是使数据库从一个一致性状态变成另一个一致性状态。*张三向李四转100元，转账前和转账后的数据是正确的状态，这就叫一致性，如果出现张三转出100元，李四账号没有增加100元这就出现了数据错误，就没有达到一致性。*
  - I(Isolation - 隔离性): 事务的执行不能干扰其他事务
  - D(Durability - 持续性): 事务一旦完成，对数据库的修改是永久的
  
- **原理**

  日志、锁、MVCC 等机制
  
- **MySQL 默认隔离级别**

  可重复读: 一个事务两次读取到的数据相同  避免 `脏读` `不可重复读`



### 5 MVCC 特性

*背*: `MVCC 是数据库中一种多版本并发控制逻辑。它会对每个事务设定一个版本号也即事务id, 通过隐藏字段存储。这时根据当前操作事务的id 与 ReadView 中的 m_ids(活跃事务ID)的最小值和最大值进行比较, 如果小于最小值则可见, 大于则不可见, 在此中间则根据当前事务ID是否位于m_ids中以及是否等于创建该ReadView的id判断, 如果不位于m_ids中或等于creator_id则可见, 其余不可见。然后根据ReadView的结果, 得到结果。`

> **Multi-Version Concurrency Control （多版本并发控制）**: 一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。MySQL 数据库管理系统使用的一种并发控制机制，它允许多个事务同时读取数据库中的数据，而不会出现读写冲突。 `解决 脏读、不可重复读、幻读`
>
> 通俗的讲，数据库中同时存在多个版本的数据，并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在，在某个事务对其进行操作的时候，需要查看这一条记录的隐藏列事务版本id，比对事务id并根据事物隔离级别去判断读取哪个版本的数据。数据库隔离级别**读已提交、可重复读** 都是基于MVCC实现的，相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。   [Link](https://juejin.cn/post/7016165148020703246#heading-30)

- **关键点**

  - 事务版本号: 事务开启前, 都会获取一个自增长的事务ID, 根据ID判断事务执行先后顺序。

  - 隐式字段: 对于InnoDB存储引擎，每一行记录都有两个隐藏列**trx_id**、**roll_pointer**，如果表中没有主键和非NULL唯一键时，则还会有第三个隐藏的主键列**row_id**。

    | 列名         | 是否必须 | 描述                                             |
    | ------------ | -------- | ------------------------------------------------ |
    | row_id       | 否       | 单调递增的行ID，不是必需的，占用6个字节。        |
    | trx_id       | 是       | 记录操作该数据事务的事务ID                       |
    | roll_pointer | 是       | 这个隐藏列就相当于一个指针，指向回滚段的undo日志 |

  - undo log: **回滚日志**，用于记录数据被修改前的信息。在表记录修改之前，会先把数据拷贝到undo log里，如果事务回滚，即可以通过undo log来还原数据。

    可以这样认为，当delete一条记录时，undo log 中会记录一条对应的insert记录，当update一条记录时，它记录一条对应相反的update记录。

    undo log 用途？

    1. 事务回滚时，保证原子性和一致性。
    2. 用于MVCC快照读。

  - 版本链: 多个事务并行操作某一行数据时，不同事务对该行数据的修改会产生多个版本，然后通过回滚指针（roll_pointer），连成一个链表，这个链表就称为**版本链**。(实质上就是多个事务执行事务完成后得到的不同版本随机链接起来)

  - 快照读: 读取的是记录数据的可见版本（有旧的版本）。不加锁,普通的select语句都是快照读,如：

    ```sql
    select * from core_user where id > 2;
    ```

  - 当前读: 读取的是记录数据的最新版本，显式加锁的都是当前读

    ```csharp
    select * from core_user where id > 2 for update;
    select * from account where id>2 lock in share mode;
    ```

  - Read View

    事务执行SQL语句时，产生的读视图。实质上就是根据:

      m_ids:当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。

      min_limit_id:表示在生成ReadView时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。

      max_limit_id:表示生成ReadView时，系统中应该分配给下一个事务的id值。

      creator_trx_id: 创建当前read view的事务ID

    *判断当前事务 trx_id 是否在 ReadView 之前|之后完成, 则可见|不可见。在两者中间根据情况讨论。*

    **Read view 匹配条件规则**:

    1. 如果数据事务ID `trx_id < min_limit_id`，表明生成该版本的事务在生成Read View前，已经提交(因为事务ID是递增的)，所以该版本可以被当前事务访问。
    2. 如果`trx_id>= max_limit_id`，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。
    3. 如果 `min_limit_id =<trx_id< max_limit_id`,需腰分3种情况讨论

    - 如果`m_ids`包含`trx_id`,则代表Read View生成时刻，这个事务还未提交，但是如果数据的`trx_id`等于`creator_trx_id`的话，表明数据是自己生成的，因此是**可见**的。
    - 如果`m_ids`包含`trx_id`，并且`trx_id`不等于`creator_trx_id`，则 ReadView生成时，事务未提交，并且不是自己生产的，所以当前事务也是**看不见**的；
    - 如果`m_ids`不包含`trx_id`，则说明你这个事务在Read View生成之前就已经提交了，修改的结果，当前事务是能看见的。

- 原理分析

  - 查询一条记录，基于MVCC，是怎样的流程

    1. 获取事务自己的版本号，即事务ID
    2. 获取Read View
    3. 查询得到的数据，然后Read View中的事务版本号进行比较。
    4. 如果不符合Read View的可见性规则， 即就需要Undo log中历史快照;
    5. 最后返回符合规则的数据

    InnoDB 实现MVCC，是通过 ` Read View + Undo Log` 实现的，Undo Log 保存了历史快照，Read View可见性规则帮助判断当前版本的数据是否可见。

  - 当一个事务对数据库进行修改时，MySQL不会直接修改原始数据，而是将其标记为删除，并创建一个新版本的数据。新版本的数据会被加上新的创建时间和事务ID。

  - 当一个事务查询数据时，MySQL会根据该事务ID和创建时间来确定该事务能够看到哪些数据版本。如果该事务的开始时间早于某个数据版本的创建时间，则该事务不能看到该数据版本。

  - 当一个事务提交时，MySQL会将该事务的所有修改操作应用到数据库中，并将其事务ID与当前时间一起记录在数据库的undo日志中，用于回滚操作。

**MVCC 机制的好处是可以允许并发的读取和写入，提高数据库的并发性能。同时，MVCC也提供了高度的隔离性，保证了事务之间的数据不会相互影响。**



### 6 慢 SQL 优化

> SELECT COUNT(*) FROM yield 查询慢 -> 没有使用到索引, 加了 `WHERE id > 0` 则快了

*定位慢 SQL* -> `Explain 分析执行计划` -> *profile 耗时分析* -> `optimizer trace 分析详情`

- **慢 SQL 定位**

  `通过慢查询日志定位慢 SQL,` 

- **EXPLAIN**

  `通过执行计划分析索引和IO开销, 定位原因。`  *一般来说， 我们需要保证查询至少达到 range 级别， 最好达到ref*

  ```sql
  explain select * from user where id > 1;
  ```

  | 列名          | 含义                                                         |
  | ------------- | ------------------------------------------------------------ |
  | select_type   | select 子句类型                                              |
  | partitions    | 匹配的分区                                                   |
  | type          | 访问类型，即怎么找数据行的方式(ALL, index, range, ref, eq_ref, const, system, NULL  从左到右效率越来越高) |
  | possible_keys | 能使用的索引                                                 |
  | key           | 预测使用的索引                                               |
  | key_len       | 索引使用的字节数                                             |
  | ref           | 连接匹配条件                                                 |
  | rows          | 估算出所查到的数据行数                                       |
  | filtered      | 通过条件过滤出的行数所占百分比估计值，1~100，100表示没有做任何过滤 |
  | Extra         | 该列包含MySQL解决查询的详细信息                              |

  慢 SQL 的常见原因：

  - **索引使用问题，通过两个字段分析**

    ```
    possible_keys(能用到的索引) | key(实际用到的索引)
    ```

    - 没有使用索引
    - `理论上用到了 - 实际用到的`
    - 优化器选择了错误索引
    - 没有实现覆盖索引

  - **I/O开销问题，通过两个字段分析**

    ```
    filtered(有效行数/扫描行数比值) | rows(执行当前查询要遍历的行数)
    ```

    - 扫描的行数过多
    - 返回无用列且无用列有明显I/O性能开销(比如text、blob、json 等类型）

- **PROFILE**

  `show profile 分析实际SQL执行过程中的资源消耗情况, 进一步分析慢SQL。`

  后续执行的SQL语句都会记录其资源开销，包括 IO，上下文切换，CPU，Memory、执行耗时 信息。

- **Optimizer Trace**

  `分析优化器如何选择执行计划, 如何实际执行SQL语句。`

- **优化方案**

  **不使用子查询**

  ```text
  SELECT * FROM t1 WHERE id (SELECT id FROM t2 WHERE name='hechunyang');
  ```

  在MySQL5.5版本中，内部执行计划器是先查外表再匹配内表，如果外表数据量很大，查询速度会非常慢

  再MySQL5.6中，有对内查询做了优化，优化后SQL如下

  ```text
  SELECT t1.* FROM t1 JOIN t2 ON t1.id = t2.id;
  ```

  但也仅针对select语句有效，update、delete子查询无效，所以生产环境不建议使用子查询

  **避免函数索引**

  ```text
  SELECT * FROM t WHERE YEAR(d) >= 2016;
  ```

  即使d字段有索引，也会全盘扫描，应该优化为：

  ```text
  SELECT * FROM t WHERE d >= '2016-01-01';
  ```

  **使用IN替换OR**

  ```text
  SELECT * FROM t WHERE LOC_ID = 10 OR LOC_ID = 20 OR LOC_ID = 30;
  ```

  非聚簇索引走了3次，使用IN之后只走一次：

  ```text
  SELECT * FROM t WHERE LOC_IN IN (10,20,30);
  ```

  **LIKE双百分号无法使用到索引**

  ```text
  SELECT * FROM t WHERE name LIKE '%de%';
  ```

  应优化为右模糊

  ```text
  SELECT * FROM t WHERE name LIKE 'de%';
  ```

  **增加LIMIT M,N 限制读取的条数避免数据类型不一致**

  ```text
  SELECT * FROM t WHERE id = '19';
  ```

  应优化为

  ```text
  SELECT * FROM t WHERE id = 19;
  ```

  **分组统计时可以禁止排序**

  ```text
  SELECT goods_id,count(*) FROM t GROUP BY goods_id;
  ```

  默认情况下MySQL会对所有GROUP BY co1，col2 …的字段进行排序，我们可以对其使用

  ```text
  ORDER BY NULL
  ```

  **禁止排序，避免排序消耗资源**

  ```text
  SELECT goods_id,count(*) FROM t GROUP BY goods_id ORDER BY NULL;
  ```

  **去除不必要的ORDER BY语句**

  **优化表结构 - 表拆分**

  **总结**

  总的来说，我们知道慢查询的SQL后，优化方案可以做如下尝试：
  
  1. SQL语句优化，尽量精简，去除非必要语句
  2. 索引优化，让所有SQL都能够走索引
  3. 如果是表的瓶颈问题，则分表，单表数据量维持在2000W（理论上）以内
  4. 如果是单库瓶颈问题，则分库，读写分离
  5. 如果是物理机器性能问题，则分多个数据库节点



### 7 聚簇与非聚簇索引(二级索引)

- **聚簇索引**

  找到了索引就找到了需要的数据，那么这个索引就是聚簇索引，所以主键就是聚簇索引，修改聚簇索引其实就是修改主键。

- **非聚簇索引**

  索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询, 非聚簇索引也叫做辅助索引。

- **区别**

  索引与数据是否放在一起。 聚簇 - 在一起; 非聚簇 - 不在一起

  主键一定是聚簇索引, 其它普通索引需要区分SQL场景，当SQL查询的列就是索引本身时，我们称这种场景下该普通索引也可以叫做聚簇索引。



### 8 MySQL 的索引类型 | 种类 | 索引失效 | 联合索引

> 速背:
>
> - 按存储方式:  聚簇和非聚簇
> - 按索引方法:  BTree | Hash
> - 按索引类型:  主键、唯一、常规、联合、全文、空间索引

MySQL 使用 Innodb 引擎, 底层由 B+ 树实现, 索引可以加快数据查询的速度。

- **索引方法**

  - BTree索引: 常见和默认的索引方法。

    `B+ 树` `适合范围查询`   用于需要支持范围查询、排序和部分键值匹配的场景，如在查询中使用`<`、`>`、`BETWEEN`等操作符，或者需要按名称、日期等进行排序。

  - Hash 索引

    `HashTable` `适合等值查询`  用于需要快速的等值查询(A=B)的场景，如根据主键或唯一键进行查找。它在处理大量数据时，尤其是具有高基数的列（即不重复值较多）时，性能较好。但是，哈希索引不适用于范围查询、排序和部分键值匹配。

- **索引类型**

  主键索引(PRIMARY KEY): 某一个属性组可以标识一条记录。

  唯一索引(UNIQUE): 避免同一个表中某些数据列重复。

  常规索引(INDEX): 快速定位数据

  联合索引(UNION INDEX): 多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。遵循最左前缀法则

  全文索引(FULLTEXT): 主要用来查找文本中的关键字，而不是直接与索引中的值相比较。

  空间索引(Spatial): 用于存储和查询具有空间属性的数据，例如地理位置和几何图形。

  - **主键索引和唯一索引的区别?**

    `主键索引`: *不允许NULL* *只允许有一个* *聚簇索引* 

    `唯一索引`: *允许NULL* *可以有多个* *非聚簇索引*

- **索引失效**

  `索引列参与运算(需要全表扫描再执行)` `索引列上存在函数或表达式` `以 % 开头的 Like 模糊查询，索引失效` 

  `类型隐式转换` - 参数类型与字段类型不匹配，导致类型发生了隐式转换，索引失效

  `OR 左右某个列没做索引` - or 左右单列做索引, 索引列会生效, 但是未索引的列依旧会回表, 索引失效

  `索引两列作比较` - id、age都做索引但是比较之后就会造成索引失效 

  `key is not null 导致索引失效` - 查询条件使用is null时正常走索引，使用is not null时，不走索引

  `not in 非主键索引失效` - 查询条件使用not in时，如果是主键则走索引，如果是普通索引，则索引失效

  `联合索引 - 违反最左前缀法则` [Link](https://juejin.cn/post/7069562982711164965)

  - 最左前缀法则

    

    - *= 和 in 可以乱序*: 比如 a = 3 and b = 4 and c = 5 建立 （a，b，c）索引可以任意顺序。

    - *是否使用联合索引的前缀列*: 如索引 A、B、C, 使用 A | AB | ABC 均可使用联合索引, BC 则不可以, 因为不符合最左前缀 - 同时ABC的顺序可以乱序只要包含即可

    - *范围查询（> ， < ，between，like）右边失效*: 联合索引遇到范围查询就终止匹配使用范围条件时。
    
      如 a = 3 or b = 4 or c = 5 建立 （a，b，c）索引只会匹配到 a = 3 则停止使用索引
    
      如 a = 3 and b = 4 and c > 5 and d = 6，建立（a,b,c,d）索引，则 d 索引失效;建立（a,b,d,c）索引, 则索引生效且 a，b，d 的顺序可以随意调换。
    
  - 原因: 索引结构为 B+ 树, 联合索引建立的顺序就是索引的顺序。如建立(a,b,c,d)索引, 索引会保证数据有序优先级为 a>b>c>d , 后置的字段需要前置字段提供有序才成立, 因此需要最左前缀法则来保证。

- **索引级别**

  `system > const > eq_ref > ref > range > index > ALL`



### 9 undo | redo | binlog | 写入机制 | 持久化方式 | MySQL 日志

**MySQL持久化**: 使用日志来持久化, 主要方式包括 `Binlog` `Redolog` (描述见前述)

Binlog 和 Redo Log在MySQL中有不同的作用和使用方式。Binlog主要用于数据恢复、主从复制和增量备份等场景，而 Redo Log主要用于崩溃恢复和保证事务的持久性。

- `Undolog（回滚日志）`

  *撤销写入性操作* Undolog 用于处理事务的回滚操作, 保证 **原子性**。记录对数据库增删改的撤销日志, 以便在需要时可以撤消事务的更改。

- `Redolog（重做日志）`

  *记录事务提交的操作* Redolog 用于确保事务的 **持久性**（durability）。当事务提交时，相关的数据修改操作将被记录在重做日志中。重做日志的目的是在数据库崩溃或意外关闭后，通过重新执行日志中的操作，将数据恢复到崩溃之前的状态。 *数据恢复 持久性* 

- `Binlog（二进制日志）`

  *记录写入性操作* Binlog 是 MySQL 中的二进制日志文件，用于记录数据库的所有更改操作。它包含了对数据库执行的所有更新、插入、删除等操作的日志记录。 *主从复制 数据恢复 增量恢复*

**binlog 与 redo log 的基本区别**

1. 使用方式不一样
   binlog 是用作人工恢复数据，redo log 是 MySQL 自己使用，用于保证在数据库崩溃时的事务持久性。

2. 存储方式不一样

   binlog 存储逻辑日志(SQL语句); redolog 存储物理日志(物理页的变化)  `"Page 42:image at 367,2; before:'ke';after:'ca'"`

3. 所属不一样

   binlog 是 MySQL 的 Server 层实现的, 所有引擎都可以使用; redo log 是 InnoDB 引擎特有的

4. 写入逻辑不一样

   redo log 文件是固定大小的，是循环写的，写满了会从头继续写，而 binlog 是追加写的，写满了再新建文件接着写。

**写入机制**

- **Binlog**

  MySQL服务器将Binlog的事件写入到Binlog文件中，文件以一定大小（由参数 *binlog_size_limit* 控制）进行切割。Binlog文件的写入可以采用同步或异步方式进行，可以通过参数*sync_binlog* 来配置同步方式的策略，如每次事务 *提交时同步* 或 *每秒同步* 等。

- **Redolog**

  MySQL引擎层将Redo Log的物理修改操作写入到RedoLog缓冲区中，然后定期将缓冲区中的内容刷新到磁盘的RedoLog文件中。Redo Log的刷新可以采用同步或异步方式进行，可以通过参数*innodb_flush_log_at_trx_commit* 来配置同步方式的策略，如 *每次事务提交时同步* 或 *每秒同步* 等。



### 10 MySQL 索引使用 B+ 树?

`树高较低-比较矮胖` - *高度为3~4层B+树可存储50亿数据, 查询效率高, IO次数少*

`排序效率高` - *最优排序效率的数据结构*

`更利于范围查询和排序` - *B+ 树叶子结点构成链表, 方便范围查询和排序*



### 11 MySQL 刷盘

> 刷盘 = 持久化 = 写入物理磁盘

- 日志刷盘

  `Binlog 刷盘` `Redolog 刷盘`

- BufferPool 刷盘

  缓冲池是一块内存区域用于提高数据库的读写性能, InnoDB首先将更改写入缓冲池，然后按照一定的策略将数据刷新到磁盘。

- 刷盘策略

  `脏页刷盘` 当 Buffer Pool 中的内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。将内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。 时机: buffer pool内存不足; 系统空闲时; MySQL正常关闭时



### 12 快照读和当前读

- **快照读**

  快照读，读取的是**快照数据**，不加锁的普通 SELECT 都属于快照读。

- **当前读**

  当前读就是读的是**最新数据**，而不是历史的数据，加锁的 SELECT，或者对数据进行增删改都会进行当前读。



### 13 MySQL是怎么解决幻读问题的

[Linkl](https://www.cnblogs.com/wudanyang/p/10655180.html)

- **多版本并发控制（MVCC）（快照读/一致性读）** 

  采用多版本并发控制，靠保存数据快照实现。

  原理: 将历史数据存一份快照，所以其他事务增加与删除数据，对于当前事务来说是不可见的。 `快照读`

- **next-key 锁 （当前读)**

  next-key 锁包含两部分

  - 记录锁（行锁）
  - 间隙锁

  原理: 将当前数据行与上一条数据和下一条数据之间的间隙锁定, 划定可见范围, 保证此范围内读取的数据是一致的。



### 14 MySQL 加锁方式

在MySQL中，可以通过使用锁来控制并发访问数据库的行为。MySQL支持多种类型的锁，包括行级锁和表级锁。以下是MySQL中常用的加锁方式：

- **行级锁**

  行级锁可以在MySQL中使用SELECT ... FOR UPDATE语句进行加锁。该语句会在查询时对选中的行进行加锁，防止其他事务同时对同一行进行修改。例如：

  ```
  SELECT * FROM table_name WHERE id = 1 FOR UPDATE;
  ```

  该语句会将id为1的行加上行级锁，直到当前事务提交或回滚之前，其他事务无法对该行进行修改。

- **表级锁**

  表级锁可以在MySQL中使用LOCK TABLES语句进行加锁。该语句会将整个表加上锁，防止其他事务对该表进行修改。例如：

  ```
  LOCK TABLES table_name WRITE;
  ```

  该语句将table_name表加上写锁，其他事务无法对该表进行写操作，直到当前事务提交或回滚之后，锁才会释放。



### 15 MySQL 里面有哪些锁

- **行级锁**

  `对当前操作的行进行加锁`    特点: 开销大，加锁慢，会出现死锁。发生锁冲突的概率最低，并发度也最高。

  *行级锁分为共享锁和排他锁*

  **InnoDB 行锁算法**

  1, Record Lock（记录锁）：单个行记录上的锁。这个也是我们日常认为的行锁。

  2，Gap Lock（间隙锁）：间隙锁，锁定一个范围，但不包括记录本身（只不过它的锁粒度比记录锁的锁整行更大一些，他是锁住了某个范围内的多个行，包括根本不存在的数据）。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。该锁只会在隔离级别是RR或者以上的级别内存在。间隙锁的目的是为了让其他事务无法在间隙中新增数据。

  3，Next-Key Lock（临键锁）：它是记录锁和间隙锁的结合，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。next-key锁是InnoDB默认的锁

  上面这三种锁都是排它锁（X锁）

- **表级锁**

  `对当前操作的整张表加锁`     特点: 开销小，加锁快，不会出现死锁。发生锁冲突的概率最高，并发度也最低。

  *表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）*

- **页级锁**

  `锁定相邻的一组记录(页)`     特点: 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

- **间隙锁**

  `在索引记录之间的间隙上的锁`   特点: 保证某个间隙内的数据在锁定情况下不会发生任何变化。



### 16 两段锁协议

> 概念: 所有事务必须分两个阶段对数据项加锁和解锁。事务分两个阶段，第一个阶段是 `获得封锁` 事务可以获得任何数据项上的任何类型的锁，但是不能释放；第二阶段是 `释放封锁`，事务可以释放任何数据项上的任何类型的锁，但不能申请。  *获得锁 - 释放锁 分为两个阶段, 不可交替执行*

- **扩展阶段**

  第一阶段是获得封锁的阶段, 该阶段可以进入加锁操作，`在对任何数据进行读操作之前要申请获得S锁`，`在进行写操作之前要申请并获得X锁`，`加锁不成功，则事务进入等待状态`，直到加锁成功才继续执行。就是加锁后就不能解锁了。

- **收缩阶段**

  第二阶段是释放封锁的阶段, 当事务释放一个封锁后，事务进入封锁阶段，在该阶段只能进行解锁而不能再进行加锁操作。



### 17 count(1) | count(*) | count(列名) 的区别

**执行效果**

- `count(*)` 和 `count(1)` 直接查询符合条件的数据库表的行数，不会忽略为NULL的值。 *执行计划、效率一致* *count(1)执行计划会转化为count(\*)*
- `count(列名)` 查询符合条件的列的值不为NULL的行数, 忽略为NULL的值。 `全表所秒`

**执行效率**

- count(*) ≈ count(1) > count(id) > count(字段)



### 18 分库分表 | 水平 | 垂直 分库分表

> 分库分表: 分库分表就是为了解决由于数据量过大而导致数据库性能降低的问题，将原来独立的数据库拆分成若干数据库组成 ，将数据大表拆分成若干数据表组成，使得单一数据库、单一数据表的数据量变小，从而达到提升数据库性能的目的。

- **水平分表**

  概念: 同一个数据库内，把同一个表的数据按一定规则拆到多个表中。

  优点: 优化单一表数据量过大而产生的性能问题; 避免IO争抢并减少锁表的几率

  `等比例均匀划分`  *ID单双数* *ID取模 HASH* *根据区域、字段类型等* *数值范围 - 日期、数字范围、使用频次*

- **水平分库**

  概念: 把同一个表的数据按一定规则拆到不同的数据库中，每个库可以放在不同的服务器上。(尽可能保证等比例划分)

  优点: 解决了单库大数据，高并发的性能瓶颈; 提高了系统的稳定性及可用性。

  `等比例均匀划分`  *ID单双数* *ID取模 HASH*

- **垂直分表**

  概念: 将一个表按照字段分成多表，每个表存储其中一部分字段

  优点: 避免IO争抢、发挥热门数据的操作效率

  `根据访问频次分表` 商品ID、名称、描述 - (ID、名称) (ID、描述) 描述的字段占用空间大且访问频次低单独分割

  `根据字段占用空间大小分表`

- **垂直分库**

  概念: 按照业务将表进行分类分布到不同的数据库上面，每个库可以放在不同的服务器上，它的核心理念是专库专用。

  优点: 解耦合;能对不同业务的数据进行分级管理、维护、监控、扩展等;高并发场景下，垂直分库一定程度的提升IO、数据库连接数、降低单机硬件资源的瓶颈

  `根据业务划分分库` 商品信息表 - 



### 19 超卖解决方案

- **分布式锁**

  对数据库内的产品信息加锁

- **限流和排队**

  对请求进行限流和排队, 只拿到固定数量的请求然后分配库存



### 20 数据库连接池

> **概念**: 一种管理和复用数据库连接的技术，它通过预先创建一定数量的数据库连接保存在连接池的方法, 避免了传统方式在与数据库建立连接时发生的连接创建和销毁操作, 进而提高了数据库访问性能和资源利用率。 使用连接池，可以在应用程序启动时，并将它们保存在连接池中。当应用程序需要与数据库进行交互时，可以从连接池中获取一个可用的连接，使用完毕后将连接归还给连接池，以便其他线程或请求可以重复利用它们。

- **常用的数据库连接池组件**

  `druid` - 阿里 `DBCP` - Apache  `C3P0` - 开源 

- **项目中使用数据库连接池**

  *添加依赖* -> *配置连接池(yaml|properties)* -> *获取连接* -> *使用连接*

- **常见参数**

  *url* 数据库连接URL

  *username* 用户名

  *password* 密码

  *initialSize* 连接池初始化时创建的连接数

  *maxActive* 最大连接数，这里取值为20，表示同时最多有20个数据库连接

  *minIdle* 最小空闲连接数 

  *maxIdle* 最大空闲连接数

  *maxWait* 连接池中连接用完时,新的请求等待时间, 单位 : 毫秒



### 21 数据库关联关系 | 连接语法

- LEFT JOIN    取左表全部和右表匹配的数据, 右表没有的为 NULL

- RIGHT JOIN   取右表全部和左表匹配的数据, 左表没有的为 NULL

- INNER JOIN   取两表交集 - 左表和右表都有的数据

- FULL JOIN    取两表并集(MYSQL没有)

  将两个或多个表中的所有数据进行连接，不管是否存在匹配的值。全连接会返回所有的行，如果连接字段没有匹配的值，那么对应的字段将会填充为NULL

- **LEFT | RIGHT JOIN 查询慢的优化方法?**

  `采用小表驱动大表` - A * JOIN B, A 为小表, B 为大表

  `使用慢SQL分析 - EXPLAIN 分析执行计划和索引情况, PROFILE 分析资源使用情况, OPTIMIZER TRACE 分析数据库语句具体执行情况  `



### 22 数据库常用语法 | 函数

**语法**

`SELECT * FROM table`  查询

`INSERT INTO table(key1, key2,...,key#) VALUES(value1, value2, ... , value#)` 插入

`UPDATE table SET key1 = value1, key2 = value2` 修改

`DELETE FROM table WHERE key1 = value` 删除

`CREATE TABLE table_name` 创建表

`ALTER TABLE table_name ADD COLUMN key` 修改表结构

`DROP TABLE table_name` 删除表结构

`key (IS | IS NOT) NULL` 判断值是否为空

`ORDER BY key1 DESC, key2 ASC,...` 按书写的前后为优先级一次进行排序  ASC 升序  DESC 降序

`GROUP BY key` 按照指定的列对查询结果进行分组

`DiSTINCT key` 去重

`HAVING `   常与 GROUP BY 一起使用, 可以使用聚合函数

```
SELECT column_name(s)
FROM table_name
WHERE condition
GROUP BY column_name(s)
HAVING condition
ORDER BY column_name(s);

//以下 SQL 语句列出了每个地区的客户数量。 仅包括拥有 5 个以上客户的地区：
SELECT COUNT(CustomerID), Country
FROM Customers
GROUP BY Country
HAVING COUNT(CustomerID) > 5;
```

`UNION`   组合两个或多个 SELECT 语句的结果集 *不允许重复值*

```sql
//从 "Websites" 和 "apps" 表中选取所有不同的 country（只有不同的值）
SELECT country FROM data1
UNION
SELECT country FROM data2
ORDER BY country;
```

`UNION ALL`  组合两个或多个 SELECT 语句的结果集  *允许重复值*

```sql

SELECT City FROM Customers
UNION ALL
SELECT City FROM Suppliers
ORDER BY City;
```

`LIKE %key | _key`   用于搜索列中的指定模式 - '%' 表示零个、一个或多个字符; '_' 代表一个，单个字符

```sql
SELECT column1, column2, ...
FROM table_name
WHERE columnN LIKE pattern;
```



**聚合函数**

`COUNT(* | key)` 计算指定列的行数

`SUM(key)` 计算指定列的总和

`AVG(key)` 计算指定列的平均值

`MAX(key)` 找出指定列的最大值

`MIN(key)` 找出指定列的最小值



**相关函数**

- **字符串**

  `CONCAT(str1, str2,...,str#) AS new_str`  拼接多个字符串为一个字符串

  `SUBSTRING(value, startIndex, length)`  从字符串中提取子字符串（从位置 startIndex 开始，提取 length 个字符）

  `LEFT(value, m)`  从左到右截取value的前m个字符

  `RIGHT(value, m)`  从右到左截取value的前m个字符

  `LENGTH(value)` 获取字符串的长度

- **数值**

  `ABS(value) ` 求绝对值

  `AVG(value1, value2)` 求均值

  `数学函数` - SIN COS TAN COT LOG LOG10 LOG2 EXP 等

  `ROUND(value, m)`  四舍五入到指定的 m 位

- **日期和时间函数**

  `NOW` 表达式的平均值

  `DATE_FORMAT("2017-06-15", "%M %d %Y")` 格式化日期

  `DATE_ADD(date, INTERVAL expr unit)`   SELECT DATE_ADD(NOW(), INTERVAL 1 DAY) AS tomorrow;   

  `DATEDIFF(date1,date2)`  返回两个日期之间相差天数

- **条件函数**

  `IF(condition, value_if_true, value_if_false)`    IF(500<1000, "YES", "NO")  IF函数

  `CASE WHEN`

  ``````
  CASE
      WHEN condition1 THEN result1
      WHEN condition2 THEN result2
      WHEN conditionN THEN resultN
      ELSE result
  END;
  
  //以下 SQL 将按城市对客户进行排序。 但是，如果 City 为 NULL，则按 Country 排序：
  SELECT CustomerName, City, Country
  FROM Customers
  ORDER BY
  (CASE
      WHEN City IS NULL THEN Country
      ELSE City
  END);
  ``````

  `IFNULL(expression, alt_value)`    如果表达式为NULL，则返回指定值，否则返回表达式      SELECT IFNULL(a=1, 500);  //a=1 则返回 500

  



### 23 索引 | 视图 | 存储过程 | 触发器 创建

- **索引创建**

  `主键索引`

  ```sql
  CREATE TABLE 表名(
  -- 添加主键 (主键是唯一性索引,不能为null,不能重复,)
  字段名 类型 PRIMARY KEY,
  );
  
  ALTER TABLE 表名 ADD PRIMARY KEY ( 列名 )
  ```

  `唯一索引`

  ```sql
  CREATE TABLE 表名(
  列名 类型(长度),
  -- 添加唯一索引
  UNIQUE [索引名称] (列名)
  );
  
  create unique index 索引名 on 表名(列名(长度))
  ```

  `普通索引`

  ```sql
  create index 索引名 on 表名(列名[长度])
  ALTER TABLE 表名 ADD INDEX 索引名 (列名)
  ```

- **视图创建**

  概念: 视图是建立在表的基础上，表存储数据库中的数据，而视图只是做一个数据的展示, 不需要网络传输SQL语句 - 实质上就是查询语句套壳

  ```sql
  create view 视图名 [column_list] as select语句;
  view: 表示视图
  column_list: 可选参数，表示属性清单，指定视图中各个属性的名称，默认情况下，与SELECT语句中查询
  的属性相同
  as : 表示视图要执行的操作
  select语句: 向视图提供数据内容
  ```

- **存储过程创建**

  ```sql
  -- 1 创建
  DELIMITER $$ -- 声明语句结束符，可以自定义 一般使用$$
  CREATE PROCEDURE 过程名称() -- 声明存储过程
  BEGIN -- 开始编写存储过程
  -- 要执行的操作
  END $$ -- 存储过程结束
  
  DELIMITER $$
  CREATE PROCEDURE goods_proc()
  BEGIN
  select * from goods;
  END $$
  
  -- 2 创建
  CREATE PROCEDURE 存储过程名称(IN 参数名 参数类型)
  DELIMITER $$
  CREATE PROCEDURE goods_proc02(IN goods_id INT)
  BEGIN
  DELETE FROM goods WHERE gid = goods_id ;
  END $$
  
  -- 3 调用
  call 存储过程名
  -- 调用存储过程 查询goods表所有数据
  call goods_proc;
  ```

- **触发器创建**

  概念: 触发器（trigger）是MySQL提供给程序员和数据分析员来保证数据完整性的一种方法，它是与表事件相关的特殊的存储过程，它的执行不是由程序调用，也不是手工启动，而是由事件来触发，比如当对一个表进行操作（insert，delete， update）时就会激活它执行。

  ```sql
  delimiter $ -- 将Mysql的结束符号从 ; 改为 $,避免执行出现错误
  CREATE TRIGGER Trigger_Name -- 触发器名，在一个数据库中触发器名是唯一的
  before/after（insert/update/delete） -- 触发的时机 和 监视的事件
  on table_Name -- 触发器所在的表
  for each row -- 固定写法 叫做行触发器, 每一行受影响，触发事件都执行
  begin
  -- begin和end之间写触发事件
  end
  $ -- 结束标记
  
  -- 实例
  DELIMITER $
  CREATE TRIGGER t1
  AFTER INSERT ON orders
  FOR EACH ROW
  BEGIN
  UPDATE goods SET num = num -1 WHERE gid = 1;
  END$
  ```



### 24 数据库索引建立原则

- **选择重复度低列建立索引 | 唯一性索引**

  唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。如果使用姓名的话，可能存在同名现象，从而降低查询速度。

  `选择区分度高的列作为索引` 区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少

- **建立索引字段选择**

  为需要 `排序` `分组` `联合` `查询` 操作的字段建立索引, 加快执行速度

- **限制索引的数目**

  `如果表的数据很少, 无需建立索引` 索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。

- **尽量使用长度短的值作为索引**

  如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间肯定要比对CHAR(10)类型的字段需要的时间要多。

  `尽量使用前缀来索引` 如果索引字段值很长，最好使用值的前缀来索引。如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。

- **问题**

  **1、一个有一万行数据的表，属性列有五种值，能不能建立索引** 

  可以但不建议, 数据量太少, 建立索引反而会影响执行效率。

  **2、一个商品表，价格存在重复，能不能在该列建立索引**

  可以但不建议, 如果价格存在重复值会导致索引的选择性下降, 降低检索的效率。



### 25 数据库三大范式

1. 第一范式（1NF）：  `原子性` `消除重复` `多值依赖`  **保证表中字段的数据，不可以再拆分**  : 销售部小张 -> 销售部 小张
   - 要求数据库表中的每个列都是原子的，即不可再分; 每个表中的每个属性都必须具有原子性，不允许属性列中包含多个值或者重复组。
2. 第二范式（2NF）： `非主键列对主键的部分依赖` **保证主键可以代表非主键值** : 学号->姓名、年龄等 :->(无法确定) 课程名、课程成绩
   - 在满足 1NF 的基础上，要求表中的非主键列完全依赖于主键，而不是部分依赖。
   - 如果表中有复合主键，那么每个非主键列都必须直接依赖于全部复合主键，而不是依赖于部分主键。
3. 第三范式（3NF）： `非主键列之间的传递依赖` **保证某一非主键无法确认其余建** : 学号->班级、姓名、班主任; 存在班级->班主任的情况, 该表不符合3NF, 需要拆分
   - 在满足2NF的基础上，要求表中的非主键列之间不存在传递依赖关系。
   - 非主键列之间不能存在依赖传递，即不能有非主键列依赖于其他非主键列。



### 26 数据库事务

- **自动事务**

  MySQL默认就是自动事务管理(自动开启事务,自动提交事务),一条sql语句就是一个事务

- **手动事务**

  `start transaction`  开启事务

  `commit`    提交

  `rollback`   回滚

  以下是 MySQL 开启事务并使用事务的示例。

  ```sql
  -- 没有异常
  start transaction; -- 开启事务
  update account set money = money - 100 where name = 'zs'; -- zs钱-100
  -- 没有异常
  update account set money = money + 100 where name = 'ls'; -- ls钱 +100
  commit; -- 提交事务
  
  -- 有异常
  start transaction; -- 开启事务
  update account set money = money - 100 where name = 'zs'; -- zs钱-100
  -- 有异常
  update account set money = money + 100 where name = 'ls'; -- ls钱 +100
  rollback; -- 回滚事务
  ```

  **回滚点**

  概念: 设置一个点可以供后续失败操作返回到该位置，而不是返回所有操作，这个点称之为回滚点

  语法:  `savepoint` `rollback to` 

  案例: 以下是使用回滚点的具体数据库语句和案例, 当设置回滚点之后我们可以通过 rollback to 返回到具体的回滚点

  ```sql
  start transaction;
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  -- 以上sql语句没有问题
  savepoint abc;
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  -- 出现异常,回滚到abc回滚点位置
  rollback to abc;
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  update account set money = money - 100 where name = 'zs'; -- zs账户-100
  commit;
  ```




### 27 MySQL 主从复制

**原理**：将数据库操作通 BINLOG 传输到从数据库上，然后将这些日志重新执行，从而使从数据库和主数据库的数据保持一致。

**优点**: 故障恢复, 数据恢复 - 高可用; 设置读写分离; 备份; 

- 主库: 生成 `Binlog线程` `I/O 写操作线程`
- 从库: 生成 `I/O 线程` `SQL线程`

1. 主库写入数据到 Binlog

2. 从库侦测主库日志变化, 变化则发起IO请求获取 Binlog 指定位置之后的内容
3. 主库读取Binlog 指定位置之后的内容通过I/O线程发送给从库
4. 从库通过I/O线程接受Binlog写入到中继日志(RelayLog), 解析中继日志执行SQL同步数据



## RabbitMQ

> **概念**: RabbitMQ是一款开源用Erlang编写的消息中间件；最大的特点就是消费并不需要确保提供方存在, 实现了服务之间的高度解耦可以用它来：解耦、异步、削峰。
>
> **使用场景**:
>
> （1）服务间异步通信
>
> （2）顺序消费
>
> （3）定时任务
>
> （4）请求削峰
>
>  (5) 应用解耦

### 1 RabbitMQ 延时消息如何实现

通过消息的`延时级别（Delay Level）`来实现的。延时级别是一个预定义的参数，用于指定消息发送后的延时时间。延时级别是通过设置消息的属性来实现的。

- 延时级别

  RabbitMQ 配送的延时时间间隔有 1s，5s，10s，30s，1m，2m，3m，4m，5m，6m，7m，8m，9m，10m，20m，30m，1h，2h 对应 1,2,3,4...n, 用等级来表示时间间隔。

- Broker持久化延时消息

  Broker对于接收到的消息首先会判断一下是不是延时消息，如果是延时消息会将消息以 SCHEDULE_TOPIC_XXXX 为 topic 替换原有的 topic名称进行持久化，实现方法在CommitLog的putMessage中。

- 延时消息处理

  通过 `定时任务服务 ScheduleMessageService` 的方式不断的读取topic为SCHEDULE_TOPIC_XXXX何queueId为延时等级的消息进行消息还原处理，这样消息被还原之后消费者就可以拉取消息了。

- 消费者消费消息

原理: 设置延时参数 -> 持久化存储延时消息 -> 根据延时时间推送消息给消费者 -> 消费



### 2 重复消费 | 消息不丢失 | 幂等性 | 可靠性投递

- 重复消费

  `生产和消费阶段都会生成一个ID作为去重的依据(投递失败则重传) `

- 消息不丢失

  `持久化日志文件` 

- 幂等性

  `全局唯一ID + Redis`

- 可靠性投递

  **生产者发送确认** 和 **消费者接收确认**



### 3 RabbitMQ 和 Kafka 的区别

- **RabbitMQ**

  应用场景: `实时的，对可靠性要求较高的消息传递`

  特点: `吞吐量略低` `可靠性高` `支持事务` `需要其它组件提供负载均衡` `不支持批量操作` `推送消息到服务端` `处理完毕消息及时删除` 

  `多消费者同时从一个队列读取消息无法保证处理顺序` - 对于订单状态 创建->待支付->已支付->已完成 的严谨流式消息处理不太适用

  - **不重复消费**

    `场景`: 正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。

    `解决方案`: *消费阶段生成ID做唯一标识, 每次消费做判断*

  - **可靠性 | 可靠传输**

    `生产者丢消息` *开启MQ事务* *开启Confirm模式*(多 - 指派唯一ID发送ACK进行确认)

    `消费者丢消息` *关闭MQ自动ACK* (自动确认如果处理失败会导致消息丢失)

    `MQ丢消息` *开启MQ持久化*(持久化到磁盘就可以保证不丢失)

  - **幂等性**

    `场景`: 一个消息消费多次和消费一次的效果一样

    `解决方案`: *消费阶段生成ID做唯一标识, 每次消费做判断*

  - **有序性**: 

     `每个消息队列对应一个消费者` 

- **Kafka**

  应用场景: `活跃的流式数据，大数据量的数据处理` 

  特点: `吞吐量高` `保证消息处理顺序` `通过zookeeper提供负载均衡` `支持批量操作` `服务端手动拉取消息` `处理完毕消息保存到磁盘` 
  
  **不重复消费**: `消费写入offset, 间隔提交, 消费过就不在消费`
  
  **幂等性**: `数据库-插入数据判断存在与否决定写入|更新; Redis-只有set操作因此天然幂等`
  
  **有序性**: `指定一个Key的消息只发送到同一个分区 - 分区内有序`



### 4 确保消息正确地发送至 MQ | 确保接收方正确消费消息 | 可靠性投递

- **发送方确认模式**

  信道设置成 confirm 模式则指派唯一ID, 投递后|写入磁盘后发送确认给生产者（包含消息唯一 ID）; 如果丢失则发送nack（notacknowledged，未确认）消息

- **接收方确认机制**

  消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。



### 5 MQ 的工作模式

- **Basic简单队列模式**

  队列-消费者的 1:1 简单消费模式

  <img src="imgs/image-20231011225133727.png" alt="image-20231011225133727" style="zoom:33%;" />

- **Work 工作队列模式**

  队列-消费者的 1:* 争抢消费模式

  <img src="imgs/image-20231011225212504.png" alt="image-20231011225212504" style="zoom:33%;" />

- **publish/subscribe 发布订阅模式**

  队列-监听消费者 每个消费者有所属的监听队列, 队列发布消费者接收

  <img src="imgs/image-20231011225359170.png" alt="image-20231011225359170" style="zoom:33%;" />

- **routing 路由模式**

  生产者将消息发送到交换机根据路由key判断分配到不同的队列交由具有对应key的消费者消费 

  <img src="imgs/image-20231011225452243.png" alt="image-20231011225452243" style="zoom:33%;" />

- **topic 主题模式**

  交换机根据key使用通配符模糊匹配到对应的队列, 由队列监听者接受并进行消费



### 6 RabbitMQ基本概念
`Broker`： 简单来说就是**消息队列服务器实体**

`Producer`  消息生产者，就是投递消息的程序
`Consumer`： 消息消费者，就是接受消息的程序

`Exchange`： 消息交换机，它指定消息按什么规则，路由到哪	个队列
`Queue`：    消息队列载体，每个消息都会被投入到一个或多个队列
`Binding`：   绑定，它的作用就是把exchange和queue按照路由规则绑定起来
`Routing Key`： 路由关键字，exchange根据这个关键字进行消息投递
`VHost`：   vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部均含有独立的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 

​          vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 vhost 中）。
`Channel`： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务



写入和打开一个新段的轻量的过程叫做 refresh







## ElasticSearch

### 1 同步 MySQL 内容到 ElasticSearch

- 同步双写: 写入 MySQL，直接也同步往 ES 里写一份数据
- 异步双写: 写入 mySQL, ES 搜索再写入
- 定时写入: 写入 MySQL, 设置定时任务进行写入
- Logstash: Logstash 是一个开源的数据收集引擎，可以将数据从各种来源收集并发送到不同的目标，包括 Elasticsearch。你可以使用 Logstash 的 JDBC 输入插件来连接 MySQL 数据库，并使用 Elasticsearch 输出插件将数据发送到 Elasticsearch。配置 Logstash 来定期轮询 MySQL 数据库，读取更新的数据，并将其索引到 Elasticsearch 中。



### 2 ElasticSearch 使用 | 存储 | 内部原理

- 使用

  通过设置 ik 分词器实现单井的搜索词提示

  `查询` 查询倒排索引拿到ID，再根据ID查询到对应的数据

  `增加` 发送请求判断文档位于那个索引、分片存储

  `删除` 发送请求判断文档位于那个索引、分片删除

  `更新` 发送请求判断文档位于那个索引、分片先删除然后再添加

- 存储

  >  Elasticsearch 将数据划分为多个分片，每个分片是一个独立的倒排索引。分片可以分布在不同的节点上，并可以有多个副本以提高可用性和容错性。

  `索引` 相同类型文档的集合 *SQL 表*

  `文档` *SQL 行*

  `字段` 文档内的属性  *SQL 列*

  `映射` *SQL 表结构*

  `语句` SQL - DSL(JSON风格的请求语句)

  `倒排索引` 文档 = 数据库内的行; 词条对应多个文档(小米手机 - 文档id1、文档id1) 

  `分片` 为了实现分布式存储和搜索，Elasticsearch 将索引划分为多个分片。每个分片都是一个独立的倒排索引，包含一部分数据和索引的副本。

- 优点

  1. 数据存储：Elasticsearch 将数据划分为多个分片，每个分片是一个独立的倒排索引。分片可以分布在不同的节点上，并可以有多个副本以提高可用性和容错性。
  2. 倒排索引：Elasticsearch 使用倒排索引来加速搜索。倒排索引将每个词条映射到出现该词条的文档位置，以便快速定位包含特定词条的文档。
  3. 倒排索引的结构：每个分片的倒排索引由多个词条组成，每个词条包含词项和对应的文档位置信息。倒排索引还包含词频信息和文档频率信息，用于计算相关性和搜索结果排序。
  4. 分布式搜索：当执行搜索请求时，Elasticsearch 将查询分发到所有相关分片上，并将结果合并返回。这样可以并行处理查询，提高搜索性能。
  5. 聚合和分析：除了搜索，Elasticsearch 提供了强大的聚合和分析功能。它可以根据指定的条件对数据进行分组、求和、平均等操作，以便进行数据分析和可视化。
  6. 节点通信和协调：Elasticsearch 集群中的节点通过内部通信来协调和管理数据。节点之间交换索引信息、分片分配和复制信息，并共同决策如何处理查询和写入操作。
  7. 水平扩展和容错性：Elasticsearch 的分布式架构允许在集群中添加或删除节点，实现水平扩展和容错性。当节点加入或离开集群时，分片会自动重新分配以保持数据的平衡和可用性。
  
- **概念**

  共同点:  操作目的相同, 两者都用于使文档在索引操作后立即可供搜索。 在 ES 中添加新文档时，我们可以对索引调用 _refresh 或 _flush 操作，以使新文档可用于搜索。 

  `Refresh`   索引中的最新写入操作（包括索引、更新和删除）使之对搜索可见的操作。ES每隔1秒自动执行一次 Refresh 操作，也可以手动调用 **_refresh** API 进行刷新。

  `Flush`    将内存缓冲区的数据写入磁盘，并清空缓冲区，释放内存。默认自动执行, 可配置参数来控制 Flush 的频率和条件。



### 3 多条件查询

**条件**

- `must`: 表示所有条件都必须满足，相当于逻辑运算符 AND。
- `must_not`: 表示指定的条件不应满足，相当于逻辑运算符 NOT。
- `should`: 表示至少一个条件满足，相当于逻辑运算符 OR。

```json
{
  "query": {
    "bool": {
      "must": [
        { "match": { "field1": "value1" } },
        { "range": { "field2": { "gte": 10, "lte": 20 } } }
      ],
      "must_not": [
        { "term": { "field3": "value3" } }
      ],
      "should": [
        { "term": { "field4": "value4" } },
        { "term": { "field5": "value5" } }
      ]
    }
  }
}
```



### 4 多表查询

- **嵌套文档**

  在一个文档中嵌套另一个类型的文档。这样可以在一个查询中跨多个嵌套对象进行联合查询。但是需要注意，嵌套查询会带来一些性能开销。 `嵌套查询`

- **父子文档**

  在不同的类型之间建立父子关系。父文档和子文档之间可以通过指定的关联字段进行关联查询。父子关系可以在 Elasticsearch 中使用专门的父子类型来建模。 `has_child query`

  `has_parent query`



### 5 Elasticsearch 索引优化

[Link](https://www.cnblogs.com/hahaha111122222/p/12624662.html)

**写入调优**

`增加 flush 时间`  减小数据写入磁盘的频率，减小磁盘IO频率。



**索引性能调优**

- `设置合理的索引分片数和副本数`

  索引分片数建议设置为集群节点的整数倍, 生产环境副本数建议设置为 1。  

  设置更多分片|副本会占用更多存储空间，操作系统缓存命中率会下降，检索性能不一定提升。

- `批量写入|多线程写入`

  使用批量操作 API（如 `bulk`）进行索引和更新操作，可以减少网络开销和提高索引效率。

- `调大 refresh interval`

  增大刷新的间隔, 减少 segment 文件的创建，减少 segment 的 merge次数。

  优点: 提高写入性能   缺点: 降低实时搜索的数据更新速度

  在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置 refresh_interval，降低每个索引的刷新频率。

- `加大 Flush 设置`

  文件缓存系统中的段持久化到硬盘, 当 Translog 的数据量达到 512MB 或者 30 分钟时，会触发一次 Flush。

  index.translog.flush_threshold_size 参数的默认值是 512MB，我们进行修改。

- `配置事务日志刷新间隔`

  sync_interval 时间设置大 : 调整默认日志刷新间隔 5 秒，例如改为 60 秒, 进而优化时间消耗。



**查询性能优化**

- `分片分割调整`

  单个文档数据量大时划分多个分片, 并行处理查询请求，从而提高性能。 *按数据源划分* *按时间划分* *Hash划分* 保证等间隔

- `使用过滤器缓存和分片查询缓存`

- `避免大结果集查询`

- `使用路由 routing`

  Elasticsearch写入文档时，文档会通过一个公式路由到一个索引中的一个分片上。默认的公式如下：

  ```ini
  shard_num = hash(_routing) % num_primary_shards
  ```

  `_routing` 字段的取值，默认是 `_id` 字段，可以根据业务场景设置经常查询的字段作为路由字段。例如可以考虑将用户 id、地区作为路由字段，查询时可以过滤不必要的分片，加快查询速度。

- `避免查询深度翻页`

  搜索得太深，就会造成性能问题，会耗费内存和占用cpu。

  Elasticsearch 默认只允许查看排序前 10000 条的结果，当翻页查看排序靠后的记录时，响应耗时一般较长。使用 search_after 方式查询会更轻量级，如果每次只需要返回 10 条结果，则每个 shard 只需要返回 search_after 之后的 10 个结果即可，返回的总数据量只是和 shard 个数以及本次需要的个数有关，和历史已读取的个数无关。

- `预索引`

- `使用filter代替query`

- `数据查询量过大 - 使用滚动搜索`



- **关闭评分功能**

  评分消耗资源，如果不需要可使用 filter 过滤来达到关闭评分功能。		

- **保证版本更新**

  ES 每次更新都能带来很大的查询效率提升, 保持版本跟进。





### 6 数据类型

- **数字类型**

  long integer short byte double float half_float scaled_float unsigned_long

- **Keywords**

  keyword：适用于索引结构化的字段

- **dates**

  包括[`date`](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.10%2Fdate.html)和`date_nanos`

- **alias**

  别名

- **text**

  当一个字段是要被全文搜索的，比如Email内容、产品描述，这些字段应该使用text类型。设置text类型以后，字段内容会被分析，在生成倒排索引

- **对象关系类型**

  1. object：用于单个JSON对象
  2. nested：用于JSON对象数组
  3. join：为同一索引中的文档定义父/子关系。

- **结构化类型**

  1. geo-point：纬度/经度积分
  2. geo-shape：用于多边形等复杂形状
  3. point：笛卡尔坐标点
  4. shape：笛卡尔任意几何图形



## Java 基础

### 1 接口与抽象类的区别

- 接口

  *Interface*  *多继承*  *没有构造方法* 

  *包含抽象、默认、静态方法和常量*   JDK1.8之后接口可以包含抽象方法、默认方法、静态方法, 后两者可以有方法的实现   常量必须赋初值不能被修改

  *接口用于定义统一的操作和功能 强调特定功能的实现*

  *访问类型默认 public abstract*

- 抽象类

  *abstract* *单继承*  *有构造方法*  

  *包含抽象和其它方法和实例字段* 

  *包含抽象方法的一定是抽象类, 抽象类不一定有抽象方法*

  *抽象类适用于提供统一接口和属性, 子类需要继承父类属性和方法的场景  强调所属关系*

  *访问类型默认 default*

- 相同点

  都不能被实例化; 继承抽象类和实现接口的子类都要实现声明的抽象方法; 
  
- 应用

  接口被用于常用的功能，便于日后维护和添加删除，而抽象类更倾向于充当公共类的角色，不适用于日后重新对立面的代码修改。功能需要累积时用抽象类，不需要累积时用接口。



### 2 Java 基本类型和引用类型 | 装箱拆箱

8种基本类型: 

`byte 8 1` `short 16 2` `int 32 4` `long 64 8` `float 32 4` `double 64 8` `char 16 2` `boolean 1` (不同JVM大小不同)

其他数据类型如: 数组、类、接口、String 等在生命时不会被立即分配内存, 只是存储了内存地址。



`自动装箱`: 将基本类型赋值给对应的包装类型。 

`自动拆箱`: 将包装类型对象赋值给基本类型。

通过自动装箱、自动拆箱功能,简化基本类型变量和包装类对象之间的转换过程。

| 基本数据类型 | 对应包装类 |
| ------------ | ---------- |
| byte         | Byte       |
| short        | Short      |
| int          | Integer    |
| long         | Long       |
| float        | Float      |
| double       | Double     |
| char         | Character  |
| boolean      | Boolean    |

**为什么要有包装类型?**

1. 包装类里面有一些很有用的方法和属性，如HashCode,ParseInt

2. 基本类型不能赋 null 值，某些场合需要。

3. 基本数据类型方便、简单、高效，但泛型不支持、集合元素不支持



### 3 final | static

- **final**

  final 修饰类, 该类不可被继承;

  final 修饰方法, 该方法不能被重写;

  final 修饰变量, 基本类型值不可改变, 引用类型值可变地址不可变;

  **修饰不同类型变量**

  `基本类型`   当使用`final`修饰基本类型变量时，该变量的值不能被改变

  `引用类型`   当使用`final`修饰引用类型变量时，该变量的引用地址不能被改变，但是对象本身是可以修改的。

  ```java
  final StringBuilder sb = new StringBuilder("Hello");
  // sb = new StringBuilder("World"); // 编译错误，无法修改 final 变量的引用地址
  sb.append(" World"); // 可以修改 sb 引用的对象
  ```

- **static**

  Java类中包含: 成员变量、方法、构造器、初始化块和内部类（包括接口、枚举）5种成员。

  `static` 关键字可以修饰除了构造器外的其他4种成员。

  静态方法只能访问用 `static` 修饰的成员 

  1. 修饰方法与成员变量  

     *静态变量是在类初始化之前就在方法去的静态域中分配内存空间了* *程序运行结束时被销毁*

     static 修饰的变量是存储于方法区的, 表示类方法或者类成员变量，是所有对象所共享的。可以通过类名调用，也可以通过实例对象调用。  *无需创建对象就可以个使用这个属性*

  2. 静态代码块:

     当类被加载时，静态代码块会执行一次，因为一个类只加载一次，所以静态代码块只执行一次。通常使用静态代码块对类的成员变量进行初始化。  *优先于普通代码块先执行* *静态代码块可以给静态成员变量和静态常量进行赋值* *调用当前类的静态方法时会先执行静态代码块* *静态代码块-->普通代码块-->构造器*

  3. 修饰内部类 

     可以在不创建外部类对象的情况下被实例化。

     *静态内部类可以定义静态变量、静态常量、静态方法，普通内部类则不可以。普通内部类只可创建普通的成员变量和方法，和static有关的操作都不可使用。*

     *在其他对象中可以创建静态内部类的实例对象，例如TestStatic.ClassStatic tcs = new TestStatic.ClassStatic();*

     *静态内部类与外部类是平级, 访问需要 new*

     *静态内部类属于类, 普通内部类属于对象*



### 4 String | String、StringBuffer、Stringbuilder

- **String**

  String 类由 `final` 修饰, 所以它不可被继承。 

  *创建方式不同*

  - 直接赋值

    直接赋值方式创建 `String` 对象, 现在常量池检查是否有相同内容字符串,  有直接返回, 没有才执行创建。    `存储在字符串常量池`

  - new

    至少会创建一个对象，也有可能创建两个。使用new创建字符串时, 首先在堆中创建字符串, 再判断常量池是否有该字符串,如果有指向堆内变量; 没有则创建并指向堆内变量。  `存储在堆`

  - 区别

    直接赋值更高效, 可以节约内存和提高性能。而使用 `new` 关键字创建的字符串对象在堆内存中独立存储，适用于需要动态创建和修改字符串的情况。

  *为什么设计为不可变*

  - **性能需要**

    `常量池需要` `hashCode 缓存需要` `多线程安全` 

  - **原理**

    `私有的字符数组和hashCode变量` `所有对字符串的更改方法都是新建String实现` `final不可继承` `构造函数深拷贝`

- **String | StringBuffer | Stringbuilder 区别**

  Java 提供了 String、StringBuffer 两个类和大量的方法来封装字符串。

  String 被创建后不可变、效率低, 但复用率高; 

  StringBuffer 创建后可变、效率高, 线程安全; 

  StringBuilder 也可变、效率最高, 但线程不安全; 

  `总结`: 单线程下使用 StringBuilder 效率高; 多线程下使用 StringBuffer, 保证安全性。
  
- **String 为什么是不可变的 | StringBuilder等为什么是可变的?**

  `String 不可变性`: 通过 final 修饰且私有, 不可被继承, String 地址不可变, 其内部也没有提供修改String底层 char[] 的方法

  `StringBuilder | StringBuffer 的可变性:` 两者都继承了 *AbstractStringBuilder* 类, 该类底层依旧使用 *char []*, 同时提供了 *append() insert()* 方法等方法实现字符串的可变性, 每次扩容按照 $当前容量*2 + 2 $ 扩容, 底层通过 *Arrays.copyOf()* 返回新数组实现扩容。

- **底层**

  `字符数组` 

  ```java
  private final char value[];
  ```

- **方法**

  `翻转字符串` 

  *StringBuilder* *StringBuffer* *StringUtils*

  ```java
  new StringBuilder("sdada").reverse();
  new StringBuffer("sdada").reverse();
  StringUtils.reverse(str);
  ```





### 5  == 与 equals() 的区别 | 为什么重写 equals() 就要重写 hashCode()

- **区别**

  `==` 比较基本类型时比较值是否相等, 引用类型则比较地址是否相等; 

  `equals()` 没有重写之前与 `==` 一致, 重写后可使用 按值比较。

- **equals() 与 hashCode()**

  `hashCode` 用于获取哈希值, `equals()` 用于比较对象是否相等; 如果两个对象相等, 它们必须有相同的哈希码；若两个对象的哈希码相同, 他们却不一定相等。也就是说, equals() 比较两个对象相等时 hashCode() 一定相等, hashCode() 相等的两个对象 equqls() 不一定相等; 由于hashCode() 与 equals() 具有联动关系, equals() 重写时, hashCode() 进行重写, 使得这两个方法始终满足相关的约定。



### 6 反射 | 优缺点 | 为什么需要反射

> 提供运行时分析类以及执行类中方法的能力。通过反射可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。

- 优点

  `代码更灵活` 

- 缺点

  `性能差` `安全问题 - 无视泛型参数的安全检查 `

- 应用场景

  `Spring SpringBoot MyBatis` 动态代理通过反射获取方法并处理; MVC 架构下配置的 xml 包扫描, MyBatis 的 mapper 文件配置的扫描。



### 8 封装 | 继承 | 多态 | 面向对象

- **封装**

  `将数据和操作结合为一个不可分割的整体, 隐藏对象属性和细节, 只提供对外接口。使用者无需了解细节, 只需通过外部接口即可访问和完成操作。`

  - private: 只能被当前类内部访问
  - default: 只能被当前类和其所在包的其他类访问
  - protected: 只能被当前类和其所在包的其他类以及子类访问。
  - public: 可以被当前项目中的所有类访问

  ![img](imgs/274e6b8cc40c4c66ad93056fe6c5991b.png)

- **继承**

  `子类继承父类, 让子类对象具有父类对象的属性、方法和行为`

  Animal <- Dog   <- Cat

- **多态**

  `同一个行为具有多个不同表现形式或形态的能力`

  现实生活中，同一个方法，具体实现会完全不同。 比如：同样是调用人的"休息"方法，张三是睡觉，李四是旅游，王五是听音乐； 同样是调用人“吃饭”的方法，中国人用筷子吃饭，英国人用刀叉吃饭，印度人用手吃饭。

  1. 多态是方法的多态，不是属性的多态（多态与属性无关）。

  2. 多态的存在要有 3 个必要条件：继承，方法重写，父类引用指向子类对象。

  3. 父类引用指向子类对象后，用该父类引用调用子类重写的方法，此时多态就出现了。

     使用父类做方法的形参和返回值，是多态使用最多的场合。即使增加了新的子类，方法也无需改变，符合开闭原则。

  **重载和重写的区别 | 构造方法能不能重写**

  - 重写 `override` 

    在父子类中发生, 用于方法的拓展, 方法与参数都相同; 

  - 重载 `overload`

    在类中发生, 方法名相同参数不同。构造方法无法重写, 重写要求类名一致, 而父类和子类的构造方法名不一致, 因此无法重写。

- 面向对象 - 面向过程

  `面向过程` - C语言中实现猫吃饭这样一个动作, 面向过程可能拆解为多个函数, 猫、饭的初始化函数, 吃饭的函数, 3个函数组合就完成了功能。

  `面向对象` - Java 实现猫吃饭动作, 首先定义猫、饭这两个对象(类), 然后在猫的类中定义吃饭的方法并传递饭作为参数, 最终完成功能。 `面向过程更关注于功能的实现, 面向对象更关注于模式的设计(对象提取)便于维护` 

  面向对象有三大基础特征: **封装、继承、多态**。

  封装: 将对象的状态信息隐藏起来, 不允许外界直接访问, 只能通过暴露的接口进行操作访问, 提高代码可维护性; 

  继承: 实现代码复用的手段, 能够通过 extends 关键字继承父类的属性和方法; 

  多态: 依赖于继承, 子类可以选择重写父类方法, 也可选择直接调用父类方法实现功能的复用与拓展。



### 9 泛型 | 泛型擦除 | 通配符

> JDK1.5 之后引入泛型, 泛型可以为类型指定参数, 减少了插入对象的类型出错问题(泛型需求的为 Person, 传入其他的就会报错), 所有强制转换都是自动且隐藏的提高了代码的复用率。

- 泛型擦除

  Java 的泛型是伪泛型, 因为编译器在编译期间需要在进行擦除, 然后进行类型转换。如在代码中定义 `List<Object>` 和 `List<String>` 等类型，在编译后都会变成 `List` ，JVM看到的只是List，而由泛型附加的类型信息对JVM是看不到的。

- 泛型应用

  `项目中后端返回前端的 DATA 使用泛型指定` `ExcelUtil 类动态指定导出数据类型`

- 通配符

  - ？ 表示不确定的 java 类型
  - T (type) 表示具体的一个 java 类型
  - K V (key value) 分别代表 java 键值中的Key Value
  - E (element) 代表 Element
  - ？无界通配符 (让泛型能够接受未知类型的数据。)
  - 上界通配符 < ? extends E> (类型1指定一个数据类型，那么类型2就只能是类型1或者是类型1的子类)
  - 下界通配符 < ? super E>   (类型1指定一个数据类型，那么类型2就只能是类型1或者是类型1的父类)



### 10 内部类

- 成员内部类(非静态内部类)

  定义在类的内部, 像是外部类的一个成员，所以内部类可以拥有 private、public 等访问权限修饰; 成员内部类可以访问外部类的所有成员,（包括private）成员; 

- 静态内部类

  定义在类的内部, 在成员内部类前面加上一个 static: 静态内部类可以访问外部类的静态成员; 静态内部类当中不仅可以定义静态成员也可以定义非静态成员

- 局部(方法)内部类

  定义在方法的内部类: 局部内部类不能有访问权限修饰符; 局部内部类不能被定义为static; 局部内部类不能定义static成员; 局部内部类也可以使用 Outer.this 语法制定访问外部类成员

- 匿名内部类

  定义在代码中的类，没有类名，用于实现某个接口或者继承某个类。

  匿名内部类必须继承一个抽象类或者实现一个接口; 匿名内部类没有类名，因此没有构造方法。



### 11 Java 程序执行过程

<img src="imgs/20190328181601314-16929609377273.png" alt="在这里插入图片描述" style="zoom:67%;" />

1. 编译: 将 `.java` 文件编译为 `.class` 字节码文件

2. 加载: 类加载器将 `.class` 文件加载到内存

   **类加载机制**

   类加载模型主要经过7个阶段, 分别是: 加载、验证、准备、解析、初始化、使用、卸载。

   - 加载: 查找和导入 `class` 文件
   - 验证: 保证加载类的准确性
   - 准备: 为类变量分配内存并设置类变量初始值
   - 解析: 把类中的符号引用转换为直接引用
   - 初始化: 对类的静态变量，静态代码块执行初始化操作
   - 使用: JVM 开始从入口方法开始执行用户的程序代码
   - 卸载: 当用户程序代码执行完毕后，JVM 便开始销毁创建的 Class 对象。

   **双亲委派模型**

   - 原理是: 在加载一个类时首先委托上一级的类加载器加载, 如果上一级也有上级, 则继续往上委托; 如果该类委托上级没有加载, 子加载器则尝试加载该类。 原因: 可以避免一个类被重复加载; 保证类库 API 不会被修改, 也即用户自定义的类与 API 一致时会报错而非加载。

3. 执行: 找到程序入口 `main()` 函数, 执行字节码指令



### 12 Java 的4种引用方式

- 强引用: 以 NEW 关键字创建的引用都是强引用。被强引用引用的对象永远*不会回收*。
- 软引用: 以 `SoftReference` 类创建的对象为软引用。*系统内存不足时会被GC回收*。
- 弱引用: 以 `WeakReference` 类创建的对象为弱引用。*无论内存充足与否都会被GC回收*
- 虚引用: 以 `PhantomReference` 类创建的对象为虚引用。它是最弱的引用类型, *被GC回收时会得到通知*。



### 13 类的实例化过程

类的实例化主要包括以下步骤: 

1. 类加载: 将类加载到虚拟机的内存中。
2. 分配内存: 给类分配足够的内存空间。
3. 初始化: 对类分配的内存空间进行初始化 - 赋0。
4. 执行构造器: 对变使用构造器进行初始化操作。
5. 返回对象: 实例化完成后返回指向对象的引用。



### 14 常见线程安全集合有哪些

`Vector`：是一个动态数组，实现了List接口，并且线程安全。  `synchronized`
`Hashtable`：实现了Map接口，是一个键值对的集合，线程安全。  `synchronized`
`Stack`：是一个后进先出（LIFO）的集合，线程安全。
`ConcurrentHashMap`：是对HashMap的改进，实现了ConcurrentMap接口，线程安全。
`CopyOnWriteArrayList`：是一个可变的、线程安全的ArrayList，使用了写时复制的策略，适用于读多写少的场景。 
`CopyOnWriteArraySet`：是一个可变的、线程安全的Set，也使用了写时复制的策略。
`Properties`



### 15 拷贝 | 克隆 | 属性拷贝方法

- **浅拷贝**

  原对象和克隆对象不同,但对象内的成员引用相同

  `手动复制` `Object的clone()方法` `BeanUtils.copyProperties` 

- **深拷贝**

  原对象和克隆对象不同,且对象内的成员引用也不同

  `序列化和反序列化` `SerializationUtils.clone(oldUser);` `Json序列化和反序列化` 



### 16 fail-fast(快失败) - fail-safe(安全失败)

- fail-fast

  直接在容器上进行遍历，在遍历过程中，一旦发现容器中的数据被修改了，会立刻抛出异常遍历失败 `不支持并发修改(不允许遍历时修改数据)`

- fail-safe

  在容器的克隆上遍历，对容器内容的修改不影响                                                                                                                                                                                                                                                                遍历。java.util.concurrent包下的容器都是安全失败的,可以在多线程下并发使用,并发修改。采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。  `允许并发修改(允许遍历时修改数据)，但是 无法保证在迭代过程中获取到最新的值`



### 17 Java 类中的变量、方法、对象的保存位置

- `局部变量` - *栈*
- `成员变量、对象和对象数组` - *堆*
- `本地方法` - *本地方法栈*  本地方法: 就是一个为了提供C/C++程序功能的接口, 声明为 Java 的 Native Method, 但是实现是其它语言。
- `字段、方法、修饰符` - *方法区*
- `常量` - *常量池*

- `基本类型` - *栈中直接分配内存*
- `引用类型` - *引用在栈, 存储在堆*



### 18 JDK proxy 和 cglib 的区别

JDK proxy 和 CGLIB 是Java中两种常用的动态代理实现方式。

- **JDK proxy**

  **实现 InvocationHandler 接口使用**

  `Java自带` `拦截器+反射实现` `直接操作字节码` `实现调用简单`  *基于接口进行代理* (InvocationHandler拦截+代理)  JDK动态代理的代理类字节码在创建时，需要业务实现类所实现的接口作为参数。如果业务实现类是没有实现接口而是直接定义业务方法的话，就无法使用JDK动态代理了。

  ```java
  // Java Proxy
  // 1. 首先实现一个InvocationHandler，方法调用会被转发到该类的invoke()方法。
  class LogInvocationHandler implements InvocationHandler{
  	...
  	private Hello hello;
  	public LogInvocationHandler(Hello hello) {
  		this.hello = hello;
  	}
  	@Override
  	public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
  		if("sayHello".equals(method.getName())) {
  			logger.info("You said: " + Arrays.toString(args));
  		}
  		return method.invoke(hello, args);
  	}
  }
  // 2. 然后在需要使用Hello的时候，通过JDK动态代理获取Hello的代理对象。
  Hello hello = (Hello)Proxy.newProxyInstance(
      getClass().getClassLoader(), // 1. 类加载器
      new Class<?>[] {Hello.class}, // 2. 代理需要实现的接口，可以有多个
      new LogInvocationHandler(new HelloImp()));// 3. 方法调用的实际处理者
  System.out.println(hello.sayHello("I love you!"));
  ```

- **CGLib**

  **实现代理器接口同时需要Enhancer类继承该类来使用**

  `第三方`  `性能高` `基于 ASM`(ASM - Java 字节码操作框架)  *基于继承实现代理* (MethodInterceptor+Enhancer)   通过定义 Enhancer 对象继承代理对象实现动态代理, 因此被代理类不能被关键字 final 修饰，如果被 final 修饰，再使用 Enhancer 设置父类时会报错，动态代理的构建会失败。

  ```java
  // CGLIB动态代理
  // 1. 首先实现一个MethodInterceptor，方法调用会被转发到该类的intercept()方法。
  class MyMethodInterceptor implements MethodInterceptor{
    ...
  	@Override
  	public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
  		logger.info("You said: " + Arrays.toString(args));
  		return proxy.invokeSuper(obj, args);
  	}
  }
  // 2. 然后在需要使用HelloConcrete的时候，通过CGLIB动态代理获取代理对象。
  Enhancer enhancer = new Enhancer();
  enhancer.setSuperclass(HelloConcrete.class);
  enhancer.setCallback(new MyMethodInterceptor());
  
  HelloConcrete hello = (HelloConcrete)enhancer.create();
  System.out.println(hello.sayHello("I love you!"));
  ```

- **区别**

  JDK 动态代理是实现了被代理对象所实现的接口，CGLib是继承了被代理对象。 JDK和CGLib 都是在运行期生成字节码,JDK是直接写Class字节码，CGLib 使用 ASM 框架写Class字节码，Cglib代理实现更复杂，生成代理类的效率比JDK代理低。JDK 调用代理方法，是通过反射机制调用,CGLib 是通过FastClass机制直接调用方法,CGLib 执行效率更高。cglib是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，*



### 19 类加载过程 | 规则 | 类加载器 | 双亲委派模型

**规则**

不会一次性加载所有的类，而是根据需要去动态加载。也就是说，大部分类在具体用到的时候才会去加载，这样对内存更加友好。对于已经加载的类会被放在 `ClassLoader` 中。在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。

**类加载器**

- **`BootstrapClassLoader`(启动类加载器)**：最顶层的加载类，由 C++实现，通常表示为 null，并且没有父级，主要用来加载 JDK 内部的核心类库（ `%JAVA_HOME%/lib`目录下的 `rt.jar`、`resources.jar`、`charsets.jar`等 jar 包和类）以及被 `-Xbootclasspath`参数指定的路径下的所有类。

- **`ExtensionClassLoader`(扩展类加载器)**：主要负责加载 `%JRE_HOME%/lib/ext` 目录下的 jar 包和类以及被 `java.ext.dirs` 系统变量所指定的路径下的所有类。

- **`AppClassLoader`(应用程序类加载器)**：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。

**双亲委派模型**

- **原理**

  在加载一个类时首先委托上一级的类加载器加载, 如果上一级也有上级, 则继续往上委托; 如果该类委托上级没有加载, 子加载器则尝试加载该类。 

  `优点` 可以避免一个类被重复加载; 保证类库 API 不会被修改, 也即用户自定义的类与 API 一致时会报错而非加载。

  <img src="imgs/class-loader-parents-delegation-model.png" alt="类加载器层次关系图" style="zoom:67%;" />

**类加载过程**

`加载`   `验证` `准备` `解析`   `初始化` `使用` `卸载`     

- 加载: 查找和导入 `class` 文件
   - 验证: 保证加载类的准确性
   - 准备: 为类变量分配内存并设置类变量初始值
   - 解析: 把类中的符号引用转换为直接引用
   - 初始化: 对类的静态变量，静态代码块执行初始化操作
   - 使用: JVM 开始从入口方法开始执行用户的程序代码
   - 卸载: 当用户程序代码执行完毕后，JVM 便开始销毁创建的 Class 对象。

<img src="imgs/image-20230919135811155.png" alt="image-20230919135811155" style="zoom: 33%;" />



### 20 int 与 Integer 

- **Integer**

  `int的包装类-对象` `默认值是null` `提供额外的方法` 

  - **缓存机制**

    `仅在自动装箱有用` 

    通过 IntegerCache 类提供缓存支持, 支持 -128 到 127 之间的自动装箱过程。这样在如下场景下会从缓存中取对象而非创建新对象。

    ```
    Integer j = 100;
    Integer b = 100;		//缓存中取
    ```

  

- **int**

  `基本类型` `默认值是0` `直接存储数值` 

- **比较**

  *两个通过new生成的Integer变量永远是不相等 - 因为new生成的是两个对象，其内存地址不同*

  *Integer变量和int变量比较时，只要两个变量的值是向等的，则结果为true - 拆箱值比较*

  *非new生成的Integer变量和new Integer()生成的变量比较时，结果为false - 非new生成的Integer变量指向的是java常量池中的对象，而new Integer()生成的变量指向堆中新建的对象*

  ```
  Integer i = new Integer(100);
  Integer j = 100;
  System.out.print(i == j); //false
  ```

  *对于两个非new生成的 Integer对象，进行比较时，如果两个变量的值在区间-128到127之间，则比较结果为true，如果两个变量的值不在此区间，则比较结果为false* 缓存机制

  原因： java在编译Integer i = 100 ;时，会翻译成为Integer i = Integer.valueOf(100)。而java API中对Integer类型的valueOf的定义如下，对于-128到127之间的数，会进行缓存，Integer i = 127时，会将127这个Integer对象进行缓存，下次再写Integer j = 127时，就会直接从缓存中取，就不会new了。

  

### 21 字符串直接量和 new 的区别

- 字符串直接量

  创建时, 先在字符串池中查找是否存在值为"ab"的字符串对象。如果存在，就将引用指向该对象；如果不存在，则在字符串池中创建一个新的字符串对象，并将引用指向它。

- new String(A)

  创建时, 常量池内没有则创建新对象, 再在堆内存区新建一个对象引用常量池中的对象, 返回堆内对象 `2`; 有则在堆中新建一个对象引用常量池中的对象 `1`。



### 22 Lambda 表达式

`流式编程`   *Arrays.stream(nums).foreach(System.out::println*  可以使用 *func().func1().func2()* 的方式完成编码

> 概念: `函数式编程(函数编程思想) - 通过一段代码完成面向对象想要做的代码量` 起源于匿名类, 在代码中可以通过匿名类的方式创建对象, 这种方式简化了类的创建过程, 如 `Comparator` 接口可以直接通过内部类创建实例。允许把函数作为一个方法的参数（函数作为参数传递进方法中）, 使用 Lambda 表达式可以使代码变的更加简洁紧凑。

**语法**

- 小括内的语法与传统方法参数列表一致，没有参数就留空，有多个参数就用逗号分隔   书写的内容和接口中的抽象方法的参数列表一致

- 【->】 是新引入的语法格式，代表指向动作

- 大括号内的语法与传统方法体要求一致   书写的内容和实现接口中的抽象方法体一致

```java
(参数列表） -> {代码}
```

**使用条件**

通过接口实现,  规定接口中只能有一个需要被实现的方法（即只能有一个抽象方法），不是规定接口中只能有一个方法，这也称之为“函数式接口”, 想定义函数式接口需要使用`@FunctionalInterface`注解，要求接口中的抽象方法只有一个。  *接口中不使用 default|static 的方法都是抽象方法, 如果使用Lambda表达式只能声明一个抽象方法*



*使用匿名类方式对 words 排序*

```java
import java.util.*;

public class Main {
    public static void main(String args[]) {
        ArrayList<String> words = new ArrayList<>();
        words.add("A");
        words.add("BC");
        words.add("DBAD");
        words.add("CDD");
        words.add("EA");
        //根据字符串的长度 短->长 排序
        words.sort(new Comparator<String>() {
            @Override
            public int compare(String s1, String s2) {
                return Integer.compare(s1.length(), s2.length());
            }
        });
        for (String word : words) {
            System.out.println(word);
        }
    }
}
```

*使用 Lambda 方式对 words 排序*

```java
import java.util.*;

public class Main {
    public static void main(String args[]) {
        ArrayList<String> words = new ArrayList<>();
        words.add("A");
        words.add("BC");
        words.add("DBAD");
        words.add("CDD");
        words.add("EA");
        //根据字符串的长度 短->长 排序
        words.sort((s1, s2) -> Integer.compare(s1.length(), s2.length()));
        for (String word : words) {
            System.out.println(word);
        }
    }
}
```

*实例*

```java
// 1. 不需要参数,返回值为 5  
() -> 5  
// 2. 接收一个参数(数字类型),返回其2倍的值  
x -> 2 * x  
// 3. 接受2个参数(数字),并返回他们的差值  
(x, y) -> x – y  
// 4. 接收2个int型整数,返回他们的和  
(int x, int y) -> x + y  
// 5. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void)  
(String s) -> System.out.print(s)
```



### 23 定时任务概率出现堆内存溢出

- **产生原因**
  1. `执行定时任务频率过高` ：如果定时任务的触发频率非常高，例如每秒触发多次，并且任务本身执行逻辑较为复杂，可能会导致堆内存无法及时释放。随着时间的推移，堆内存可能会被持续占用，最终触发堆内存溢出。
  2. `定时任务内存泄漏` ：如果定时任务中存在内存泄漏的情况，即任务执行过程中产生的对象无法被垃圾回收器正确回收，那么随着定时任务的不断触发，堆中的内存使用量将不断增加，最终导致堆内存溢出。
  3. `定时任务过长时间运行`：如果定时任务的执行时间非常长，可能会导致堆内存长时间被占用。如果堆内存的使用超过了系统的承载能力，就会触发堆内存溢出。
- **解决办法**
  1. `调整定时任务的触发频率`：根据实际需求和系统资源情况，合理设置定时任务的触发频率，避免过高的频率导致内存无法及时释放。
  2. `优化定时任务的执行逻辑`：确保定时任务的执行逻辑简洁高效，避免不必要的资源占用和内存泄漏问题。
  3. `增加堆内存的大小`：如果确定定时任务的执行需要较大的内存空间，可以适当增加Java虚拟机的堆内存大小，以确保足够的内存供定时任务使用。可以通过调整启动参数中的`-Xmx`和`-Xms`选项来设置堆内存大小。
  4. `注意资源的释放`：在定时任务执行完毕后，及时释放占用的资源，避免产生内存泄漏问题。



### 24 Java 堆和栈的区别

**堆**

`存储对象和对象数组` 

`由所有线程共享`

`数组实现的完全二叉树结构`

`可通过JVM启动参数调整`

`由GC分配和释放`

**栈**

`存储方法调用、局部变量和操作数` `由栈帧组成, 存放局部变量表、返回值、返回地址等` 

`线程私有的`

`先进先出结构` 

`大小固定, JVM启动时分配` 

`自动分配和释放` 随着方法的调用和返回而进行



### 25 位运算

`&`  按位与 : 两个位都为1时，结果才为1   0101 & 1010 => 0000

`|`  按位或 : 两个位都为0时，结果才为0   0101 | 1010 => 1111

`^`  异或   : 两个位相同为0，相异为1    0101 ^ 1010 => 1111 

`~`  按位非 : 0变1，1变0    1010 -> 0101

`<<` 左移   : 各二进位全部左移若干位，高位丢弃，低位补0        *2

`>>` 右移   : 各二进位全部右移若干位，对无符号数，高位补0      /2



### 26 IO 流

> Java IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。
>
> - `InputStream`/`Reader`: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。
> - `OutputStream`/`Writer`: 所有输出流的基类，前者是字节输出流，后者是字符输出流。



- **字节流**

  `InputStream`  用于从源头（通常是文件）读取数据（字节信息）到内存中

  `OutputStream`  用于将数据（字节信息）写入到目的地（通常是文件）

- **字符流**

  不知道编码类型容易乱码

  `Reader`  从源头（通常是文件）读取数据（字符信息）到内存中

  `Writer`  用于将数据（字符信息）写入到目的地（通常是文件）

- **字节缓冲流**

  *缓冲的意义*  IO 操作是很消耗性能的，缓冲流将数据加载至缓冲区，一次性读取/写入多个字节，从而避免频繁的 IO 操作，提高流的传输效率。

  `BufferedInputStream`  内部维护了一个缓冲区(字节数组), 从源头（通常是文件）读取数据（字节信息）到内存时从缓冲区读取, 减少IO次数。

  `BufferedOutputStream`  将数据（字节信息）写入到目的地（通常是文件）时从缓冲区读取写入, 减少IO次数。

- **字符缓冲流**

  同样维护了缓冲区(字节数组)用来减少IO次数

  `BufferedReader`   `BufferedWriter`  

- **字节流 <=> 字符流 转换**

  `InputStreamReader`  字节流到字符流的桥梁：它读取字节，并使用指定的字符集将其解码为字符。它的字符集可以由名称指定，也可以接受平台的默认字符集。

  `OutputStreamWriter`  字符流通向字节流的桥梁：用指定的字符集将字符编码为字节。它的字符集可以由名称指定，也可以接受平台的默认字符集。

  ```java
  import java.io.*;
  
  public class ByteToCharExample {
      public static void main(String[] args) throws Exception {
          // 将字节流转换为字符流
          FileInputStream input = new FileInputStream("input.txt");
          InputStreamReader reader = new InputStreamReader(input, "UTF-8");
  
          // 读取字符数据
          char[] buffer = new char[1024];
          int length = reader.read(buffer);
          String text = new String(buffer, 0, length);
          System.out.println(text);
  
          // 将字符流转换为字节流
          FileOutputStream output = new FileOutputStream("output.txt");
          OutputStreamWriter writer = new OutputStreamWriter(output, "UTF-8");
  
          // 写入字符数据
          String message = "Hello, World!";
          writer.write(message);
          writer.flush();
          writer.close();
      }
  }
  ```

  

### 27 值传递 和 引用传递

**值传递**（pass by value）:   在调用函数时将 `实际参数` 复制一份传递到函数中，在函数内对参数进行修改，不会影响到实际参数。

**引用传递**（pass by reference）:   在调用函数时将 `实际参数的地址` 直接传递到函数内，在函数内对参数所进行的修改，将影响到实际参数。

如下所示: 如果想在函数内修改, 必须要调用引用对象自身的修改方法才可生效。

```java
import java.util.ArrayList;
import java.util.HashMap;

public class Main {
    public static void foo(String text) {
        text = "ipad";
        System.out.println("In Function: " + text);
    }

    public static void foo1(StringBuilder builder) {
        builder.append(" is great");
        System.out.println("In Function1: " + builder.toString());
    }

    public static void main(String[] args) {
        String str = "windows";
        foo(str);
        System.out.println("Main Function: " + str);
        StringBuilder sb = new StringBuilder(str);
        foo1(sb);
        System.out.println("Main Function1: " + sb.toString());
    }
}
>>>
In Function: ipad
Main Function: windows
In Function1: windows is great
Main Function1: windows is great
```



### 28 Stream 流

- 过滤：使用`filter`方法根据指定条件过滤出符合条件的元素。
- 映射：使用`map`方法将元素映射为另一种类型的元素。
- 排序：使用`sorted`方法对元素进行排序。
- 去重：使用`distinct`方法去除重复的元素。
- 聚合：使用`reduce`方法对元素进行聚合操作，如求和、求最大值等。
- 收集：使用`collect`方法将流中的元素收集到集合或其他数据结构中。



### 29 自定义注解 | 多例注解

<img src="imgs/25200814-475cf2f3a8d24e0bb3b4c442a4b44734.jpg" alt="img" style="zoom:67%;" />

**核心**: 如下所示 - Retention 配置运行时保留级别; Target 应用位置; Inherited 允许继承; 

```java
/**
 * 性别赋值
 * @author zzs
 */
@Documented
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.FIELD,ElementType.METHOD})
@Inherited
public @interface InitSex {
    /**
     * sex enum
     * @author zzs
     */
    enum SEX_TYPE {MAN, WOMAN}
    SEX_TYPE sex() default SEX_TYPE.MAN;
}

public class User {
    private String username;
    @ValidateAge(min = 20, max = 35, value = 22)
    private int age;
    @InitSex(sex = InitSex.SEX_TYPE.MAN)
    private String sex;
}
```

**多例注解**

- `@Scope`

  singleton  单实例的(单例)(默认)   ---- 全局有且仅有一个实例
  prototype  多实例的(多例)    ----  每次获取Bean的时候会有一个新的实例
  reqeust    同一次请求       ----  request：每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效
  session    同一个会话级别    ----  session：每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效

- Spring 的bean默认注入是 **单例** 的，它在Spring容器初始化的时候创建对象；

- 修改为多例 - *注意不可使用 Autowired 导入, 需要使用 Resource 导入, 否则还是单例模式*

  ```java
  @Component
  @Scope("prototype")
  ```

  

### 30 Java8 新特性

- **Lambda 表达式**：Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）
- **函数式接口**：指的是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口，这样的接口可以隐式转换为 Lambda 表达式
- **方法引用**：方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码
- **默认方法**：默认方法就是一个在接口里面有了一个实现的方法
- **Stream API**：新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。
- **Optional 类**：Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。
- **Date Time API**：加强对日期与时间的处理。
- **Nashorn, JavaScript 引擎**：Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用





## Java 集合

### 1 List | Set | Queue | Map  概述

List、Set、Queue 继承 Collection 接口， Map 单独的顶级接口

- **List** `有序可重复`

  ArrayList  对象数组实现的， 场景: 需要频繁访问元素和动态数组。  优点: 简单、支持快速访问  缺点: 插入、删除效率低
  LinedList  双向链表实现的， 场景: 需要频繁插入、删除元素。      优点: 需要频繁插入、删除元素  缺点: 访问元素时需要遍历链表, 效率低

- **Set** `不可重复`

  HashSet  哈希表实现的，数据无序。     场景: 保证不重复   优点: 插入、删除和查找复杂度均为O(1)  缺点: 不保证元素的顺序, 不支持快速访问

  TreeSet  二叉树实现的，数据自动排序。  场景: 保证不重复且对元素进行排序并保持有序   优点: 元素有序  缺点: 插入、删除和查找性能差 O(log n)

- **Queue** `有序可重复`

  PriorityQueue:  Object[] 数组来实现二叉堆  场景:   优点:  缺点:  

  ArrayQueue:     Object[] 数组 + 双指针    场景:   优点:  缺点:  

- **Map** `Key 无序不可重复, value 无序可重复`

  HashMap   线程不安全，效率快，适用于单线程操作  场景: 需要根据键快速查找值的情况，不关心键的顺序   优点: 插入、删除和查找复杂度均为O(1)  缺点: 不保证顺序

  TreeMap   二叉树实现的，数据有序，HashTable 与 HashMap无序  场景: 保证排序  优点: 键有序   缺点:  插入、删除和查找复杂度均为O(log n)

  HashTable  线程安全，因为底层都加了 synchronized 关键字来确保线程同步，适用于多线程操作  场景:   优点:  缺点:  



### 2 List

- **ArrayList**

  - 底层

    Object[] 数组

  - 特性

    `有序可重复` `查找速度快, 插入删除速度慢`

  - **初始化**

    无参 - 空对象数组

    带容量参数 - 直接赋值为 容量 大小数组

  - **扩容机制**

    JDK 1.7: 创建容器时会自动创建一个长度为 10 的对象数组

    JDK 1.8: 不会立即创建数组, 而是在第一次执行 add() 方法时才创建长度为10的数组。

    默认情况下, ArrayList 扩容时会扩容为原来容量的1.5倍, 同时将原有的数据赋值到新数组中完成扩容。

- **Vector**

  - 底层

    Object[] 数组
    
  - 特性

    `线程安全`  `扩容为原来的一倍` `需要连续的内存空间`

- **LinkedList**

  - 底层

    `双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)`

  - 特性

    `查找速度慢, 插入删除速度快` `占用的内存更多`

  

### 3 Set

- **HashSet**

  - 底层

    `HashMap(数组+链表 | 数组+链表+红黑树)`

  - 特性

    `无序` `元素值允许为NULL` `不允许重复` `非线程安全` `基于HashMap实现` `JDK8之前，数组+链表;  JDK8以后，数组+链表+红黑树 - 扩容原则与 HashMap 一致`

  - 保证不重复

    使用 `hashCode` 与 `equals` 方法检测重复。一个元素, 使用 `hashCode` 判断该元素key值是否存在, 已存在则不添加; 不存在再调用 `equals` 方法判断结果, 如果依旧一样则不添加, 不一样则添加到 Set 集合。

- **LinkedHashSet**

  - 底层

    `LinkedHashMap(LinkedList)` 

  - 特性

    HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。 `按插入顺序有序`  

- **TreeSet**

  - 底层

    `TreeMap(红黑树)`

  - 特性

    `基于 TreeMap 实现(红黑树)` `有序且不重复` `依照比较器去重(不使用hashCode|equals方法)`


- 区别
  - `HashSet`、`LinkedHashSet` 和 `TreeSet` 都是 `Set` 接口的实现类，都能保证元素唯一，并且都不是线程安全的。
  - `HashSet`、`LinkedHashSet` 和 `TreeSet` 的主要区别在于底层数据结构不同。`HashSet` 的底层数据结构是哈希表（基于 `HashMap` 实现）。`LinkedHashSet` 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。`TreeSet` 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。
  - 底层数据结构不同又导致这三者的应用场景不同。`HashSet` 用于不需要保证元素插入和取出顺序的场景，`LinkedHashSet` 用于保证元素的插入和取出顺序满足 FIFO 的场景，`TreeSet` 用于支持对元素自定义排序规则的场景。



### 4 Queue

- **Deque**

  `Deque` 是双端队列，在队列的两端均可以插入或删除元素。`Queue` 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循先进先出（FIFO）规则。

- **PriorityQueue**

  - 底层

    Object[] 数组来实现二叉堆  

  - 特性

    元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。

- **ArrayQueue**

  - 底层

    Object[] 数组 + 双指针

  - 特性

    `不能存储null` `线程不安全` `不支持随机访问和随机插入数据` 



### 5 Map | HashMap

- **HashMap**

  - **底层**

    - Beafor 1.8(1.7): 数组 + 链表    *头插法* *初始容量16*
    - After  1.8:  数组 + 链表 + 红黑树  *尾插法* *第一次 put 才初始化*

  - **特性**

    `null 作为键只能有一个; 值可多个为null` `数组 + 链表 + 红黑树` `非线程安全` 

  - **PUT 流程**

    通过计算存入 KEY 的 Hash 值确定存入位置, 如果当前位置存在数据也即发生碰撞则通过链表接在一起。

    `树化:` 当链表长度达到 8 时则转为红黑树存放, 以此提高查询效率。

  - **初始化**

    `HashMap()` 初始化负载因子为 0.75

    `HashMap(initCapacity)` 创建时如果给定了容量初始值, HashMap 会将其扩充为 2 的幂次方大小

  - **扩容机制**
  
    JDK 1.7 时  HashMap 数组初始容量为 16
    
    JDK 1.8 时, 第一次 put 才初始化
    
    达到默认装载因子 0.75 时会触发 2 倍扩容。
    
    `为什么是2倍扩容?`
    
    *扩容后元素不用在频繁移动, 减少元素移动* *使元素均匀分散在 HashMap 中*
    
    初始容量为2的幂幂数，扩容后的容量也是2的幂数，则元素在新表中的位置要么不动，要么满足新位置=原长度+原位置, 可以提高元素哈希的效率,减少哈希冲突; 容量为2的幂数则可以使元素均匀的散布hashmap中，减少hash碰撞。 为了更好地分散元素在数组中的位置，减少哈希冲突的概率，提高散列性能。
    
  - 遍历  fail-fast
  
- **ConcurrentHashMap**

  - 底层    `线程安全的 HashMap`
    - Beafor 1.8: 数组 + 链表
    - After 1.8:  数组 + 链表 + 红黑树
  
- **HashTable**

  - 底层

    `数组 + 链表`

  - 扩容机制

    `Hashtable` 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。 负载因子也是 0.75

  - 初始化

    创建时如果给定了容量初始值， `Hashtable` 会直接使用你给定的大小。

  - 特性

    `线程安全` `不允许 NULL 值(key 和 value都不允许null值)` `底层为数组+链表`
    
  - 加锁机制

    对整个 Hash 表加 `synchronized`, 所有的 get/put 操作都有锁, 多线程访问只能有一个线程访问或操作对象, 类似于串行的操作导致其性能差
    
  - 遍历  fail-safe(快照遍历 - 保证安全性)

- **TreeMap**

  - 底层

    `红黑树`

  - 特性

    `基于红黑树实现` `按 Key 顺序或 Comparator 顺序有序` `不允许重复` `动态扩容`    *效率低于HashMap, 一般在需要排序的情况下使用*

- **LinkedHashMap**

  - 底层

    `HashMap(数组+链表+红黑树) + LinkedList(HashMap操作数据结构, LinkedList维护插入元素的先后顺序)`

  - 特性

    `插入顺序有序` `HashMap(数组+链表+红黑树) + LinkedList`

  

### 6 HashMap 如何解决哈希冲突

`链地址法`

- **链地址法**

  `将所有冲突元素按照链表存储`

- 再散列法(二次哈希)

  `再次使用一个不同的哈希算法再计算一次`

- 开放地址法

  `寻找下一个为空的数组下标,而后将冲突元素存储`



### 7 Collection 下数据结构的特点 | 应用场景

- ArrayList  `查询快, 插入删除慢` *日常使用, 结构简单使用方便*
- Set   `不允许重复` *用于需要保证不重复的数据存储*
- Queue `先进先出` *用于符合该特点的数据存储*
- Stack `先进后出` *栈*
- TreeSet | TreeMap `按照key的字典顺序来排序（升序）` *需要保证有序的数据存储*
- HashTable | ConcurrentHashMap  `线程安全`



### 8 HashMap

- **底层**

  - Beafor 1.8: 数组 + 链表  *头插法*
  - After 1.8:  数组 + 链表 + 红黑树 *尾插法*

- **特性**

  `null可以作为键，这样的键只有一个 - 可以有一个或多个键所对应的值为null` `数组 + 链表 + 红黑树` `非线程安全` *链地址法解决冲突*

- **PUT 流程**

  通过计算存入 KEY 的 Hash 值确定存入位置, 如果当前位置存在数据也即发生碰撞则通过链表接在一起。

  `树化:` 当链表长度达到 8 时则转为红黑树存放, 以此提高查询效率。

- **初始化**

  创建时如果给定了容量初始值, `HashMap` 会将其扩充为 2 的幂次方大小

- **扩容机制**

  HashMap 数组初始容量为 16, 达到默认装载因子 0.75 时会触发 2 倍扩容。

  `为什么是2倍扩容?`

  *扩容后元素不用在频繁移动, 减少元素移动* *使元素均匀分散在 HashMap 中*

  初始容量为2的幂幂数，扩容后的容量也是2的幂数，则元素在新表中的位置要么不动，要么满足新位置=原长度+原位置, 可以提高元素哈希的效率,减少哈希冲突; 容量为2的幂数则可以使元素均匀的散布hashmap中，减少hash碰撞。 为了更好地分散元素在数组中的位置，减少哈希冲突的概率，提高散列性能。

- **线程安全**

  `HashMap 线程安全的吗？如果不是该如何解决？`

  - 使用 HashTable 效率低
  - 使用 Collection 下的 synchronizedXX() 方法包装 HashMap
  - 使用 ConcurrentHashMap 

  `为什么不安全?`

  - JDK1.7 HashMap线程不安全体现在：

    *死循环-死链*:  线程A、B都在一条链表上扩容且两者指向和next都为同一节点, 此时B挂起A执行扩容后头插导致链表倒置, B唤醒后B.next变为了其前面的节点形成了环。

    ​	<img src="imgs/7c304dd6cf6c440bb4330d14c9c9b3af.png" alt="在这里插入图片描述" style="zoom:33%;" />

    *数据丢失*:   AB在同一条链表上执行, A挂起 - B执行修改了链表, A唤醒又修改了链表

  - JDK1.8 HashMap线程不安全体现在：数据覆盖。 *多个线程在put操作时, 线程A在判重完毕后被阻塞, 线程B拿到时间片在A插入的位置插入数据, A拿回时间片直接插入引起数据的覆盖。*

- **常规问题**

  `负载因子`

  - **概念**

    负载因子是一个介于0和1之间的值，表示散列表中已存储元素数量与散列表容量之间的比率。在HashMap中，当已存储元素数量超过负载因子与容量的乘积时，就会触发扩容操作，即重新调整散列表的大小，以提供更多的存储空间。 *默认为0.75*

  - **调大负载因子的问题**

    会导致散列表的平均链表长度增加，可能会影响HashMap的性能和效率。 *内存占用大* *冲突可能高* *扩容频率低*

  `为什么使用红黑树`

  - *查找性能高*：红黑树是一种自平衡的二叉搜索树，具有较快的查找性能。在红黑树中，查找、插入和删除操作的时间复杂度都是 $O(log n)$ ，相较于链表的线性查找$O(n)$，红黑树可以更高效地处理大量元素。
  - *平衡性好*：红黑树的自平衡性质保证了树的高度相对较低，即使在极端情况下，也能保持较快的查找性能。红黑树通过旋转和重新着色等操作来保持平衡，确保树的高度在可控范围内，避免出现极度不平衡的情况。
  - *插入和删除性能优秀*：红黑树的插入和删除操作相对链表来说更高效。当需要插入或删除元素时，红黑树通过调整树的结构和重新着色来保持平衡，不会像链表一样需要遍历整个链表来进行插入或删除操作

- **源码**

  **PUT 流程**
  
  <img src="imgs/v2-bb8ee0ee1c0cc51537ae5f8e02038102_1440w.webp" alt="img" style="zoom:67%;" />
  
  调用 `put()` 会再调用 `putVal()` 方法(计算 key 的 hashcode)
  
  ```java
  public V put(K key, V value) {
       return putVal(hash(key), key, value, false, true);
  }
  ```
  
  `putVal`
  
  ```java
  final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                     boolean evict) {
          Node<K,V>[] tab; Node<K,V> p; int n, i;
          //1. 如果数组是空的，那么就通过 resize 方法来创建一个新的数组。
          if ((tab = table) == null || (n = tab.length) == 0)
              n = (tab = resize()).length;
          //2. i 为待插入的位置, 取得 hashcode 后将 tab[insert]元素赋值给 p, 判断该位置是否存在元素, 不存在则直接插入(newNode) - 存在则下一步
          if ((p = tab[i = (n - 1) & hash]) == null)
              tab[i] = newNode(hash, key, value, null);
          //3. 处理 Hash 冲突
          else {
              Node<K,V> e; K k;
              //3.1  判断 tab[i] 中的元素是否与插入的key一样，若相同那就直接使用插入的值p替换掉旧的值e
              if (p.hash == hash &&
                  ((k = p.key) == key || (key != null && key.equals(k))))
                  e = p;
              //3.2 判断插入的数据结构是红黑树还是链表，在这里表示如果是红黑树，那就直接 putTreeVal 到红黑树中。
              else if (p instanceof TreeNode)
                  e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
              //3.3 数据结构是链表
              else {
                  // 遍历数组
                  for (int binCount = 0; ; ++binCount) {
                      // 3.3.1 p 是链表尾部节点, p.next 插入新节点
                      if ((e = p.next) == null) {
                          p.next = newNode(hash, key, value, null);
                          // 如果长度超过 8, 触发树化
                          if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                              treeifyBin(tab, hash);
                          break;
                      }
                      //如果存在使用新的value替换掉旧的
                      if (e.hash == hash &&
                          ((k = e.key) == key || (key != null && key.equals(k))))
                          break;
                      p = e;
                  }
              }
              if (e != null) { // existing mapping for key
                  V oldValue = e.value;
                  if (!onlyIfAbsent || oldValue == null)
                      e.value = value;
                  afterNodeAccess(e);
                  return oldValue;
              }
          }
          ++modCount;
         // 判断一下实际存在的键值对数量 size 是否大于阈值threshold, 如果大于那就开始扩容了
          if (++size > threshold)
              resize();
          afterNodeInsertion(evict);
          return null;
      }
  ```



**扩容流程**

<img src="imgs/v2-f43eafe4e5d4d7616f885335fc185f3d_1440w.webp" alt="img" style="zoom:67%;" />

当容量不足时触发或者生成新 HashMap 的时候也会触发

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    //第一部分：扩容: 超过了数组的最大容量，那么就直接将阈值设置为整数最大值，然后如果没有超过，那就扩容为原来的2倍，这里要注意是oldThr << 1，移位操作来实现的
    if (oldCap > 0) {
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    //第二部分：设置阈值   如果阈值已经初始化过了，那就直接使用旧的阈值
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    // 如果没有初始化，那就初始化一个新的数组容量和新的阈值
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    //第三部分：旧数据保存在新数组里面
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                //只有一个节点，通过索引位置直接映射
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                //如果是红黑树，需要进行树拆分然后映射
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else {
                    //如果是多个节点的链表，将原链表拆分为两个链表
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    //链表1存于原索引
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    //链表2存于原索引加上原hash桶长度的偏移量
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```



**Hash 冲突解决**

hash值 = hashcode 异或 16(异或运算能够是的计算出来的hash比较均匀)  *链地址法*

```java
static final int hash(Object key) {
     int h;
     return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```



### 9 ConcurrentHashMap

- **结构**

  <img src="imgs/image-20230916145052214.png" alt="image-20230916145052214" style="zoom:80%;" />

- **底层**  `数组+链表+红黑树` 

- **线程安全**

  - 1.7 - 分段锁(segments) 

    `底层实现`: *ReentrantLock*  将整个 HashMap 分段分为 Segment 与 HashEntry 控制多段的并发。

    **为什么使用分段锁 | 设计理念?**

     : 通过维护 Segment 数组(独立的HashMap), 不同的 Segment 可以由不同的线程同时访问，能够减小锁的粒度, 降低并发时的锁竞争情况, 从而提高并发性能。

  - 1.8 - 槽锁(头结点锁)

    `底层实现`: *CAS + sychronized* 对 HashMap 数组的头节点加锁。 CAS 用于头节点为空时的初始化; sychronized 用于头结点非空时的并发控制。

    **为什么使用 synchronized?**

     : *减少内存开销* 加入多个分段锁浪费内存空间, 使用ReentrantLock则需要节点继承AQS来获得同步支持，增加内存开销，而1.8中只有头节点需要进行同步。

       *内部优化* synchronized 由 JVM直接支持能够在运行时作出相应的优化措施：锁粗化、锁消除、锁自旋等。

    生产环境中， map 在放入时竞争同一个锁的概率非常小，分段锁反而会造成更新等操作的长时间等待; 为了提高 GC 的效率



### 10 ArrayList

- **底层**

  Object[] 数组

- **特性**

  `有序可重复` `查找速度快, 插入删除速度慢`

- **初始化**

  无参 - 空对象数组

  带容量参数 - 直接赋值为 容量 大小数组

- **扩容机制**

  JDK 1.7: 创建容器时会自动创建一个长度为 10 的对象数组

  JDK 1.8: 不会立即创建数组, 而是在第一次执行 add() 方法时才创建长度为 10 的数组。

  默认情况下, ArrayList 扩容时会扩容为原来容量的1.5倍, 同时将原有的数据赋值到新数组中完成扩容。

- **源码**

  `构造函数`

  无参构造 - 赋值空对象数组

  带容量的构造 - 容量大于 0 则直接创建 capacity 对象; =0则直接赋值空数组; 其它抛出不合法

  ```java
  public ArrayList() {
      this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
  }
  
  public ArrayList(int initialCapacity) {
      if (initialCapacity > 0) {
          this.elementData = new Object[initialCapacity];
      } else if (initialCapacity == 0) {
          this.elementData = EMPTY_ELEMENTDATA;
      } else {
          throw new IllegalArgumentException("Illegal Capacity: "+
                                             initialCapacity);
      }
  }
  ```

  `新增`

  *add()* => *ensureCapacityInternal()* 确保数组空间足够, 是否需要初始化数组 => *ensureExplicitCapacity()* 修改次数, 判断是否需要扩容 => *grow()* 扩容

  ```java
  public boolean add(E e) {
      ensureCapacityInternal(size + 1);  // Increments modCount!!
      elementData[size++] = e;
      return true;
  }
  
  //确保数组空间足够 - 如果为空则创建长度为10的数组返回; 不为空则进入扩容流程
  private void ensureCapacityInternal(int minCapacity) {
      if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
          minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
      }
  
      ensureExplicitCapacity(minCapacity);
  }
  
  //修改次数+1; 如果需要的最小空间>数组空间 grow() 扩容
  private void ensureExplicitCapacity(int minCapacity) {
      modCount++;
  
      // overflow-conscious code
      if (minCapacity - elementData.length > 0)
          grow(minCapacity);
  }
  
  //当前的数组已使用空间（size）加1之后 大于数组长度，则增大数组容量，扩大为原来的1.5倍
  private void grow(int arg0) {
      int arg1 = this.elementData.length;
      int arg2 = arg1 + (arg1 >> 1);		// 右移/2 => (1+0.5) = 1.5 倍
      if (arg2 - arg0 < 0) {
          arg2 = arg0;
      }
      if (arg2 - 2147483639 > 0) {
          arg2 = hugeCapacity(arg0);
      }
      //复制数组空间
      this.elementData = Arrays.copyOf(this.elementData, arg2);
  }
  ```

  

  





## JUC

> 基本概念:
>
> - 原子性
>   定义: 即一个操作或者多个操作要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。
> - 可见性
>   定义: 指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
> - 有序性
>   定义: 即程序执行的顺序按照代码的先后顺序执行。



### 1 Synchronized | ReentrantLock | ThreadLocal

> Java 常用的锁和原理: `Synchronized` 和 `Lock` 

#### 1) Synchronized

`Sychronized ` 保证原子性(要么都做要么都不做)、资源可见性(变量的修改可以被其他线程看到)、有序性(指令按固定顺序执行 - volatile)。 

特点: `用于修饰静态方法(等于给类加锁)、代码块、普通方法`; `关键字`; `synchronized 可以自动释放`; `synchronized 不可以判断加锁状态`; `非公平锁`; `粒度较粗`

1. 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象； 
2. 修饰一个非静态方法，作用范围 整个方法，获取的是对象级别的锁，不同实例对象之间互不影响。 *不同对象获取锁不受限制*
3. 修改一个静态的方法，作用范围 整个静态方法，获取的是类级别的锁，所有实例对象之间互斥。   *该类不同对象互斥的获取锁*
4. 修改一个类，其作用的范围是synchronized后面括号括起来的部分，作用的对象是这个类的所有对象。 

**synchronized 的底层原理**

- 底层

  `Java对象头` 对象头包含锁字段, 支持锁升级。

- **核心**：

  ​	对象头和内置锁。每个Java对象都包含对象头, 内置标记字段表示对象是否被锁定, *synchronized* 同步实质上就是对对象头的锁标记进行操作, 多线程获取对象时会判断锁标记。Java同时内置了互斥锁, 保证同一时间只能有一个线程获取到锁, 通过底层的操作系统提供的互斥机制实现。


- **加锁和解锁必须原子操作吗**: 

  ​	加锁和解锁可以看做一个整体的事务, 需要保证原子性(原子操作)。当一个线程进入临界区访问临界资源并加锁, 此时线程挂掉就无法自行解锁, 所以需要原子性来保证事务的一致性, 防止多线程执行中的并发问题。



synchronize 的用法及原理:

synchronized 能够保证同一时间只有一个线程执行该代码, 保证线程安全。它能够在执行完毕或出现异常后自动释放锁。底层是采用Java对象头来存储锁信息的,并且还。在JVM里的实现都是 基于进入和退出 Monitor 对象来实现方法同步和代码块同步。synchronized 加在普通方法上, 锁当前实例; 加在静态方法, 锁当前类的从class对象;加在代码块上, 则需要在关键字后面的小括号里, 显式指定一个对象作为锁对象。





#### 2) Lock

*Lock* 是一个接口, 其中继承其的类有: 读锁、写锁、可重入锁(ReentrantLock)等, 其中最常见的是 ReentrantLock。常用方法包括 `lock() 获取锁` : `unlock() 释放锁` : `tryLock() 尝试获取锁` 等。特点: `接口`; `Lock 加锁不会自动释放`; `Lock 可以通过 tryLock() 判断加锁状态`; `公平锁 | 非公平锁`; `粒度较细`

<img src="imgs/1771072-20200216201818148-1683117055-16937248890052.png" alt="img" style="zoom: 67%;" />

**Lock 的底层原理**

`AbstractQueuedSynchronizer - AQS`

`volatile 状态变量 + CAS + 自旋锁` 使用 CAS 操作访问 volatile 变量来判断锁是否被持有, 未持有则获取锁, 持有则将该线程放在 CLH 链表里边, 其中每个线程的锁不断自旋 - 也即不断判断锁是否被释放(不断判断锁是否被释放) - *实质上就是 AQS 的原理*



#### 3) ReentrantLock

`ReentrantLock` 继承了 `Lock` 接口来处理对共享对象的访问, 保证变量的互斥性和内存可见性。它的特点与 `Lock` 一致。如: `Lock 加锁不会自动释放`; `Lock 可以通过 tryLock() 判断加锁状态`; `公平锁 | 非公平锁`; `粒度较细`





#### 4) ThreadLocal

> 线程局部变量: 全称 thread local variable, 它的使用场合主要是为了解决多线程中因为数据并发产生不一致的问题。 ThreadLocal为每一个线程都提供了变量的副本，使得每一个线程在某一时间访问到的并不是同一个对象，这样就隔离了多个线程对数据的数据共享，这样的结果无非是耗费了内存，也大大减少了线程同步所带来的性能消耗，也减少了线程并发控制的复杂度。
>
> `* ThreadLocal 是 Java 中的一个线程级别的变量存储工具类，它提供了一种在多线程环境下，每个线程都拥有自己独立的变量副本的机制。 *`	
>
> **主要是为了解决多线程中因为数据并发产生不一致的问题; 同时可以保证同一个线程内, 不同方法之间的属性共享问题;每个线程都有一个 ThreadLocalMap 变量, ThreadLocalMap的存储位置是在Thread线程中。 **  [Link](https://juejin.cn/post/7042211997743579144)



ThreadLocal 是 JDK包提供的，它提供线程本地变量，如果创建一个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的一个副本，在实际多线程操作的时候，操作的是自己本地内存中的变量，从而规避了线程安全问题，如下图所示。

<img src="imgs/1368768-20190613220434628-1803630402.png" alt="img" style="zoom:50%;" />

- **实现原理**

  哈希表 - ThreadLocalMap 实现。 `get ` `set` `remove` 

  ==ThreadLocalMap中, key 存放 ThreadLocal 对象(当前线程对象), value 为要存放的线程局部变量。 get()用于获取线程自身的变量 ,set 则为设置, remove 为删除。==

- **优点**

  1. 线程封闭性（Thread Confinement）：ThreadLocal 可以实现将变量绑定到当前线程，使得变量对其他线程不可见，实现了线程封闭性。这在多线程环境下，可以避免共享变量引起的线程安全问题。
  2. 线程上下文传递（Thread Context Propagation）：ThreadLocal 可以用于在线程之间传递上下文信息。比如，在 Web 应用中，可以将当前用户的登录信息存储在 ThreadLocal 中，这样在不同的业务方法中都可以方便地获取到用户的登录信息。
  3. 隐式参数传递（Implicit Parameter Passing）：ThreadLocal 可以用于将一些公共参数在方法调用链中隐式传递，避免在每个方法参数中显式传递这些参数。这样可以简化方法的调用，提高代码的可读性。
  4. 数据隔离（Data Isolation）：在一些需要数据隔离的场景下，ThreadLocal 可以用于实现数据的隔离。比如，在数据库连接池中，可以使用 ThreadLocal 来保存每个线程使用的数据库连接，确保每个线程使用自己的连接，避免数据混乱。

- **源码**

  ThreadLocal源码中常用的方法有 get、set 和remove，这几个函数的源码很简单

  ```java
  public T get() {
      Thread t = Thread.currentThread();
      ThreadLocalMap map = getMap(t);
      if (map != null) {
          ThreadLocalMap.Entry e = map.getEntry(this);
          if (e != null) {
              @SuppressWarnings("unchecked")
              T result = (T)e.value;
              return result;
          }
      }
      return setInitialValue();
  }
  
  public void set(T value) {
      Thread t = Thread.currentThread();
      ThreadLocalMap map = getMap(t);
      if (map != null)
          map.set(this, value);
      else
          createMap(t, value);
  }
  public void remove() {
      ThreadLocalMap m = getMap(Thread.currentThread());
      if (m != null)
          m.remove(this);
  }
  ```

  这几个函数中都要先调用getMap这个函数来获取ThreadLocalMap对象，然后操作这个map对象来实现变量的存取。看下getMap这个函数

  ```java
  ThreadLocalMap getMap(Thread t) {
      return t.threadLocals;
  }
  ```

- 案例

  ```java
  package test;
  
  public class ThreadLocalTest {
  static ThreadLocal<String> localVar = new ThreadLocal<>();
  
  static void print(String str) {
      //打印当前线程中本地内存中本地变量的值
      System.out.println(str + " :" + localVar.get());
      //清除本地内存中的本地变量
      localVar.remove();
  }
  
  public static void main(String[] args) {
      Thread t1  = new Thread(new Runnable() {
          @Override
          public void run() {
              //设置线程1中本地变量的值
              localVar.set("localVar1");
              //调用打印方法
              print("thread1");
              //打印本地变量
              System.out.println("after remove : " + localVar.get());
          }
      });
  
      Thread t2  = new Thread(new Runnable() {
          @Override
          public void run() {
              //设置线程1中本地变量的值
              localVar.set("localVar2");
              //调用打印方法
              print("thread2");
              //打印本地变量
              System.out.println("after remove : " + localVar.get());
          }
      });
  
      t1.start();
      t2.start();
  }
  }
  
  >threadl : localVar1
  >after remove : null
  >thread2 : localVar2
  >after remove : null
  ```

- **内存泄露**

  ThreadLocal 的引用在线程运行中，在没有执行 remove 的情况下被设置为null，即释放了强引用，ThreadLocal对象只有 Entry 的弱引用了。下次 gc 被回收，`key是弱引用被回收，value 是强引用一直存储在内存中`。线程还在运行，value的内存就不会释放，这样发生了内存泄漏。  **手动回收**

  

#### 5) 区别

1. `Synchronized` 与 `ThreadLocal`  

ThreadLocal 和 Synchonized 都用于解决多线程的并发访问; Synchronized是利用锁的机制，使得变量或者是代码块在某一时刻里只能被一个线程来进行访问。ThreadLocal是为每一个线程都提供了一个变量的副本，这样每一个线程在某一时刻里访问到的不是同一个对象，这样就隔离了多个线程对数据的数据共享。



### 2 公平锁和非公平锁 | 可重入锁

- 公平锁

  所有线程按申请顺序获得锁, 队列第一个才可以获得锁。

  - 优点：所有的线程都能得到资源，不会饿死在队列中。
  - 缺点：吞吐量会下降很多，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销会很大。

- 非公平锁

  所有线程获取锁先尝试, 没有的话才等待, 否则直接拿到锁。

  - 优点：可以减少 CPU 唤醒线程的开销，整体的吞吐效率会高点，CPU 也不必取唤醒所有线程，会减少唤起线程的数量。
  - 缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，导致饿死。

- 可重入锁

  实质上就是一个线程可以多次获得某个锁而不会出现死锁。 `Sychronized` 与 `ReentrantLock` 都是可重入的锁

- Lock实现公平锁与非公平锁方法

  ReentrantLock 的构造函数可以传入一个boolean参数，用于控制锁的公平性, 如下所示

  ```java
  public ReentrantLock() {
      sync = new NonfairSync();
  }
  public ReentrantLock(boolean fair) {
      sync = fair ? new FairSync() : new NonfairSync();
  }
  ```

  公平锁会有 `hasQueuedPredecessors` 方法判断该线程是否位于队列头部, 只有在队列头部的线程才能获得锁。



### 3 volatile 的用法及原理

`volatile 是一个Java的关键字，用来解决内存可见性问题的。它能够保证线程之间可见, 通过添加屏障的方式避免指令重排序导致的线程安全问题。`  **只保证可见性和有序性, 不保证原子性。**

*应用场景*: 被 volatile 修饰的变量保证对所有线程可见, 可以用于状态标志位, 检查某个线程运行状态、任务完成状态等; 线程之间的共享变量; 

- 保证线程之间的可见性

  volatile 关闭 JIT(即时编译器) 对其所修饰变量的优化(多线程并发的情况下, JIT 优化有时候会导致非预期的结果)

- 禁止指令重排序

  volatile 禁止指令重排序(添加内存屏障)

  写操作加的屏障是阻止上方其它写操作越过屏障排到 volatile 变量写之下
  读操作加的屏障是阻止下方其它读操作越过屏障排到 volatile 变量读之上

  volatile使用技巧:

  - 写变量让 volatile 修饰的变量的在代码最后位置
  - 读变量让 volatile 修饰的变量的在代码最开始位置



### 3 Sychronized 锁升级

`无锁 ----> 偏向锁 ----> 轻量级锁 ----> 重量级锁`   锁升级是不可逆的，只能升级不能降级

- **无锁**

  不添加锁

- **偏向锁**

  `为什么引入`: 解决只有一个线程执行同步代码时提高性能。

  `升级过程`: 就是在锁对象的对象头中有个 `ThreadId` 字段, 这个字段如果是空的，线程第一次获取锁的时候，就将线程自身的 `ThreadId` 写入到锁的 `ThreadId` 字段内，将锁头内的是否偏向	锁的状态位置 1。这样下次获取锁的时候，直接检查ThreadId是否和自身线程Id一致，如果一致，则认为当前线程已经获取了锁，因此不需再次获取锁，略过了轻量级锁和重量级锁的加锁	阶段。

  `撤销过程`: 只有当其他线程竞争该锁时，持有偏向锁的线程才会被撤销，释放该偏向锁。并且撤销需要等待全局安全点，也就是该时间点没有字节码正在执行。

  `作用`: 当一段同步代码一直被同一个线程多次访问时，由于只有一个线程，该线程后续访问时无需再次获取锁。  -  性能高

  `问题`

  - 大流量场景下使用偏向锁的问题?

    偏向锁主要解决无竞争情况下的锁性能问题, 它的目标是在没有竞争的情况下，让线程获取锁的代价更低。在大流量场景下, 偏向锁需要花费额外的开销来获取和释放锁, 还需要进行锁状态的判断和记录, 因此在高并发情况下，如果发生频繁的锁竞争和状态切换会导致性能下降。

- **轻量级锁**

  轻量级锁，偏向锁是单线程下的锁优化，这个就说多线程下的锁优化了，当有多个 线程竞争同一个临界资源，这个时候偏向锁就会被撤（这个步骤也是十分消耗资源的），然后升级为轻量级锁，这个也是一个基于 CAS 的乐观锁。

  `为什么引入 | 作用`: *在线程近乎交替执行同步代码时提高性能*。轻量级锁是为了在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统的 Mutex Lock 带来的性能消耗，轻量级锁适用于线程	交替执行同步代码的场景。所以轻量级锁是为了在线程近乎交替执行同步代码时提高性能。

  `升级过程`: *线程 A 与 线程 B 同时抢占锁对象时，偏向锁会被撤销并将锁升级为轻量级锁。*线程 A 在执行同步代码前，JVM 在线程的栈帧中创建用于存储锁记录的空间 Lock Record。当线程 A 抢占锁对	象时，JVM 使用 CAS 操作将锁对象的对象头的 Mark Word 拷贝进线程 A 的锁记录 Lock Record 中（这个拷贝 Mark Word 的过程官方称为 `Displaced Mark Word`），并且将 Mark 	Word 中指向线程栈中 Lock Record 的指针指向线程 A 的锁空间。如果更新成功，则线程 A 持有该对象锁，并将对象锁的 Mark Word 的锁标志位更新为 00。即此时线程 A 持有轻	量级锁会执行同步代码，而线程 B 会自旋等待获取该轻量级锁；如果更新失败，则说明该锁被线程 B 抢占。

  `撤销过程`: 1. 当有两个以上的线程同时竞争一个锁时，那么轻量级锁会被撤销并升级为重量级锁，不再通过自旋的方式等待获取锁而是直接阻塞线程；

  ​		 2. 当持有轻量级锁的线程执行完同步代码时会释放轻量级锁，使用 CAS 操作将锁对象的 Mark Word 中指针指向的锁记录 Lock Record 重新替换回锁对象的 Mark Word。

- **重量级锁**

  当存在两个以上的线程竞争同一把锁或线程竞争轻量级锁自旋多次仍然失败时，会导致锁升级为重量级锁。重量级锁会直接阻塞持有锁的线程以外的所有线程，防止 CPU 空转，减小 CPU 的开销。通过将锁对象的 Mark Word 的锁标志位更新为 10，从而将锁升级为重量级锁。此时可以看到 Mark Word 中有一个指向互斥量的指针，这个指针其实指向的就是 Monitor 对象的起始地址，通过 Monitor 对象即可实现互斥访问同步代码，也就是通过阻塞唤醒的方式实现同步。

- **锁自旋**

  锁自旋，什么是锁自旋呢，很简单就是线程自己做一些无用功，避免线程被挂起阻塞 ，它自己在哪里做一些空任务，然后去竞争锁，避免被挂起阻塞（阻塞和唤醒是又是十分消耗性能的行为，这边涉及到用户态和核心态的操作系统问题，一般我们操作的都是用户态，但是线程的挂起阻塞是需要从用户态切换到核心态，同样，线程唤醒也一样，这个步骤会造成巨大的性能消耗，能避免尽量避免）。当然，锁自旋也是会消耗一定的 CPU 的。

- **总结**

  以上就是 synchronized 的锁升级内容了，JDK 1.6 之后采用锁升级的方式来优化 synchronized 同步锁，提高了程序的运行效率。接下来总结一下偏向锁、轻量级锁、重量级锁三者的优缺点以及使用场景。

  |  锁类型  |                             优点                             |                             缺点                             |
  | :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
  |  偏向锁  | `只有一个线程`访问同步代码时，只在置换ThreadID时进行一次CAS操作，锁的开销低，性能接近于无锁状态。 | 线程间存在竞争时，需要频繁暂停持有锁的线程并检查状态和撤销锁，反而带来额外的开销。 |
  | 轻量级锁 | (`两个线程`)线程间存在交替竞争时，竞争的线程不需要阻塞，提高了响应速度。 | 当大量线程存在竞争时，线程始终的抢占不到锁，会导致CPU空转消耗CPU性能。 |
  | 重量级锁 | `(多个线程竞争一个)`通过阻塞唤醒的方式实现同步，防止CPU空转，不会消耗CPU性能。 | 线程阻塞导致响应时间变长，频繁切换CPU状态，导致性能消耗增大。 |

  根据三类锁的优缺点可以知道使用场景：

  - 偏向锁：**适用于单线程的情况**，在不存在锁竞争的时候进入同步代码可以使用偏向锁。
  - 轻量级锁：**适用于竞争较不激烈且同步代码执行时间较短的情况**，存在竞争时升级为轻量级锁，轻量级锁采用的是自旋锁，采用轻量级锁虽然会占用cpu资源但是相对比使用重量级锁要更高效。
  - 重量级锁：**适用于竞争激烈且同步代码执行时间较长的情况**，此时使用轻量级锁自旋带来的性能消耗就比使用重量级锁更严重，这时候就需要升级为重量级锁。



### 5 JUC | CAS | AQS

`JUC(java.util.concurrent)` 包含多个支持并发操作的工具, 是Java支持并发操作的核心, 包括线程操作、线程池、并发容器、原子操作的具体实现。

- 原子类: 遵循 CAS(比较和替换)原则, 可用于解决单个变量的线程安全问题。
- 锁: 在包含 Synchronized 所有功能基础上, 支持超时和响应中断机制, 主要解决多个变量的线程安全问题。
- 线程池: 可以方便的管理线程, 避免重复开关线程导致的消耗。
- 并发容器: 例如ConcurrentHashMap，支持多线程操作的并发集合，效率更快。 

`CAS(Compare And Swap - 比较和替换)`

- CAS的全称是 Compare-and-Swap，也就是比较并交换，是并发编程中一种常用的算法。

  它包含了三个参数：V，A，B。其中，V表示要读写的内存位置，A表示旧的预期值，B表示新值。

  `CAS` 的核心思想是：在执行操作之前，先比较当前内存中的值是否等于期望值，如果相等，则执行修改操作；如果不相等，则不执行修改操作，继续进行比较，直到内存中的值与期望值相等为止。这个过程中不会出现线程的阻塞和唤醒，因此可以提高系统的并发性能。 CAS 操作需要输人两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。

`AQS (Abstract Queued Synchronizer - 队列同步器)`

- **概念**: 用来构建锁和同步器的框架, 用于实现锁和其他同步组件和维护共享资源, 使用队列让线程进行排队的过程, Lock 基于其实现。

- **理解**: `AQS` 通过一个 `FIFO` 队列维护线程同步状态，实现类只需要继承该类，并重写指定方法即可实现一套线程同步机制。

- **原理**: AQS 维护了一个 `valatile int state` 变量和 `CLH 虚拟双向队列`(即不存在队列实例，仅存在节点之间的关联关系), 队列中的节点持有线程引用，每个节点均可通过`getState()`、`setState()`和`compareAndSetState()`对`state`进行修改和访问。当线程获取锁时，即试图对`state`变量做修改，如修改成功则获取锁；如修改失败则包装为节点挂载到队列中，等待持有锁的线程释放锁并唤醒队列中的节点。

- **底层和唤醒机制**: *先进先出的双向队列 - 双向链表*   *维护了 valatile int state 变量, 锁被释放即唤醒第一个任务, 加锁则阻塞所有任务*

  <img src="imgs/e22dfb7003ee44afb6f80ddfbce68a93tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.awebp" alt="img" style="zoom:50%;" />
  
- **CLH 队列锁**

  概念: 一种是基于逻辑队列非线程饥饿的一种 *自旋公平锁*

  原理: 

  - 首先有一个 **尾节点** 指针，通过这个尾结点指针来构建等待线程的逻辑队列，因此能确保线程线程先到先服务的公平性，因此尾指针可以说是构建逻辑队列的桥梁；此外这个尾节点指针是原子引用类型，避免了多线程并发操作的线程安全性问题；

  - 通过等待锁的每个线程在自己的某个变量上自旋等待，这个变量将由前一个线程写入。由于某个线程获取锁操作时总是通过尾节点指针获取到前一线程写入的变量，而尾节点指针又是原子引用类型，因此确保了这个变量获取出来总是线程安全的。

  步骤:   

  - 首先获得当前线程的当前节点`curNode`，这里每次获取的`CLHNode`节点的`locked`状态都为`false`；

  - 然后将当前`CLHNode`节点的`locked`状态赋值为`true`，表示当前线程的一种有效状态，即获取到了锁或正在等待锁的状态；

  - 因为尾指针`tailNode`的总是指向了前一个线程的`CLHNode`节点，因此这里利用尾指针`tailNode`取出前一个线程的`CLHNode`节点，然后赋值给当前线程的前继节点`predNode`，并且将尾指针重新指向最后一个节点即当前线程的当前`CLHNode`节点，以便下一个线程到来时使用；

  - 根据前继节点（前一个线程）的`locked`状态判断，若`locked`为`false`，则说明前一个线程释放了锁，当前线程即可获得锁，不用自旋等待；若前继节点的locked状态为true，则表示前一线程获取到了锁或者正在等待，自旋等待。

  - `理解` 

    实质上就是通过 preNode(存取前置节点Locked的状态)+curNode(存取当前节点Locked的状态)+tailNode(存取后置节点的Locked的状态), 如果有新的线程到来就将 tailNode 赋

    当前线程的 preNode 节点, 然后 curNode 就会不断自旋判断 preNode.Locked 的状态观察是否可获取锁, 如果不可以就一直自旋, 后面线程也一样。

  <img src="imgs/image-20231023224144490.png" alt="image-20231023224144490" style="zoom: 67%;" />



### 6 分布式锁实现

> 当多个进程不在同一个系统中，用于控制多个进程对资源访问的锁

- **数据库实现**

  创建锁表用于存储锁的信息 - 通过数据库的事务机制来保证并发安全。尝试在数据库中插入一条记录，如果插入成功，则表示获取到了锁；如果插入失败，则表示锁已被其他线程或进程获取。

  `加锁 - 向锁表插入; 解锁 - 删除锁表记录`

- **Redis 实现**

  创建锁键 - 通过 SETNX 设定

  `加锁 - 不存在设定键的值, 存在忽略; 解锁 - 删除键` 

- **其它**

  `Redisson` `zookeeper` 





### 7 线程池 创建 | 核心参数 | 扩容与缩容策略

> 线程池：主要起到管理线程作用, 可以有效的管理线程: 线程数量、线程复用。线程池的好处：1.更方便管理线程 2.可以减少因频繁创建线程和销毁线程带来的内存消耗，提高程序的运行效率。  1）它可以管理线程的数量，可以避免无节制的创建线程，导致超出系统负荷直至奔溃。2）它还可以让线程复用，可以大大地减少创建和销毁线程所带来的开销。

- **创建**

  一般使用 Executors 类创建, 提供了 4 个通用方法:

  - `newCachedThreadPool()` 

    线程数量随着任务增加⽽增加，如果线程执⾏完毕却空闲了⼀段时间则会被回收
    特点：没有核⼼线程数，也不会有缓冲队列，⼀个任务对应会创建⼀个线程，线程的最⼤空闲时间 1分钟。

    ```java
    public class TreadPoolTest {
        public static void main(String[] args) {
            ExecutorService executorService1 = Executors.newCachedThreadPool();
            ExecutorService executorService2 = Executors.newFixedThreadPool(10);
            ExecutorService executorService3 = Executors.newSingleThreadExecutor();
            for (int i = 0; i < 100; i++) {
            int idx = i;
            executorService1.submit(() ->
            	System.out.println(Thread.currentThread().getName() + " task execution i = " + idx));
            }
        }
    }
    ```

  - `newFixedThreadPool`

    创建固定线程数量的线程池，如果某个线程因为执⾏异常⽽结束，那么线程池会补充⼀个新线程代替它
    特点：没有核⼼线程数等于最⼤线程数，⽆界队列作为缓冲，排队可能导致 OOM。

    ```java
    public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
            0L, TimeUnit.MILLISECONDS,
            new LinkedBlockingQueue<Runnable>());
    }
    ```

  - `newSingleThreadExecutor`

    创建只有⼀个线程的线程池对象，如果该线程出现异常⽽结束，那么线程池会补充⼀个线程
    特点： 只有⼀个线程的线程池，⽆界队列作为缓冲，排队可能导致 OOM。

    ```java
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                0L, TimeUnit.MILLISECONDS,
                new LinkedBlockingQueue<Runnable>()));
    }
    ```

  - `newScheduledThreadPool`

    创建⼀个线程池，可以实现在给定的延时后运⾏任务，或者定期执⾏任务

    ```java
    public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    	return new ScheduledThreadPoolExecutor(corePoolSize);
    }
    ```

    `运行阶段`

    <img src="imgs/image-20230904150235070.png" alt="image-20230904150235070" style="zoom:50%;" />

- **线程池核心参数**

  *ThreadPoolExecutor*

  ```java
  public ThreadPoolExecutor(int corePoolSize,
                           int maximumPoolSize,
                           long keepAliveTime,
                           TimeUnit unit,
                           BlockingQueue<Runnable> workQueue,
                           ThreadFactory threadFactory,
                           RejectedExecutionHandler handler)
  ```

  `corePoolSize`	线程池核心线程大小

  `maximumPoolSize` 线程池最大线程数量

  `keepAliveTime`  线程存活时间(线程空闲多久后被释放)

  `unit`		  存活时间单位

  `workQueue`	 工作队列 - 4种: 基于数组、链表、不缓存、优先级的有界阻塞队列  (无界队列|有界队列)

  <img src="imgs/image-20230901192712408.png" alt="image-20230901192712408" style="zoom:50%;" />

  `threadFactory`  线程工厂 - 创建线程用的工厂, 指定线程名等

  `handler`       拒绝策略

  - AbortPolicy：处理程序遭到拒绝，则直接抛出运行时异常 RejectedExecutionException。(默认策略)
  - CallerRunsPolicy：由调用线程（提交任务的线程）直接执行此任务。
  - 此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。
  - DiscardPolicy：无法执行的任务将被删除。
  - DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重新尝试执行任务（如果再次失败，则重复此过程）。

- **扩容与缩容策略**

  线程池的扩容和缩容操作可以通过调整核心线程数和最大线程数来实现：

  - 扩容：当提交的任务数量超过核心线程数且工作队列已满时，线程池会创建新的线程来处理任务，直到达到最大线程数。可以通过适当增大核心线程数和最大线程数来提高线程池的并发能力。
  - 缩容：线程池中的线程在空闲一定时间后会被销毁，以减少资源消耗。可以通过设置合适的线程存活时间来控制线程的缩容。



### 8 线程池 submit() excute() 的区别

  `submit()` 和 `execute()` 方法都用于向线程池提交任务，但它们之间有一些区别：

- 返回值

  `submit()`   返回一个 Future 对象，可以通过该对象获取任务的执行结果或取消任务。

  `execute()`  没有返回值，无法获取任务的执行结果。

- 异常处理

  `submit()`   可以通过 Future.get() 获取任务异常并处理。

  `execute()` 无法捕获任务执行中的异常，需要在任务代码中进行适当的异常处理。

- 方法重载

  submit()   可以接受 Runnable 或 Callable(带返回结果)

  `execute()`  只能接受 Runnable 类型的任务对象(不带返回结果)

​	综上所述，`submit()` 方法比 `execute()` 方法更加灵活，可以处理任务的执行结果和异常，适用于需要获取任务结果或处理异常的情况。而 `execute()` 方法更简单，适用于不需要获取任务结果的情况。根据具体的需求，选择适合的方法来提交任务到线程池。



### 9 线程池 + ThreadLocal 产生的问题 | 线程池优先级

`产生问题`

- 内存泄漏

  在线程池中使用ThreadLocal时，如果没有及时清理ThreadLocal的值，可能会导致内存泄漏。

- 业务数据错乱

  由于线程池中的线程可能会被多个任务共享，如果使用ThreadLocal保存业务数据，则多个任务可能会互相干扰。这可能导致业务数据错乱，产生不可预料的结果。

  解决: 任务执行前显式地清理 ThreadLocal 的值;  使用 InheritableThreadLocal 将父线程的 ThreadLocal 值传递给子线程

`如何控制线程池任务优先级?`

- *PriorityBlockingQueue* 

  使用 PriorityBlockingQueue 作任务队列并为任务定义优先级。在执行任务时，从PriorityQueue中取出优先级最高的任务进行执行,可以自定义任务对象的比较器来确定任务的优先级

- *自定义线程池*    使提交的任务自身具备排序能力 

  扩展ThreadPoolExecutor类，重写 getTask() 方法来自定义任务的获取顺序。在getTask()方法中，你可以根据任务的优先级来选择下一个要执行的任务。



### 10 线程的创建方式 | 通信方式 | 线程状态

**创建方式**

- 继承 Thread 类, 重写 run() 方法
- 实现 Runnable() 接口, 实现接口的 run() 方法
- 实现 Callable() 接口, 重写 call() 方法;  前两种方式线程执行完后都没有返回值，最后一种带返回值；
- 使用线程池

**通信方式**

- 共享变量: 如 volatile 修饰的变量, 可以在线程之间通信使用。
- 锁机制: Synchronized、ReentrantLock(维护的临界区变量) 等
- 条件变量: Condition 变量
- 信号量: Semaphore 类
- 管道: PipedInput|OutputStream



### 11 Thread 和 Runnable 的区别

> 都需要实现 run() 方法; 最终都需要通过 Thread.start() 方法启动

- Thread

  `类- 继承`  `start() run() 都有`  `单继承导致扩展型差` 

  ```java
   class MyThreadDemo extends Thread {
          @Override
          public void run(){
  			//多线程执行的方法
              for(int i=0;i<10;i++){
                  System.out.println("输出:"+i);
              }
          }
       
       @Test
       public void runTest2(){
           //实例化了两个对象。 
           MyThreadDemo thread1=new MyThreadDemo();
           MyThreadDemo thread2=new MyThreadDemo();
           //对同一个，是无法多次启动的。
           thread1.start();
           thread2.start();
       }
   }
  
  ```

- Runnable *常用*

  `接口 - 实现` `Thread 实现 Runnable` `没有 start(), 只有 run() 方法` `构造方法接受Runnable的子类实例 ` `接口可多继承扩展性好` `Thread 接受实的 Runnable 对象为参数`

  在程序开发中只要是多线程肯定永远以实现Runnable接口为主。

  实现Runnable接口相比继承Thread类有如下好处：
  1、避免继承的局限，一个类可以继承多个接口。
  2、适合于资源的共享。

  ```java
  class MyRunnableDemo implements Runnable{
      @Override
      public void run() {
          for(int i=0;i<10;i++){
              System.out.println("输出Runnable:"+i);
          }
      }
      
      @Test
      public void test1(){
          //实例化两次对象
          MyRunnableDemo myRunnableDemo1=new MyRunnableDemo();
          MyRunnableDemo myRunnableDemo2=new MyRunnableDemo();
          //分别放置到不同的线程里面
          Thread thread1=new Thread(myRunnableDemo1);
          Thread thread2=new Thread(myRunnableDemo2);
          //启动
          thread1.start();
          thread2.start();
      }
  }
  
  ```



### 12 run() 和 start() 方法区别

- run()

  `定义线程要执行的任务代码` `主线程中调用不会启动新线程, 只是当做普通方法串行运行`

- start()

  `用于启动新线程` `创建新线程` `只能被调用一次, 多次报 IllegalThreadStateException`



### 13 乐观锁 | 悲观锁

- 乐观锁

  总是假设最好的情况，每次操作数据的时候，认为别人不会修改，所以不会上锁, 只有在更新的时候会判断是否有人修改数据, 适合于多读。 `操作数据不加锁, 更新时判断是否被修改`

- 悲观锁

  总是假设最坏的情况，每次取数据时都认为别人会修改。所以在每次取数据时会自己上锁，这样线程在取数据时候就会进行阻塞。 `操作数据则加锁, 其它线程无法修改数据`




### 14 Java 线程阻塞的方法

- **线程睡眠**

  `Thread.sleep (long millis)`
  使线程转到阻塞状态。当睡眠结束后，就转为就绪（Runnable）状态。sleep()平台移植性好。

- **线程等待**

  `Object类中的 wait() 方法`
  导致当前的线程等待，直到其他线程调用此对象的 notify() 唤醒方法。wait() 使得线程进入阻塞状态，它有两种形式，一种允许 指定以毫秒为单位的一段时间作为参数，另一种没有参数，前者当对应的 notify() 被调用或者超出指定时间时线程重新进入可执行状态，后者则必须对应的 notify() 被调用。

- **线程礼让**

  `Thread.yield()`      告诉调度器，*当前线程愿意放弃当前的CPU时间片*，但是是否真正让出CPU的执行权取决于调度器的具体实现。
  暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。yield() 使得线程放弃当前分得的 CPU 时间，但是不使线程阻塞，即线程仍处于可执行状态，随时可能再次分得 CPU 时间。调用 yield() 的效果等价于调度程序认为该线程已执行了足够的时间从而转到另一个线程。

- **线程自闭**

  `join()`
  等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个线程运行结束，当前线程再由阻塞转为就绪状态。



### 15 wait() 和 sleep() 的区别

- wait()

  `等待直到唤醒, 必须放在 synchronized 块 ` `Object本地方法` `可释放线程获取的锁` `主要用于线程协作与通信`

  `进入 等待状态, 释放对象锁` `需要 notify/ notifyAll 手动唤醒` 

  直接调用 object.wait（）报异常, 需要获取对象锁之后再调用

- sleep()

  `休眠一定时间, 任何地方都可使用` `Thread的静态本地方法 ` `无法释放锁` `用于当前线程休眠，或者轮循暂停操作`

  `进入 休眠状态, 不释放对象锁` `自动苏醒`
  
  ```java
  Thread.sleep(3000L);
  ```



### 16 锁的三种应用场景

- **互斥锁**

  `互斥锁用于保护共享资源，确保同一时间只有一个线程可以访问该资源`

  应用场景

  - *临界区保护*：在多线程环境下，当多个线程需要访问共享资源（如共享变量、全局数据结构等）时，通过互斥锁来保护临界区，避免竞争条件和数据不一致问题。
  - *数据库事务*：在数据库系统中，互斥锁用于保护事务的隔离性，确保同时只有一个事务可以修改某个数据项。

- **读写锁**
  `读写锁允许多个线程同时读取共享资源，但在写操作时需要独占访问`

  应用场景

  - *读多写少的数据结构*：当数据结构被频繁读取而很少修改时，可以使用读写锁来提高并发读取性能。
  - *数据库缓存*：在数据库缓存中，读写锁可以用于控制对缓存数据的访问，提供并发读取和独占写入的支持。

- **自旋锁**
  `自旋锁是一种忙等待的锁，线程在获取锁时会一直自旋（忙等待）直到获取到锁`

  应用场景

  - *短期的临界区保护*：当临界区的持有时间很短，线程在等待锁的时间相对较少时，使用自旋锁可以避免线程切换带来的开销。
  - *多核心处理器环境*：自旋锁在多核心处理器环境中更为有效，因为在一个核心上自旋等待时，其他核心仍可以继续执行其他任务。



### 17 daemon 线程和非 daemon 线程区别(守护线程和非守护线程区别)

- daemon 线程(守护线程|后台线程)

  **特点**: 

  - `守护核心线程的线程`(用来做辅助工作 - 数据同步,垃圾回收)
  - `所有非守护线程终止, 守护线程自行终止`  不影响JVM的退出|程序结束

  **应用**: 垃圾回收

  守护线程在结束时不会执行finally块中的代码，因此不应该在守护线程中进行一些关键性的操作，如文件写入或数据库事务等。

  *setDaemon(true)* 将线程设置为守护线程

- 非 daemon 线程(非守护线程|用户线程)

  **特点**: 

  - `执行核心功能`  处理用户请求、执行计算任务
  - `不会自行终止`  生命周期不受其他线程的影响，即使其他非守护线程已经结束，非守护线程仍然可以继续执行。(影响JVM退出|主线程退出|程序终止)

非守护线程是应用程序的核心线程，它们的结束会导致应用程序的退出，而守护线程是在后台执行的辅助线程，它们的生命周期依赖于非守护线程的存在。



### 18 Java 阻塞队列

> 概念: Java中的阻塞队列（Blocking Queue）是一种线程安全的队列数据结构，它提供了在多线程环境中安全地进行元素插入和移除操作的机制。

1. 内部数据结构：阻塞队列通常使用数组或链表等数据结构来存储元素。这些数据结构提供了高效的插入和移除操作，并且支持随机访问和遍历。
2. 同步机制：阻塞队列使用同步机制来保证多线程环境下的线程安全性。常用的同步机制包括锁（如ReentrantLock）和条件变量（Condition）等，用于线程的互斥访问和等待/唤醒操作。
3. 阻塞操作：阻塞队列的关键特性是在特定条件下进行阻塞操作。当队列为空时，从队列中获取元素的操作将被阻塞，直到队列中有新的元素插入；当队列已满时，插入元素的操作将被阻塞，直到队列有空闲位置。
4. 阻塞等待和唤醒：当一个线程在阻塞队列上等待时，它将被挂起，不会占用CPU资源。当某个条件满足（例如队列非空或队列有空闲位置）时，其他线程可以通过唤醒操作（如插入新元素或移除元素）来通知等待线程继续执行。

**实现类**

- `ArrayBlockingQueue`

  *数组* *有界* *非公平*  一旦创建，容量不能改变

- `LinkedBlockingQueue`

  *单向链表* *有界|无界* 

- `SynchronousQueue`

- `DelayQueue`

- `PriorityBlockingQueue`

  *支持优先级的无界阻塞队列* 默认采用自然顺序进行排序，也可以通过自定义类实现 `compareTo()` 方法来指定排序规则，或者初始化时通过构造器参数 `Comparator` 来指定排序规则。

总结起来，Java的阻塞队列通过内部数据结构、同步机制和阻塞操作来实现多线程环境下的线程安全和阻塞等待/唤醒的功能。这使得阻塞队列成为处理并发编程中线程间通信和协作的重要工具。



### 19 Java 线程终止的方法

- **额外标记**

  `volatile boolean flag`   设置 flag 标记, 通过修改 flag 状态退出循环进而终止

- **普通场景**

  `thread.interrupt()`     *isInterrupt()* 状态设置为 true, 通知系统要停止子线程的运行, 但不一定会立即停止。

- **阻塞场景**

  `调用 thread.interrupt() 抛出 InterruptException 异常捕获进而退出 `  进入 `synchronized` 修饰但还没有运行(如果处于阻塞状态调用方法会抛出异常)

- **stop()**

  `调用 stop() 终止线程`



### 20 join() | interrupt() 区别

**join()**

- A线程内调用B线程的 `join()` 方法, A阻塞B运行, 直到B运行完A继续执行

**interupt()**

- 被中断的线程可以通过检查中断状态来决定是否终止自己的执行; 通过捕获 `InterruptedException` 异常来处理中断





## JVM

JVM 实现JAVA跨平台的核心, 能够将不同平台解释器的代码解释为相同的字节码进行编译。JVM 由类加载器、执行引擎、本地方法接口、运行时方法区(JVM内存模型: 堆、栈、程序计数器、本地方法栈、方法区)组成。

- **类加载器**

  根据给定的全限定名类名（如：java.lang.Object）来加载到运行时数据区（Running data area）的方法区中。

- **执行引擎**

  执行 classes 中的指令

- **本地方法接口**

  与 Native libraries 交互，是其它编程语言交互的接口。

- **运行时数据区**

  这块就是我们常说的JVM内存



### 1 Java 内存模型 | JVM 内存模型

- **Java 内存模型**

  `为Java跨平台提供支持` `并发编程相关规范 - 简化并发编程` 

  Java 内存模型是一种规范, 定义了Java程序中多线程并发访问共享内存时的行为和准则, 抽象了线程和主内存之间的关系就比如说线程之间的共享变量必须存储在主内存中，规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性, 旨在提供一种统一的内存访问模型, 使得开发者能够编写正确、可靠而高效的多线程程序。

  如: 线程共享变量存储在主内存, 每个线程具有独立本地内存; 还定义了并发时主内存和工作内存的操作规则来保证并发性。

- **JVM 内存模型**

  指 JVM 对内存的组织和管理方式, JVM 内存模型 定义 *Java程序在运行时的内存结构*, 包括堆、栈、方法区等。JVM内存模型规定了Java程序运行时的内存分配、使用和回收方式, 以及线程与内存的交互方式。

  <img src="imgs/image-20231017181918592.png" alt="image-20231017181918592" style="zoom: 80%;" />

  **JVM 内存模型 = 运行时数据区**

  `堆和方法区是所有线程共有`  `虚拟机栈，本地方法栈和程序计数器线程私有`

  - **堆**: 用于存储 `对象和对象数组`
  - **虚拟机栈**: 每个线程都有自己的栈, 用于存储 `方法调用、局部变量和操作数`。多个栈帧组成 - 存放局部变量表、操作数栈、动态链接、方法返回地址 *Java 方法*
  - **本地方法栈**: 用于 `执行本地方法` 的栈 
  - **方法区**: 存储 `类的结构信息、静态变量、常量、静态变量` 
  - **程序计数器**: 记录当前线程执行的 `字节码指令地址` 执行位置       *不会出现 OutOfMemoryError*

- **特点**

  - JVM 内存模型与硬件和操作系统的内存模型有一定的差异，JVM 可以在不同平台上实现统一的内存模型。
  - JVM 通过即时编译器（Just-in-Time Compiler，JIT）等技术进行代码优化和内存管理。
  - JVM 内存模型规定了对象的创建、访问、修改和销毁的方式，以及垃圾回收机制对内存的管理。



### 2 JVM 分代回收策略

> Java 虚拟机根据对象存活的周期不同，把堆内存划分为几块，一般分为新生代、老年代。 注意: 在 HotSpot 中除了新生代和老年代，还有永久代。

- **新生代**

  新生成的对象优先存放在新生代中，新生代对象存活率很低，在新生代中，常规应用进行一次垃圾收集一般可以回收 70%~95% 的空间，回收效率很高。新生代中因为要进行一些复制操作，所以一般采用的 GC 回收算法是**复制算法**。 新生代又可以继续细分为 3 部分：`Eden`、`Survivor0（简称 S0）`、`Survivor1（简称S1）`。这 3 部分按照 8:1:1 的比例来划分新生代。

- **老年代**

  一个对象如果在新生代存活了足够长的时间而没有被清理掉，则会被复制到老年代。老年代的内存大小一般比新生代大，能存放更多的对象。如果对象比较大（比如长字符串或者大数组），并且新生代的剩余空间不足，则这个大对象会直接被分配到老年代上。



### 3 GC 可达性分析 | GC Root

> 可达性分析: 通过一系列称为 `GC Roots` 的对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为“引用链”，当一个对象到 `GC Roots` 没有任何的引用链相连时(从`GC Roots`到这个对象不可达)时，证明此对象不可用。

**可达性分析根节点有哪些 | GC Roots**

- 虚拟机栈（栈帧中的局部变量区，也叫做局部变量表）中引用的对象。
- 方法区中的类静态属性引用的对象。
- 方法区中常量引用的对象。
- 本地方法栈中(Native方法) 引用的对象。
- JNI（Java Native Interface）引用的对象
- 所有被同步锁持有的对象



### 4 垃圾回收器 GC

>  垃圾回收器是JVM中负责执行垃圾回收的组件。JVM 提供了不同类型的垃圾回收器，包括：

<img src="imgs/image-20231005143319461.png" alt="image-20231005143319461" style="zoom:50%;" />



#### 1) 新生代收集器

- `Serial`  1

  *单线程* *复制算法*    在垃圾清理时，必须暂停其他所有工作线程, 单个线程收集垃圾。适用于小型应用和简单的客户端应用。  

- `Parallel Scavenge` 2

  *并行* *多线程* *复制算法*    在收集过程中会开启多个线程一起收集，整个过程都会暂停用户线程，多个线程同时收集垃圾, 直到整个垃圾收集过程结束。

- `ParNew` 3

  *多线程* *复制算法*    先停止应用线程，多线程同时收集，整个收集过程STW，直到垃圾收集完毕CPU多核环境下效率要比serial高，新生代唯一一个能与CMS配合的收集器。



#### 2) 老年代收集器

- `Serial Old`  1

  *单线程* *标记-整理算法*   内存资源占用少、单核CPU环境最佳选项。

- `Parallel Old` 2

  *多线程* *标记-整理算法*   多线程收集，CPU多核环境下效率要比serial高

- `CMS` Concurrent Mark and Sweep  *NEW* *1.9 后停用*

  *避免长时间的停顿时间(STW)*  *标记-清除 & 标记-整理* *多线程*  *初始标记、重新标记 需要STW, 其余不需要*      

  **优点:** 多线程收集，收集过程不停止用户线程，所以用户请求停顿时间短。

  **缺点:** *浮动垃圾* - 不需要STW的清理阶段用户产生的新垃圾; *空间碎片* - 标记清除算法导致的碎片问题    

  1. 初始标记: 对根节点与根节点有直接关系的对象进行可达性分析并标记。
  2. 并发标记: 根据根节点标记所有可达对象。
  3. 重新标记: 更新在并发标记阶段被复活的对象。
  4. 并发清除: 并发 *标记清除* 所有被标记为垃圾的对象并回收内存空间。空间碎片到达了一定程度时，此时CMS会使用 *标记整理* 解决空间碎片的问题。



#### 3) 混合收集器

- `G1（Garbage-First）`  *1.9 后成为默认的回收器*

  *复制 & 标记-整理*  局部-标记复制法: 把存活对象从一个Region复制到另外的Region; 全局-标记整理法，每次垃圾收集时会把存活的对象整理到其他对应区域的Region里

  **Region**

  在此之前, GC 将连续的内存空间划分为 **新生代、老年代和永久代 | 元空间 (JDK 1.8)**, 这种划分的特点是各代的存储地址（逻辑地址）是连续的。G1 (Garbage First) 的各代存储地址是不连续的，每一代都使用了 n 个不连续的大小相同的 region， 每个 region 占有一块连续的虚拟内存地址。

  舍弃内存上的物理分区，把堆内存拆分成了大小为1M-32M的 Region块，然后以Region为单位自由的组合成新生代、老年代、Eden区、survior区、大对象区（Humonggous Region），随着垃圾回收和对象分配每个Region也不会一直固定属于哪个分代，我们可以认为Region可以随时扮演任何一个分代区域的内存。

  <img src="imgs/v2-7f1bf4a4f305a0ad62f9d1c56f163196_r.jpg" alt="img" style="zoom:50%;" />

  **Collect Set（智能收集）**

  维护一个 Collect Set 集合，记录待回收的 Region 块信息和其可回收的大小空间, 这样就可以根据用户设定的可接受停顿时间来进行分析，在设定的时间范围内收集哪些区域最划算而择优先收集的区域，优先回收价值最大的 Region, 还可以根据用户的设定之间来计算收集哪些Region达到用户所期望的垃圾收集时间。  

  **优点:** 停顿时间可控，吞吐量高，可根据具体场景选择吞吐量有限还是停顿时间有限，不需要额外的收集器搭配, 提供良好的停顿时间和吞吐量。

  **缺点:** 因为需要维护的额外信息比较多，所以需要的内存空间也要大，6G以上的内存才能考虑使用G1收集器。

  **工作流程: **

  1. 初始标记: 暂停应用线程, 对根节点与根节点有直接关系的对象进行可达性分析并标记。

  2. 并发标记: 根据根节点标记所有可达对象。

  3. 最终标记: 标记在此前阶段用户线程运行产生的新垃圾, 产生 STW

  4. 筛选回收: 把存活对象复制到空闲Region，再根据Collect Set记录的可回收Region信息进行筛选，计算回收成本，根据用户设定的停顿时间值制定回收计划，根据回收计划筛选合适的Region区域进行回收 *复制算法*

     

### 5 垃圾回收算法

JVM 使用不同的垃圾回收算法来标记和回收垃圾对象。常见的垃圾回收算法包括：

- 引用计数法: 对象绑定计数器, 当引用指向该对象, 计数器+1;引用被删除, 计数器-1;为0时对象被回收(等待够一批次再进行回收) 。

- 标记-清除算法（Mark and Sweep）：标记所有活动对象，然后清除未标记的对象。	`优点：垃圾回收速度快。缺点：存在内存碎片`
- 标记-整理算法（Mark and Compact）：标记活动对象，然后将它们向一端移动，然后清除其余空间。 `优点：没有内存碎片。缺点：整理速度慢`
- 复制算法（Copying）：将存活对象复制到一个新的空间，并清除旧空间中的所有对象。  `优点：没有内存碎片。缺点：内存开销大`



### 6 三色标记

- **概念**

  三色标记是Java虚拟机（JVM）中垃圾回收算法中的一种常用标记方式，用于标记对象的存活状态。基本思想是从根对象（如根节点、全局变量等）开始，通过追踪对象之间的引用关系，递归地对对象进行标记。标记阶段完成后，未被标记的对象即为垃圾对象，可以被垃圾回收器回收。然后，JVM进行垃圾回收，回收垃圾对象所占用的内存空间，使其可供程序再次使用。   GC:  `CMS` `G1` - *标记阶段*

- **原理**

  1. 白色（White）：初始状态下，所有对象都被标记为白色，表示未被访问过，需要进行标记。
  2. 灰色（Gray）：灰色表示对象已经被访问过，但其引用的对象还未被标记。灰色对象的引用仍然需要被追踪和标记。
  3. 黑色（Black）：黑色表示对象已经被访问过，并且其引用的对象也已经被标记。黑色对象是被认定为存活对象，不会被垃圾回收。



### 7 线程池的执行流程

- **线程池策略**
  corePoolSize：核心线程数；maximunPoolSize：最大线程数
  每当有新的任务到线程池时，
  第一步： 先判断线程池中当前线程数量是否达到了corePoolSize，若未达到，则新建线程运行此任务，且任务结束后将该线程保留在线程池中，不做销毁处理，若当前线程数量已达到corePoolSize，则进入下一步；
  第二步： 判断工作队列(workQueue)是否已满，未满则将新的任务提交到工作队列中，满了则进入下一步；
  第三步： 判断线程池中的线程数量是否达到了maxumunPoolSize，如果未达到，则新建一个工作线程来执行这个任务，如果达到了则使用饱和策略来处理这个任务。注意： 在线程池中的线程数量超过corePoolSize时，每当有线程的空闲时间超过了keepAliveTime，这个线程就会被终止。直到线程池中线程的数量不大于corePoolSize为止。
  （由第三步可知，在一般情况下，Java线程池中会长期保持corePoolSize个线程。）

- **饱和策略**
  当工作队列满且线程个数达到maximunPoolSize后所采取的策略
  AbortPolicy：默认策略；新任务提交时直接抛出未检查的异常RejectedExecutionException，该异常可由调用者捕获。
  CallerRunsPolicy：既不抛弃任务也不抛出异常，使用调用者所在线程运行新的任务。
  DiscardPolicy：丢弃新的任务，且不抛出异常。
  DiscardOldestPolicy：调用poll方法丢弃工作队列队头的任务，然后尝试提交新任务
  自定义策略：根据用户需要定制。

<img src="imgs/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZW5hbg==,size_16,color_FFFFFF,t_70.png" alt="img" style="zoom:67%;" />



### 8 JVM 调优

`最大堆内存大小` `初始堆内存大小` `年轻代大小` `年轻代和老年代的内存比例` `Eden区和Survivor区内存比例` `垃圾回收器选择` `垃圾回收最大停顿时间` ``

- **常见参数**

  1. 内存相关参数：

  - `-Xmx<size>`：设置堆的最大内存大小。

  - `-Xms<size>`：设置堆的初始内存大小。

  - `-Xmn<size>`：设置新生代的大小。

  - `-XX:MaxPermSize=<size>`（Java 7及之前）| `-XX:MaxMetaspaceSize=<size>`（Java 8及之后）:

    设置持久代（Java 7及之前版本）或元空间（Java 8及之后版本）的最大内存大小。

  2. 垃圾回收相关参数：

  - `-XX:+UseSerialGC`：使用串行垃圾回收器。
  - `-XX:+UseParallelGC`：使用并行垃圾回收器。
  - `-XX:+UseConcMarkSweepGC`：使用并发标记清除垃圾回收器。
  - `-XX:+UseG1GC`：使用G1垃圾回收器。
  - `-XX:ParallelGCThreads=<num>`：设置并行垃圾回收的线程数。

  3. 垃圾回收调优参数：

  - `-XX:MaxGCPauseMillis=<ms>`：设置最大垃圾回收停顿时间目标。
  - `-XX:GCTimeRatio=<n>`：设置垃圾回收时间与应用程序执行时间的比率。
  - `-XX:NewRatio=<n>`：设置新生代与老年代内存大小的比率。
  - `-XX:SurvivorRatio=<n>`：设置Eden区与Survivor区的内存大小比率。

  4. 线程相关参数：

  - `-XX:ParallelGCThreads=<num>`：设置并行垃圾回收的线程数。
  - `-XX:ConcGCThreads=<num>`：设置并发垃圾回收的线程数。
  - `-XX:ThreadStackSize=<size>`：设置线程栈大小。

  5. JIT编译器参数：

  - `-XX:+TieredCompilation`：启用分层编译，将热点代码逐步编译为本地机器码。
  - `-XX:+PrintCompilation`：打印方法的即时编译信息。

- **JVM 调优工具**

  1. 命令行工具：

  - `jps`：用于查看Java进程的状态信息，包括进程ID（PID）和执行的主类名称。
  - `jstack`：用于查看Java进程内线程的堆栈信息，可以用于分析线程的状态、死锁等问题。
  - `jmap`：用于生成Java堆的转储快照，并提供堆内存使用情况的统计信息，有助于分析内存泄漏和内存使用情况。
  - `jhat`：是一个堆转储快照分析工具，可将jmap生成的堆转储文件加载到内存中，以便进行分析和查询。

  2. 可视化工具：

  - `jconsole`：是Java监控与管理控制台，提供了对JVM的实时监控和管理功能，包括内存、线程、类加载、GC等信息的监控和分析。
  - `VisualVM`：是一个功能强大的可视化工具，用于监控和分析Java应用程序的性能。它能够提供线程、内存、CPU使用情况的图形化展示，还支持插件扩展和远程监控功能。



### 9 Java 堆的基本结构

`主要用于存放 对象和对象数组`

在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分：

1. **新生代**

2. **老年代**

   `大对象 - 大量连续内存空间` `长期存活的对象(minorGC > 15 | age > 15)`

3. **永久代**

   `存放类信息、运行时常量池、字符串常量池、常量字段等`



下图所示的 Eden 区、两个 Survivor 区 S0 和 S1 都属于新生代，中间一层属于老年代，最下面一层属于永久代。

<img src="imgs/hotspot-heap-structure.png" alt="堆内存结构" style="zoom:67%;" />



### 10 GC 回收和分配原则

*Age 字段*

`Java 对象优先在Eden分配` -> `Eden 空间不足触发 minorGC` -> `没被 minorGC 回收转移到 survivor0|1(Age=1)` -> `每经过一次 minorGC 年龄增加1岁` -> `Age>15则晋升到老年代`(年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置)



### 11 GC 方式分类

**部分收集** (Partial GC)：

- 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；	*均支持*  `触发: Eden 区满`
- 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集； *CMS有, 其他没有*  `触发: 老年代满`
- 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。    

**整堆收集** (Full GC)：收集整个 Java 堆（新生代、老年代）和方法区的垃圾收集   *混合收集*

- **什么时候触发 FullGC?**

  `调用 System.gc() - 不一定会执行只是建议` `老年代空间不足` `空间分配担保失败` `永久代空间不足` `Concurrent Mode Failure - CMS回收跟不上生成`



### 12 空间分配担保

> **概念**: 空间分配担保是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间。
>
> **规则**: 老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小，就会进行 Minor GC，否则将进行 Full GC。: 



### 13 Java 内存异常 | OOM 问题 | 如何定位

- **堆内存异常**

  `OutOfMemoryError: Java heap space `

  **原因** 

  - *大对象分配* 大对象导致堆内存不够无法分配该对象
  - *内存泄露* 内存泄露导致内存被占用无法释放, 导致多次GC之后，无法找到空闲内存容纳对象。

  **排查思路**  分析堆内存占用情况定位问题 - 解决问题

  - *jmap dump 命令*   `jmap -dump:live,format=b,file=xxxx.hprof pid`  导出 Dump 文件
  - *JVisualVM 打开 dump 日志文件*  分析具体占用情况
  - 其它: *jmap 命令本身检测* *可视化工具* 

  **解决方案**

  - 检查是否存在大对象的分配，最有可能的是大数组分配
  - 通过jmap命令，把堆内存dump下来(内存快照)，使用mat工具分析一下，检查是否存在内存泄露的问题 
  - 如果没有找到明显的内存泄露，使用 -Xmx 加大堆内存
  - 检查是否有大量的自定义的 Finalizable 对象，也有可能是框架内部提供的，考虑其存在的必要性

- **栈内存异常**

  `StackOverflowError`

  原因: *方法调用的递归层级太深*

  解决方案: *检查代码调用层级* 

  `OutOfMemoryError : unable to create new native Thread`

  原因: *JVM 扩展栈无法申请足够空间* 大量的线程占用了栈的空间, 导致内存不足

  解决方案: *降低线程栈大小* 通过 -Xss 降低的每个线程栈大小的容量(受限于操作系统,栈内存大小超过了操作系统或硬件的限制，JVM将无法启动。)

- **方法区内存异常** = **永久代 | 元空间溢出**

  <img src="imgs/image-20231023214604474.png" alt="image-20231023214604474" style="zoom: 67%;" />

  `OutOfMemoryError: PermGen space `   等价(1.7以前是永久代, 1.8之后为元空间)

  `OutOfMemoryError: Metaspace`
  **原因**

  - *1.7前频繁的错误使用String.intern()撑爆了常量池* 
  - *运行期间生成了大量的代理类，导致方法区被撑爆，无法卸载*
  - *应用长时间运行，没有重启* 长时间运行, 堆积的数据撑爆了内存

  **解决方案**

  - 设置永久代|元空间大小
  - 检查代码中是否存在大量的反射操作 - 检查代理类情况
  - 最后一种原因 - 放大招，重启JVM

**如何定位 JAVA 异常**

- 内存监控工具   `Java VisualVM`

  使用Java虚拟机提供的监控工具，如Java VisualVM、Java Mission Control等，可以实时监控应用程序的内存使用情况，包括堆内存、非堆内存、线程等。这些工具可以帮助你发现内存泄漏、对象过多等问题。

- 堆转储快照 `jmap` `jcmd` 

  通过生成堆转储快照（Heap Dump），可以获取当前应用程序的内存快照，包括所有对象的状态和引用关系。可以使用工具如jmap、jcmd或Java VisualVM生成堆转储快照。然后，使用内存分析工具（如Eclipse Memory Analyzer）来分析堆转储快照，找出可能的内存泄漏或内存占用过高的原因。



## Spring

> Spring 是一个轻量级的免费框架，它有两大核心功能，分别是 IOC 和 AOP ，IOC 控制反转是将创建对象的权限交给 spring 框架来控制。可以很好的起到解耦的作用。AOP 是一种编程思想以及面向切面编程，底层使用的是动态代理。可以在程序原有的功能上进行增强，常用的场景有日志记录和权限验证。

### 1 IOC | AOP

- **IOC**(控制反转)

  `将创建对象的权限交给spring`

  在之前创建对象时使用new关键字，而现在直接从spring框架中拿出已创建好的实例即可。Spring负责维护对象之间的依赖关系，降低对象之间的耦合度，它的实现方式为 DI - 依赖注入 主要的注入方式包括: 构造器、setter、接口注入。

- **AOP**(面向切面编程)

  `在方法上开一个切口，可以在这个类执行之前执行自定义的方法，在不修改源代码的前提下，对方法进行增强`
  
  AOP 面向切面编程是 spring 的两大核心之一，它是一种编程思想。它可以对业务逻辑的各个部分进行隔离，降低耦合, 提高代码的可重用性。它的底层是通过动态代理来实现的，它主要场景包括日志记录和权限验证。 `动态代理: 实质上就是对方法加了一层代理, 然后在此之上增强它, 与静态代理的区别在于不需要一个个的实现, 而是通过反射判断是否需要代理, 需要则自动增加。`



### 2 BeanFactory 和 FactoryBean 和 ApplicationContext 的区别

BeanFactory 是最基础的IOC容器, 是一种规范模式; 而 FactoryBean 只是 SpringIOC 创建 Bean 的一种形式; BeanFactory和ApplicationContext是Spring的两大核心接口，都可以当做Spring的容器。其中ApplicationContext是BeanFactory的子接口。 *三者都是接口*

- **BeanFactory**

  所有 Spring Bean 容器的顶级接口，给IOC容器提供了一套完整的规范, 提供 `getBean() containsBean() getType()` 等方法, 提供获取Bean对象、判断是否单例|多例, 是否包含对象、获取Bean的class类型等功能。

  `可作为Spring容器` `只提供实例化和拿对象、生命周期维护功能` `懒加载 - 拿Bean时才实例化` `延迟加载性能好` `扩展性好差`

- **FactoryBean**

  SpringIOC 容器创建 Bean 的一种形式，该接口主要实现自定义动态生成 Bean 实例，可以让用户通过实现该接口来自定义该Bean接口的实例化过程, 无需关系具体实现细节。

- **ApplicationContext**

  应用上下文, 继承自 BeanFactory 接口。

  `可作为Spring容器` `提供国际化、访问资源、载入多个上下文、事件传播` `饿加载 - 一开始就实例化` `预先加载性能差` `功能扩展性好`

  ```java
  public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver {
      @Nullable
      String getId();
  
      String getApplicationName();
  
      String getDisplayName();
  
      long getStartupDate();
  
      @Nullable
      ApplicationContext getParent();
  
      AutowireCapableBeanFactory getAutowireCapableBeanFactory() throws IllegalStateException;
  }
  ```



### 3 Spring 循环依赖和如何解决?

- 循环依赖

  两个或则两个以上的bean互相持有对方，最终形成闭环。比如A依赖于B，B依赖于C，C又依赖于A。

  Spring中循环依赖场景有： 
  （1）构造器的循环依赖 
  （2）field属性的循环依赖。

  <img src="imgs/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd4dWVsZWkwMzY=,size_16,color_FFFFFF,t_70.png" alt="img" style="zoom:50%;" />

- 解决方案

  Spring 的循环依赖主要发生在属性注入阶段, 也即对 Bean对象注入实例属性的时候。当 A 属性注入需要 B, 则请求创建 B; 而 B 属性注入也需要 A, 此时就发生了类似死锁的循环依赖。

  `三级缓存` 

  ```java
  /** Cache of singleton objects: bean name to bean instance. */
  private final Map<String, Object> singletonObjects = new ConcurrentHashMap<>(256);
  
  /** Cache of singleton factories: bean name to ObjectFactory. */
  private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<>(16);
  
  /** Cache of early singleton objects: bean name to bean instance. */
  private final Map<String, Object> earlySingletonObjects = new HashMap<>(16);
  ```

  - 一级缓存（`singletonObjects`）：缓存的是**已经实例化、属性注入、初始化后**的 Bean 对象。
  - 二级缓存（`earlySingletonObjects`）：缓存的是**实例化后，但未属性注入、初始化**的 Bean对象（用于提前暴露 Bean）。
  - 三级缓存（`singletonFactories`）：缓存的是一个 `ObjectFactory`，主要作用是生成原始对象进行 AOP 操作后的**代理对象**（这一级缓存主要用于解决 AOP 问题，后续文章中讲解）。

  采用缓存的方式, 在A依赖B时, 创建B实体, 将 A与B 都放入二级缓存, 这是B在依赖A时直接拿到缓存中的A使用即可。Java采用三级缓存的意义在于, Spring 的 AOP操作会在 *属性注入阶段之后* 产生代理对象, 这时二级缓存缓存的只是 *未属性注入的对象*, 这时依赖的对象与真实对象不一致则会引发问题, 所以采用了三级缓存。使用 *三级缓存* 将滞后的 `AOP` 操作提前, 避免发生依赖对象不一致的问题。  [Blog](https://juejin.cn/post/7218080360403615804)



### 5 Spring Boot 常用注解

`@Autowired` `@Resource` 

**联系**

- @Autowired和@Resource注解都是作为bean对象注入的时候使用的
- 两者都可以声明在字段和setter方法上

**区别**

- @Autowired 注解是 Spring 提供的，而 @Resource 注解是 J2EE 本身提供的
- @Autowired 注解默认通过 byType 方式注入，而 @Resource 注解默认通过 byName 方式注入(不匹配则 byType)
- @Autowired 注解注入的对象需要在 IOC容器中存在，否则需要加上属性 required=false ，表示忽略当前要注入的 bean，如果有直接注入，没有跳过，不会报错

**常见注解**

- **Spring 注解**

  <img src="imgs/image-20231023234233439.png" alt="image-20231023234233439" style="zoom:67%;" />

- **SpringMVC 注解**

  <img src="imgs/image-20231023234251357.png" alt="image-20231023234251357" style="zoom:67%;" />

- **SpringBoot 注解**

  `@SpringbootAplication`: 程序入口 - 开启自动配置

  `@EnableautoConfiguration`: 开启自动配置 - 自动配置程序运行所需的功能和组件

  `@ComponentScan`: 用于扫描指定的包和组件

  `@Import`: 导入依赖  @Conditional   @Unconditional 等







### 6 Spring 事务

- 编程式事务

  - 侵入性事务管理，直接使用底层的 `PlatformTransactionManager` , 使用 `TransactionTemplate` (Spring推荐使用)；

    编程式事务管理对基于 POJO 的应用来说是唯一选择。我们需要在代码中调用 `beginTransaction()、commit()、rollback()` 等事务管理相关的方法；

    ```java
    @Autowired
    private PlatformTransactionManager transactionManager;
    
    public void testTransaction() {
    
      TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition());
              try {
                   // ....  业务代码
                  transactionManager.commit(status);
              } catch (Exception e) {
                  transactionManager.rollback(status);
              }
    }
    
    ```

- 声明式事务

  `基于AOP` `@Transactional 注解`  在 Service 层对应方法上配置 @Transaction 注解即可。本质是对方法前后进行拦截，然后在目标方法开始之前创建或加入一个事务，在执行完目标方法之后根据执行情况提交或回滚事务。 `@Transactional` 的工作机制是基于 AOP 实现的，AOP 又是使用动态代理实现的。如果目标对象实现了接口，默认情况下会采用 JDK 的动态代理，如果目标对象没有实现了接口, 会使用 CGLIB 动态代理。

  ```java
  @Transactional(propagation = Propagation.REQUIRED)
  public void aMethod {
    //do something
    B b = new B();
    C c = new C();
    b.bMethod();
    c.cMethod();
  }
  ```

  **@Transactional 的作用范围**

  - **方法**：推荐将注解使用于方法上，不过需要注意的是： 该注解只能应用到 public 方法上，否则不生效。
  - **类**：如果这个注解使用在类上的话，表明该注解对该类中所有的 public 方法都生效。
  - **接口**：不推荐在接口上使用。

  



### 7 Spring 事务的隔离级别 | 回滚规则 | 传播行为

`@Transactional` 注解属性

- **TransactionDefinition 隔离级别 - isolation **

  - `ISOLATION_DEFAULT - 默认` :使用后端数据库默认的隔离级别，MySQL 默认采用的 `REPEATABLE_READ` 隔离级别 Oracle 默认采用的 `READ_COMMITTED` 隔离级别.


  - `ISOLATION_READ_UNCOMMITTED - 读未提交` :最低的隔离级别，使用这个隔离级别很少，因为它允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**


  - `ISOLATION_READ_COMMITTED - 读已提交` : 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**


  - `ISOLATION_REPEATABLE_READ - 可重复读` : 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生。**


  - `ISOLATION_SERIALIZABLE - 串行化` : 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。但是这将严重影响程序的性能。通常情况下也不会用到该级别。


- **回滚规则 rollbackFor**

  默认情况下，事务只有遇到运行期异常（`RuntimeException` 的子类）时才会回滚，`Error` 也会导致事务回滚，但是，在遇到检查型（Checked）异常时不会回滚。

- **传播行为 propagation **

  | 事务传播行为类型          | 说明                                                         |
  | ------------------------- | ------------------------------------------------------------ |
  | PROPAGATION_REQUIRED      | 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 |
  | PROPAGATION_SUPPORTS      | 支持当前事务，如果当前没有事务，就以非事务方式执行。         |
  | PROPAGATION_MANDATORY     | 使用当前的事务，如果当前没有事务，就抛出异常。               |
  | PROPAGATION_REQUIRES_NEW  | 新建事务，如果当前存在事务，把当前事务挂起。                 |
  | PROPAGATION_NOT_SUPPORTED | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。   |
  | PROPAGATION_NEVER         | 以非事务方式执行，如果当前存在事务，则抛出异常。             |
  | PROPAGATION_NESTED        | 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 |

- **timeout**

  事务的超时时间，默认值为 -1。如果超过该时间限制但事务还没有完成，则自动回滚事务。

- **value 和 transactionManager**

  它们两个是一样的意思。当配置了多个事务管理器时，可以使用该属性指定选择哪个事务管理器。



### 8 Spring 事务的实现原理

> 概念: 当在某个类或者方法上使用@Transactional注解后，spring会基于该类生成一个代理对象，并将这个代理对象作为bean。当调用这个代理对象的方法时，如果有事务处理，则会先关闭事务的自动功能，然后执行方法的具体业务逻辑，如果业务逻辑没有异常，那么代理逻辑就会直接提交，如果出现任何异常，那么直接进行回滚操作。  事务的实现原理。如果说你加了一个 `@Transactional` 注解，此时 Spring 会使用 AOP 思想，对你的这个方法在执行之前，先去开启一个事务。执行完毕之后，根据你的方法是否报错，来决定回滚还是提交事务。

`@EnableTransactionManagement` + `@Transactional`(基于AOP-动态代理实现)

**API**

- `PlatformTransactionManager 事务管理器` 

  创建事务，提交事物和回滚事务

- `TransactionStatus 事务状态`

  事务的状态和事务执行所需要的方法: 判断是否成功、是否回滚、是否新事物、回滚参数等

- `TransactionDefinition 事务属性`

  传播级别、隔离级别、超时时间等



### 9 Spring 事务失效

@Transactional失效的场景

- `非public的方法`  原因就是在为该Bean寻找匹配的Advisor时，如果是非public方法加了该注解会忽视掉。
- `数据库引擎不支持`
- `未指定RollbackOn，且抛出的异常并非RuntimeException`
- `在声明事务的类内部调用事务方法` 基于动态代理, 类内部拿到的是原对象, 而非代理对象。



### 10 SpringBoot 自动装配原理

`约定大于配置`  从每个 jar 包中的 `META-INF/spring.factories`文件中获取到对应的需要进行自动装配的类，根据 Conditional 条件注解判定是否生成相应的Bean对象，然后将它们交给Spring容器进行管理

`@SpringBootApplication`看作是 `@Configuration`、`@EnableAutoConfiguration`、`@ComponentScan` 注解的集合。

- `SpringBootConfiguration`: 源码为 `@Configuration`, 表示该类为主配置类，可用来装配bean;  `@Configuration`：允许在上下文中注册额外的 bean 或导入其他配置类

- `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制。

  AutoConfigurationImportSelector 获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中; 

  1. **@AutoConfigurationPackage**：自动配置包

     @AutoConfigurationPackage和@ComponentScan一样，也是将主配置类所在的包及其子包里面的组件扫描到IOC容器中，但是区别是

     @AutoConfigurationPackage扫描@Enitity、@MapperScan等第三方依赖的注解
     @ComponentScan只扫描@Controller/@Service/@Component/@Repository这些常见注解。所以这两个注解扫描的对象是不一样的。

  2. **@Import(AutoConfigurationImportSelector.class)**

     - 作用：通过import导入第三方提供的bean的配置类：AutoConfigurationImportSelector：给容器中导入组件
     - 作用：扫描所有jar包类路径下的 META-INF/spring.factories 文件，将扫描到的这些文件包装成 properties 对象，从 properties 中获取到EnableAutoConfiguration.class类名对应的值，将这些值添加到容器中，用这些类做自动配置功能

- `@ComponentScan`：扫描被`@Component` (`@Service`,`@Controller`)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。如下图所示，容器中将排除`TypeExcludeFilter`和`AutoConfigurationExcludeFilter`。



### 11 注解的实现原理

`反射和依赖注入`

Spring 使用编译器解析注解, 获取类、方法、属性上的注解, 解析对应的属性值并保存到字节码文件中。在运行期间通过反射机制读取字节码文件中的注解信息, 根据注解信息进行相应的处理, 然后通过依赖注入将其它对象注入到该对象。

*编译器解析注解* -> *运行时反射读取注解* -> *解析相关注解同时使用依赖注入对象*



### 12 Bean 的生命周期 | 注入

`实例化` `属性赋值` `初始化` `使用` `销毁`

1. 实例化（Instantiation）：在这个阶段，Spring 容器根据配置信息创建 Bean 的实例对象。这可以通过构造函数实例化、工厂方法实例化或者通过依赖注入容器中的其他 Bean 来实现。
2. 属性赋值（Population）：在实例化之后，Spring 容器将通过依赖注入或者属性赋值的方式来设置 Bean 的属性值和相关的依赖关系。
3. 初始化（Initialization）：在属性赋值完成后，Spring 容器会调用 Bean 的初始化方法。这个方法可以是通过 `@PostConstruct` 注解标记的自定义初始化方法，也可以是实现了 `InitializingBean` 接口的 `afterPropertiesSet()` 方法。
4. 使用（In Use）：在初始化完成后，Bean 就可以正常使用了。它可以被其他 Bean 引用，或者在容器中被注入到其他 Bean 中。
5. 销毁（Destruction）：当应用程序关闭或者从容器中移除 Bean 时，Spring 容器会调用 Bean 的销毁方法进行清理工作。这个方法可以是通过 `@PreDestroy` 注解标记的自定义销毁方法，也可以是实现了 `DisposableBean` 接口的 `destroy()` 方法。

**注入**

`@ConfigurationProperties` `@Value`

```java
@Value("${custom.property}")
private String customProperty;

@ConfigurationProperties("custom")
public class CustomProperties {
    private String property1;
    private int property2;
    // Getters and setters
}
```



### 13 SpringBoot 配置文件的优先级

- `properties > yaml`
- `resource 目录下 > config 目录下`
- `Jar 包外配置文件 > config 配置文件`
- `config 子目录配置文件 > config 目录配置文件`
- `config > 根路径 > 根路径下的config`
- `bootstrap.properties|yml >  application.properties|yml）> 自定义配置文件`



### 14 Spring 怎么解决依赖冲突

- **不同依赖包版本不兼容**

  尝试升级或降级其中一个依赖的版本，以解决冲突。  `SpringBoot 和 Cloud 的版本一致性问题`

- **其它**

  `maven helper 插件进行排除 Exclude`  `dependencyManagement 制定版本 - 版本锁定`



### 15 SpringCloud 核心组件作用

> SpringCloud 和 Dubbo
>
> - **初始定位不同：** SpringCloud定位为微服务架构下的一站式解决方案；Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用和治理
> - **生态环境不同：** SpringCloud依托于Spring平台，具备更加完善的生态体系；而Dubbo一开始只是做RPC远程调用，生态相对匮乏，现在逐渐丰富起来。
> - **调用方式：** SpringCloud是采用Http协议做远程调用，接口一般是Rest风格，比较灵活；Dubbo是采用Dubbo协议，接口一般是Java的Service接口，格式固定。但调用时采用Netty的NIO方式，性能较好。
> - **组件差异比较多**: 例如SpringCloud注册中心一般用Eureka，而Dubbo用的是Zookeeper
>
> ![img](imgs/v2-76bc1693909f7ef756ee383387cec747_r.jpg)

- Eureka | Nacos | Zookeeper

  `服务注册与发现` 通过注册信息服务30s向Eureka发送心跳以验证存活, 否则剔除服务。

- Ribbon | LoadBalancer

  `负载均衡` 对不同请求通过轮询、权重、区域划分、并发数、随机的逻辑划分到不同的服务器

- Hystrix | sentienl

  `保证服务之间不发生级联故障(雪崩效应)` 一个服务崩溃引发大面积的崩溃, 通过线程隔离(线程池限定并发, 已满直接返回失败)、服务降级(不等待, 返回成功/失败结果)、断路器(切断访问)

- Feign | OpenFeign

  `简化远程调用` 之前的微服务以`url`方式组合访问, Feign使得现在调用类似调用本地方法一样。

- Gateway | zuul | zuul2

  `网关、路由、限流、监控、安全` 

- Config | Nacos

  `服务配置中心` 多个服务之间的配置信息的管理, 仿照Git本地修改push即可, 无需再集中在代码中修改。

- Stream

  `数据流` 传输数据

- SpringBoot

  `代码开发`

- 最新版本

  `2022.0.1` - 与SpringBoot有对应关系 `3.0.5`



### 16 SpringBoot 和 SpringCloud 和 SpringMVC 的区别

技术进展: jsp+servlet => SpringMVC => SpringBoot => SpringCloud

- **SpringMVC**

  SpringMVC 是基于MVC设计模式开发的框架, 它封装了 Servlet 并且通过 xml 配置的方式配置相关参数和环境, 提供了如 @GetMapping, @PostMapping, @RestController 等相关注解简化开发, 但是配置依旧不够简洁。

- **SpringBoot**

  简化Spring应用程序开发和部署步骤的框架, 内置Tomcat、Jetty等HTTP服务器、通过注解和配置简化XML配置、maven提供jar包管理。约定大于配置，一切由内定的约束来自动完成。

- **SpringCloud**

  Cloud 是在 Boot 的基础上开发的, 它的定位主要是提供分布式和微服务的治理, 本身不会提供具体功能性的操作，更专注于服务之间的通讯、熔断、监控等, 需要由多个中间件提供整体功能, Cloud 主要负责不同组件之间的协调和整合。

- **区别**

  SpringBoot 关注于单体|单个服务的开发; SpringCloud 则负责将 Boot 开发的多个微服务合并起来统一管理, 并提供良好的服务通信、调用、治理等服务。



### 17 SpringCloud 微服务之间的调用

- **基本方式**

  `RestTemplate` RestTemplate是Spring提供的用于发送HTTP请求的客户端工具。可以在一个微服务中使用RestTemplate来调用另一个微服务的API。

  1. 调用方和被调用方配置启动的端口号 *8081* 服务名 *application.name* 等 (无注册中心需要拼接 URL, 有注册中心将服务注册到注册中心通过application.name拼接路径访问服务)

  2. 使用 restTemplate 向服务器发起请求并处理返回结果

     ```java
     @Autowired
     private RestTemplate restTemplate;
     
     public void callAnotherService() {
         String url = "http://localhost:8081/api/endpoint"; // 要调用的目标微服务的URL
         ResponseEntity<String> response = restTemplate.getForEntity(url, String.class);
         String result = response.getBody();
         // 处理返回结果
     }
     ```

- **Feign**

  1. 导入 `Feign` 依赖

  2. 启动类开启 Feign   `@EnableFeignClients("name")`

  3. 调用方使用注解 `@FeignClient` 定义feign客户端   Feign 自动发送 http 请求

     ```java
     package cn.itcast.order.client;
     
     import cn.itcast.order.pojo.User;
     import org.springframework.cloud.openfeign.FeignClient;
     import org.springframework.web.bind.annotation.GetMapping;
     import org.springframework.web.bind.annotation.PathVariable;
     
     @FeignClient("userservice")
     public interface UserClient {
         @GetMapping("/user/{id}")
         User findById(@PathVariable("id") Long id);
     }
     ```

  4. 调用方的 controller 中调用接口

     ```java
     @Autowired
     private UserClient userClent;
     
     public Order searchById(Long orderId) {
         // 1.查询订单
         Order order = orderMapper.findById(orderId);
         //2、利用 FeignClient 发起 http 请求查询用户
         User user = userClent.findById(orderId);			//对应提供方的 findById 方法 - Controller
         order.setUser(user);
         // 4.返回
         return order;
     }
     ```

  5. 服务提供方提供方法

     ```java
     @Autowired
     private UserService userService;
     
     @GetMapping("/findById")
     public User findById(Long userId) {
         return userService.findById(userId);
     }
     ```

  6. 服务提供方配置

     ```yaml
     #服务端口
     server.port=8077
     #服务名称,#即为上面@FeignClient注解的name值(name = "provider-client")
     spring.application.name =userservice
     ```



### 18 Spring 源码解析

#### 1) SpringBoot 启动流程

[剖析](https://cloud.tencent.com/developer/article/2131866)

![spring_running.png](imgs/6ba8bf5c8177430b8f462f35948d1c74tplv-k3u1fbpfcp-zoom-in-crop-mark1512000.awebp)

1. 启动类的 main() 方法中找到 run() 方法并执行, 进入 `SpringApplication.class` 新建并初始化 `SpringApplication` 对象(确认容器类型)

*启动类*

```java
@SpringBootApplication
@EnableCaching
@EnableTransactionManagement
public class DemoApplication {
    public static void main(String[] args) {
        SpringApplication.run(DemoApplication.class, args);
    }
}
```

*SpringApplication.class*

```java
public static ConfigurableApplicationContext run(Class<?> primarySource, String... args) {
    return run(new Class[]{primarySource}, args);
}

public static ConfigurableApplicationContext run(Class<?>[] primarySources, String[] args) {
    return (new SpringApplication(primarySources)).run(args);
}
```

2. 进入run()方法      *引用启动监控模块*
   - 开启计时器计算启动时间
   - 设置 headless 设置为true, 保证没有显示器器和鼠标键盘的模式下照样可以工作
   - 创建应用监听器 `SpringApplicationRunListeners` 并从 `spring.factories` 加载监听器
   - 开始监听, 当有事件发生时调用监听器对应事件的方法

*SpringApplication.class run()*

```java
public ConfigurableApplicationContext run(String... args) {
    //开启计时, 计算 Spring 启动所用时间
    long startTime = System.nanoTime();
    DefaultBootstrapContext bootstrapContext = this.createBootstrapContext();
    ConfigurableApplicationContext context = null;
    this.configureHeadlessProperty();
    //1 获取Spring的监听器类，从 spring.factories 中去获取
    SpringApplicationRunListeners listeners = this.getRunListeners(args);
    listeners.starting(bootstrapContext, this.mainApplicationClass);
	...
}
```

3. 准备环境变量   *配置环境模块和监听：包括创建配置环境、加载属性配置文件和配置监听*
   - 准备环境变量 `ConfigurableEnvironment` - 加载系统属性和用户配置的属性  如: application.yaml|properties 等
   - 加入环境变量到监听器对象中

```java
 public ConfigurableApplicationContext run(String... args) {
        //开启计时, 计算 Spring 启动所用时间
        long startTime = System.nanoTime();
        DefaultBootstrapContext bootstrapContext = this.createBootstrapContext();
        ConfigurableApplicationContext context = null;
        this.configureHeadlessProperty();
        SpringApplicationRunListeners listeners = this.getRunListeners(args);
        listeners.starting(bootstrapContext, this.mainApplicationClass);

        try {
            ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
            // 2. 构造容器环境。将容器的一些配置内容加载到 environment  中
            ConfigurableEnvironment environment = this.prepareEnvironment(listeners, bootstrapContext, applicationArguments);
            this.configureIgnoreBeanInfo(environment);
```

4. 然后创建应用上下文 `ConfigurableApplicationContext`  

   - 实例化应用程序的上下文， 调用 createApplicationContext() 方法使用反射创建对象
   - 准备上下文 `prepareContext()`; 实例化单例的beanName生成器 - 执行初始化方法 - 将启动参数注册到容器中

   - 刷新上下文 `refreshContext()` ; 自动装配 - 启动tomcat(Spring实现)

   - 结束定时器(打印启动时间)
   - 上下文准备就绪, 启动 Spring 容器

```java
 public ConfigurableApplicationContext run(String... args) {
        long startTime = System.nanoTime();
        DefaultBootstrapContext bootstrapContext = this.createBootstrapContext();
        ConfigurableApplicationContext context = null;
        this.configureHeadlessProperty();
        SpringApplicationRunListeners listeners = this.getRunListeners(args);
        listeners.starting(bootstrapContext, this.mainApplicationClass);

        try {
            ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
            ConfigurableEnvironment environment = this.prepareEnvironment(listeners, bootstrapContext, applicationArguments);
            this.configureIgnoreBeanInfo(environment);
            Banner printedBanner = this.printBanner(environment);
            // 3. 创建上下文对象
            context = this.createApplicationContext();
            context.setApplicationStartup(this.applicationStartup);
            // 4. 准备上下文, 刷新上下文
            this.prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner);
            this.refreshContext(context);
            this.afterRefresh(context, applicationArguments);
            Duration timeTakenToStartup = Duration.ofNanos(System.nanoTime() - startTime);
            if (this.logStartupInfo) {
                (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), timeTakenToStartup);
            }

            listeners.started(context, timeTakenToStartup);
            this.callRunners(context, applicationArguments);
        } catch (Throwable var12) {
            this.handleRunFailure(context, var12, listeners);
            throw new IllegalStateException(var12);
        }

        try {
            Duration timeTakenToReady = Duration.ofNanos(System.nanoTime() - startTime);
            listeners.ready(context, timeTakenToReady);
            return context;
        } catch (Throwable var11) {
            this.handleRunFailure(context, var11, (SpringApplicationRunListeners)null);
            throw new IllegalStateException(var11);
        }
    }
```



#### 2) BeanFactory

<img src="imgs/vgrv6drlk9.png" alt="在这里插入图片描述" style="zoom:67%;" />

`BeanFactory`  顶级接口

```java
package org.springframework.beans.factory;

public interface BeanFactory {
	/**
	 * 对FactoryBean的转移定义，提供获取FactoryBean实例的方法。
	 * 如果定义bean时是通过工厂模式配置Bean的，那么通过bean的名字检索FactoryBean时
	 * 得到的会是FactoryBean生产出来的实例，如果想得到工厂本身，需要进行转义
	 */
	String FACTORY_BEAN_PREFIX = "&";

	/**
	 * 不同的获取Bean的方法
	 */
	Object getBean(String name) throws BeansException;
	<T> T getBean(String name, Class<T> requiredType) throws BeansException;
	Object getBean(String name, Object... args) throws BeansException;
	<T> T getBean(Class<T> requiredType) throws BeansException;
	<T> T getBean(Class<T> requiredType, Object... args) throws BeansException;

	/**
	 * 获取Bean的提供者（工厂）
	 */
	<T> ObjectProvider<T> getBeanProvider(Class<T> requiredType);
	<T> ObjectProvider<T> getBeanProvider(ResolvableType requiredType);
	
	// 检索是否包含指定名字的bean
	boolean containsBean(String name);
	// 判断指定名字的bean是否为单例
	boolean isSingleton(String name) throws NoSuchBeanDefinitionException;
	// 判断指定名字的bean是否为原型
	boolean isPrototype(String name) throws NoSuchBeanDefinitionException;

	/**
	 * 指定名字的Bean是否匹配指定的类型
	 */
	boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException;
	boolean isTypeMatch(String name, Class<?> typeToMatch) throws NoSuchBeanDefinitionException;

	/**
	 * 获取指定名字的Bean的类型
	 */
	@Nullable
	Class<?> getType(String name) throws NoSuchBeanDefinitionException;
	@Nullable
	Class<?> getType(String name, boolean allowFactoryBeanInit) throws NoSuchBeanDefinitionException;

	// 获取指定名字Bean的所有别名
	String[] getAliases(String name);
}
```

**子接口**

- 二级接口

  ``ListableBeanFactory``   可列出工厂中所有Bean, 批量获取Bean和BeanDefinition

  `HierarchicalBeanFactroy`  实现 Bean 工厂的分层 - 父子容器的概念

  ``AutowireCapableBeanFactory``  自动装配功能 - 实现此接口实现自动装配能力

- 三级接口

  ``ConfigurableBeanFactory``  继承了 `HierarchicalBeanFactroy` `SingletonBeanRegistry` 的子接口，提供工厂分层和单例注册的功能, 扩展了一些复杂的对单例Bean的配置与操作。

- 四级接口

  ``ConfigurableListableBeanFactory``  继承了`ListableBeanFactory`和`ConfigurableBeanFactory` `AutowireCapableBeanFactory` 接口的子接口



### 19 Spring Starter

**概念**: 用于自动配置和引入所需依赖项的一种机制, 相当于一个集合配置启动器。传统条件下WEB环境开发需要导入很多依赖, 现在通过 Web-Starter 就可以一键导入所有的依赖, 也即通过 Starter 能够进一步简化配置, 提供更便捷的代码开发环境。

**功能**

- 整合了模块需要的所有依赖，统一集合到 Starter 中。
- 提供了默认配置，并允许我们调整这些默认配置。
- 提供了自动配置类对模块内的 Bean 进行自动装配，注入 Spring 容器中。

**自定义 Starter**

目的: 将已有的功能封装到一个 starter 里面来避免重复开发。

步骤: 非官方 Starter 命名应遵循 {name}-spring-boot-starter 的格式，例如，myjson-spring-boot-starter

1. 新建 Spring 项目, 命名为 myjson-spring-boot-starter , 引用所需的 pom 依赖
2. 实现具体逻辑, 比如: 封装好的 Bean、Service 等
3. 通过 Maven install 命令打包。 打包后，会在工程的 target 目录下生成一个 jar 包，并且在 maven 本地仓库也会生成相应的 jar 包。
4. 使用时添加 Maven 依赖, 导入 Jar 包即可使用。



### 20  Filter 和 Intercepter 的区别

Filter（过滤器）和 Interceptor（拦截器）是在Web应用程序中用于处理请求和响应的两种常见的中间件组件。它们可以用于在请求到达目标处理程序之前或之后执行自定义逻辑，对请求和响应进行修改或添加额外的处理。

- **Filter**

  实现方式: 实现 `Filter` 接口

  函数: `init()` - 容器启动初始化过滤器时调用, 只调用一次  `doFilter()` - 每一次请求都调用该方法  `destroy()` - 过滤器实例被销毁时调用

  特点:

  `基于回调函数实现的` - FilterChain => 各个Filter => 根据执行情况选择放行还是不放行, 返回到FilterChain响应结果

  `Servlet组件 - 只可在web程序中使用`

  `请求容器后且进入Servlet前进行预处理`

  `对所有进入容器请求生效`

  应用场景: 字符编码转换，敏感词过滤、登陆权限验证、资源访问权限

- **Intercepter**

  实现方式: 实现 `HandlerInterceptor` 接口

  函数:

  `preHandle` - 请求处理之前调用   

  `postHandle` -  preHandle() 返回值为true时才会执行; 在Controller 中的方法调用之后，DispatcherServlet 返回渲染视图之前被调用。

  `afterCompletion()` - preHandle() 返回值为true时才会执行; 在整个请求结束之后， DispatcherServlet 渲染了对应的视图之后执行。`

  特点:

  `基于动态代理实现的`

  `Spring组件 - 单独组件可应用与其它环境`

  `进入Servlet后访问Controller前预处理`

  `对Controller或static目录访问生效`

  应用场景: 身份验证、参数解析、更细粒度的处理和控制, 与 Spring 框架结合更稳定、高效。




### 21 Servlet 与 MVC

- **Servlet**

  Java 编程语言的一种规范，用于处理 Web 请求和生成动态 Web 内容。Servlet 运行在 Web 服务器中，并通过 HTTP 协议与客户端进行通信, 交互式的浏览和修改数据，生成web内容。

  请求方式: 前端 -> servlet(处理并响应封装返回数据) - > 前端 

  特点: *位于MVC的控制层* *1个请求对应一个Servlet*(包含 doGet/doPost 方法)

- **MVC**

  MVC 一种设计模式，用于组织应用程序的结构和逻辑。 SpringMVC 是基于 Servlet 实现的 Web MVC 设计模式的请求驱动类型的轻量级 Web 框架, 它将应用程序分为三个主要组件：

  1. 模型（Model）：模型表示应用程序的数据和业务逻辑。它负责处理数据的获取、存储、处理和验证，并提供对数据的访问和操作接口。
  2. 视图（View）：视图负责呈现模型的数据给用户，并处理用户界面的交互。它通常是用户界面的一部分，如 HTML 页面或用户界面组件。
  3. 控制器（Controller）：控制器接收用户的输入并根据输入更新模型和视图。它负责处理用户请求、调用适当的模型处理逻辑，并将结果传递给适当的视图进行展示。

  特点: *支持Restful*  *对Servlet的封装* *内置标签库更易于前端* *提供数据绑定、校验等功能*

  每个 Controller 方法实际上也是一个 Servlet，通过 `RequestMapping` 过滤请求来处理特定请求并响应。





## 应用场景

### 1 全局主键生成策略

- `数据库自增序列`

- `UUID`

  **UUID由以下几部分的组合：**    `当前时间` + `时钟序列` + `机器码`
  （1）当前日期和时间，UUID的第一个部分与时间有关，如果你在生成一个UUID之后，过几秒又生成一个UUID，则第一个部分不同，其余相同。
  （2）时钟序列。  *“uuid的随机组件”  随机序列, 避免因一些特殊情况导致的 id 重复问题*
  （3）全局唯一的 IEEE 机器识别号，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得。

  ```java
  UUID uuid = UUID.randomUUID();
  ```

  **优点：**
  1）使用简单。
  2）生成ID性能高，基本不会有性能问题。
  3）全球唯一，当数据迁移、数据合并、数据库变更时，可以从容应对。

  **缺点**：
  1）数据无序，无法保证趋势递增。
  2）UUID使用字符串存储，查询效率较低。（常见优化方案为“转化为两个uint64整数存储”或者“折半存储”，折半后不能保证唯一性）
  3）存储空间较大，如果是海量数据库，需考虑存储量的问题。
  4）传输数据量大。
  5）可读性差。

- `SnowFlake 算法`

  snowflake 是 Twitter开源的分布式ID生成算法，结果是一个long型的ID。   `时间戳` + `机器码` + `序列号`

  **其核心思想是：**

  - 最高位是符号位，始终为0，不可用。
  - 41 bit 作为毫秒数 - 41位的长度可以使用69年
  - 10 bit 作为机器编号 （5个bit是数据中心，5个bit的机器ID） - 10位的长度最多支持部署1024个节点
  - 12 bit 作为毫秒内序列号 - 12位的计数顺序号支持每个节点每毫秒产生4096个ID序号

  <img src="imgs/658190-20221011092259658-771095778.png" alt="image" style="zoom:50%;" />

  算法单机每秒内理论上最多可以生成1000*(2^12)，也就是400W的ID，完全能满足业务的需求。

  snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。

  **优点：**

  - 不依赖于数据库，速度快，性能高。
  - ID 按照时间在单机上是递增的。
  - 可以根据实际情况调整各各位段，方便灵活。

  **缺点**：

  - 在单机上是递增的，由于涉及到分布式环境，每台机器上的时钟不可能完全同步，有时也会出现不是全局递增的情况。
  - 只能趋势递增。（如果绝对递增，竞对中午下单，第二天再下单即可大概判断该公司的订单量，危险！）
  - 依赖机器时间，如果发生回拨会导致可能生成id重复。



### 2 限流算法

- 令牌桶算法：

  - 原理：令牌桶算法通过维护一个固定容量的令牌桶，以固定的速率往桶中放入令牌。每个令牌代表一个请求或事件，桶中的令牌数量表示当前可处理的请求数量。当请求到达时，需要从令牌桶中获取一个令牌才能进行处理。如果桶中没有足够的令牌，则请求将被延迟或丢弃。

  - 应用场景：令牌桶算法适用于对 `请求` 进行限流的场景，可以控制单位时间内的请求速率，确保系统在高负载或突发请求情况下仍能保持稳定。

- 漏斗算法：

  - 原理：漏斗算法通过模拟一个漏斗的行为来控制请求的处理速率。漏斗具有一个固定的容量，以固定的速率流出。每个请求代表一定量的水，当请求到达时，如果漏斗有足够的容量，则可以处理该请求，漏斗容量减少；如果漏斗已满，则请求将被延迟或丢弃。

  - 应用场景：漏斗算法适用于对 `任务处理` 进行限流的场景，可以平滑请求的处理速率，防止突发请求对系统造成过大的压力。

- 区别：

  - 令牌桶算法是通过固定速率放入令牌，然后按需获取令牌来控制请求速率，而漏斗算法是通过固定速率流出来控制请求速率。

  - 令牌桶算法可以在固定的速率下处理请求，而漏斗算法可以适应突发请求，根据漏斗的容量来动态调整请求的处理速率。

  - 令牌桶算法的令牌可以积累一段时间，允许一定程度的突发请求，而漏斗算法是根据漏斗的固定容量来限制请求的处理速率。

  - 令牌桶算法对于请求速率的限制更加精确，可以精确控制每个请求的处理时间间隔，而漏斗算法更侧重于平滑请求的处理速率，对于突发请求的处理更具弹性。



### 3 Java 常见加密解密算法

- `Base64`

  用 64 个可打印字符来表示二进制数据。这 64 个字符是：小写字母 a-z、大写字母 A-Z、数字 0-9、符号"+"、"/"（再加上作为垫字的"="，实际上是 65 个字符），其他所有符号都转换成这个字符集中的字符。Base64 编码通常用作存储、传输一些二进制数据编码方法，所以说它本质上是一种将二进制数据转成文本数据的方案。

- `哈希加密`

  - MD5（Message Digest Algorithm 5）

    MD5 主要用做数据一致性验证、数字签名和安全访问认证，而不是用作加密。比如说用户在某个网站注册账户时，输入的密码一般经过 MD5 编码，更安全的做法还会加一层盐（salt），这样密码就具有不可逆性。然后把编码后的密码存入数据库，下次登录的时候把密码 MD5 编码，然后和数据库中的作对比，这样就提升了用户账户的安全性。生成128位散列值，常用于校验数据完整性。   `单向加密算法，只能加密不能解密`

  - bcrypt

    bcrypt 是一种自带盐值（自动加盐）的加密方案。 

    *加密* : 随机生成 salt -> salt; 跟 password 进行 hash

    *解密* : 从 hash 中取出salt -> salt跟 password 进行hash计算 -> 将得到的 hash 跟数据库中提取的的hash进行比对返回Boolean类型：true/false

    |    **项**    |                           **md5**                            |                          **bcrypt**                          |
    | :----------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
    | **密文长度** |                             32位                             |                             60位                             |
    |  **安全性**  | 安全性差。密码相同时，加密后密文一样。提升安全性的方案：加密前生成随机的盐值（字符串），将它与密码拼接，然后再使用md5加密。 | 安全性好。密码相同时，生成的密文是不一样的。（因为它自动生成随机盐值） |
    | **加密耗时** |                              短                              |                             略长                             |

  - SHA（Secure Hash Algorithm - 安全散列算法）

    FIPS所认证的安全散列算法。能计算出一个数字消息所对应的长度固定字符串（又称消息摘要）的算法。且若输入的消息不同，它们对应到不同字符串的机率很高。数字签名等密码学应用中重要的工具，被广泛地应用于电子商务等信息安全领域。 SHA-1、SHA-256、SHA-512 等散列算法，生成不同长度的散列值。

- `非对称加密`

  - RSA（Rivest-Shamir-Adleman）

    非对称加密算法，用于实现公钥加密和数字签名。RSA使用公钥进行加密，私钥进行解密或签名。生成密钥对、公开公钥、公钥加密私钥解密、私钥加密公钥解密。

  - DSA（Digital Signature Algorithm）

    数字签名算法，用于生成和验证数字签名。

- `对称加密`

  - AES（Advanced Encryption Standard）

    目前最常用的对称加密算法之一，支持 128 位、192 位和 256 位密钥长度。密码学中又称 Rijndael 加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的 DES，已经被多方分析且广为全世界所使用。简单说就是 DES 的增强版，比 DES 的加密强度更高。

  - DES（Data Encryption Standard）

    DES 是一种对称加密算法，所谓对称加密算法就是：加密和解密使用相同密钥的算法。DES 加密算法出自 IBM 的研究，后来被美国政府正式采用，之后开始广泛流传。但近些年使用越来越少，因为 DES 使用 56 位密钥，以现代的计算能力，24 小时内即可被破解。

  - 3DES（Triple Data Encryption Algorithm）

    对DES进行了三重加密，提供更高的安全性。

- `对称加密和非对称加密的区别`

  对称加密：

  - 使用相同的密钥进行加密和解密操作，因此也称为共享密钥加密。
  - 加密速度较快，适合处理大量数据。
  - 密钥管理相对简单，只需保护好密钥的安全性。
  - 主要用于数据加密和解密，不适用于身份验证和数字签名。
  - 常见的对称加密算法有 AES、DES、3DES 等。

  非对称加密：

  - 使用一对密钥，即公钥和私钥，进行加密和解密操作，因此也称为公钥加密。
  - 公钥用于加密数据，私钥用于解密数据，公钥可以公开分发，私钥保密。
  - 加密速度较慢，适合处理较小的数据量。
  - 可用于身份验证、数字签名和密钥交换等场景。
  - 常见的非对称加密算法有RSA、DSA等。

  对称加密和非对称加密的主要区别如下：

  - 密钥数量：对称加密使用相同的密钥进行加密和解密，而非对称加密使用一对不同的密钥。
  - 加密速度：对称加密算法加密和解密速度较快，而非对称加密算法加密和解密速度较慢。
  - 安全性：对称加密的主要安全性依赖于密钥的保护，而非对称加密的安全性依赖于私钥的保密性。
  - 用途：对称加密主要用于数据加密和解密，而非对称加密可以用于身份验证、数字签名和密钥交换等场景。



### 4 高可用设计方案

- **集群和负载均衡** 

  `Redis 集群` `Ribbon 负载均衡`

- **服务容错与故障转移**

  `Hystrix | sentienl 重试、熔断、限流` 

- **数据库高可用**

  `主从复制 | 分库分表`



### 5 单点登录 - SSO

- **概念**

  简称为 SSO，SSO的定义是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。

- **实现方式**

  `cookie` `session` `JWT` + *加密算法*
  
- **方案**

  `session + 广播` 调用用户登录信息保存到本机sesion, 通过广播复制到其他服务器session

  `cookie + redis` 登录信息存入redis, 将key值存到本地cookie, 访问时携带cookie

  `JWT Token` 返回由用户信息根据规则生成的token字符串(JWT) - *cookie | 拼接返回*, 访问时携带token



### 6 熔断、限流、降级的区别

- **熔断**（Circuit Breaking）

  `设置阈值, 触发立即拒绝` 断路器 - 保险

- **限流**（Rate Limiting）：

  `限制请求速率确保服务正常`  令牌桶算法和漏桶算法

- **降级**（Degradation）：

  `牺牲边缘功能维护核心功能正常运转`  双11关闭其它功能, 保障支付





## 常规算法

### 1 树

#### 1) 二叉树的前 | 中 | 后 | 层序遍历

`前序`

$递归$

```java
public void preOrder(TreeNode head){
    if(head == null){
        return;
    }
    System.out.println(head.val);
    preOrder(head.left);
    preOrder(head.right);
}
```

$迭代$

```java
 public int[] preOrder(TreeNode root){
        List<Integer> res = new ArrayList<>();
        if(root == null){
            return res.stream().mapToInt(Integer::valueOf).toArray();
        }

        Deque<TreeNode> stack = new LinkedList<TreeNode>();
        while(root != null || !stack.isEmpty()){
            //先一条路走到头, 然后退栈
            while(root != null){
                stack.push(root);
                res.add(root.val);     //添加值到lsit
                root = root.left;
            }
            //到头了, 退栈
            root = stack.pop();
            root = root.right;      //向右遍历
        }
        int[] ress = res.stream().mapToInt(Integer::valueOf).toArray();
        return ress;
    }
```



`中序`

$递归$

```java
public void midOrder(TreeNode head){
    if(head == null){
        return;
    }
    midOrder(head.left);
    System.out.println(head.val);
    midOrder(head.right);
}
```

$迭代$

```java
public int[] midOrder(TreeNode root){
    Deque<TreeNode> stack = new LinkedList<TreeNode>();
    List<Integer> res = new ArrayList<>();
    while(root != null || !stack.isEmpty()){
        //先一条路走到头, 然后退栈
        while(root != null){
            stack.push(root);
            root = root.left;
        }
        //到头了, 退栈
        root = stack.pop();
        res.add(root.val);     //添加值到lsit
        root = root.right;      //向右遍历
    }
    int[] ress = res.stream().mapToInt(Integer::valueOf).toArray();
    return ress;
}
```



`后序`

$递归$

```java
public void afterOrder(TreeNode head){
    if(head == null){
        return;
    }
    afterOrder(head.left);
    afterOrder(head.right);
    System.out.println(head.val);
}
```

$迭代$

```java
public int[] afterOrder(TreeNode root){
    List<Integer> res = new ArrayList<>();
    if(root == null){
        return res.stream().mapToInt(Integer::valueOf).toArray();
    }

    Deque<TreeNode> stack = new LinkedList<TreeNode>();
    TreeNode pre = null;
    while(root != null || !stack.isEmpty()){
        //先一条路走到头, 然后退栈
        while(root != null){
            stack.push(root);
            root = root.left;
        }

        root = stack.pop();
        //根据情况判断是否有右结点 && 未被访问过
        if(root.right == null || root.right == pre){
            res.add(root.val);
            pre = root;
            root = null;

        } else{
            stack.push(root);
            root = root.right;
        }
    }
    return res.stream().mapToInt(Integer::valueOf).toArray();
}
```



`层序`

通过 BFS 改造而来, 记录每次入队的个数然后添加到二维数组的对应列 : 主要是通过BFS得到每一层的结点信息, 然后将节点信息存到新的数组, 再拼接为二维数组即可。

```java
 public List<List<Integer>> levelOrder(TreeNode root) {
     List<List<Integer>> res = new ArrayList<List<Integer>>();
     Queue<TreeNode> queue = new ArrayDeque<>();
     if(root != null){
         queue.add(root);
     }
     while(!queue.isEmpty()){
         List<Integer> level = new ArrayList<>();
         int n = queue.size();
         for(int i = 0; i < n; i++){
             //遍历每一层的所有节点, 添加到列表内 - 以下是层序遍历
             TreeNode node = queue.poll();
             if(node.left != null){
                 queue.add(node.left);
             }
             if(node.right != null){
                 queue.add(node.right);
             }
             level.add(node.val);
         }
         res.add(level);
     }
     return res;
 }
```





#### 2) 二叉树深度优先遍历(DFS) | 广度优先遍历(BFS)

`DFS`

```java
public void DFS(TreeNode head){
    if(head == null){
        return;
    }
    //list.add(node.val)
    DFS(head.left);
    DFS(head.right);
}
```

`BFS`

```java
public List<Integer> BFS(TreeNode root){
    Queue<TreeNode> queue = new LinkedList<TreeNode>();
    List<Integer> list= new LinkedList<Integer>();

    if(root == null){
        return res;
    }
    queue.add(root);
    while(!queue.isEmpty()){
        TreeNode node = queue.poll();
        if(node.left != null){
            queue.add(node.left);
        }
        if(node.right != null){
            queue.add(node.right);
        }
        list.add(node.val);
        System.out.println(node.val);
    }
    return list;
}
```



#### 3) 二叉树 高度

```java
public int height(TreeNode root){
    if(root == null){
        return 0;
    }
    return Math.max(height(root.left), height(root.right)) + 1;
}
```





### 2 手撕算法

#### 1) 有效括号

```java
public boolean isValid(String s) {
    int n = s.length();
    if(n % 2 == 1){
        return false;
    }

    //定义 MAP 保存 Key - Value
    Map<Character, Character> map = new HashMap<Character, Character>() {{
        put(')', '(');
        put(']', '[');
        put('}', '{');
    }};
    //初始化栈
    Deque<Character> stack = new LinkedList<Character>();
    for(int i = 0; i < n; i++){
        char c = s.charAt(i);
        if(map.containsKey(c)){
            //如果后置括号出现: 1) 栈空, 匹配失败 2) 不等于map中匹配的括号, 匹配失败
            if(stack.isEmpty() || stack.peek() != map.get(c)){
                return false;
            }
            stack.pop();
        } else{
            stack.push(c);
        }
    }
    return stack.isEmpty();
}
```



#### 2) LRU

> 最近最久未用(Least Recently Used)算法: 也就是检查最近最少使用的数据的算法。这个算法通常使用在内存淘汰策略中，用于将不常用的数据转移出内存，将空间腾给最近更常用的“热点数据”。

```java
class LRUCache {
    int capacity;
    Map<Integer, Integer> map;

    public LRUCache(int capacity) {
        this.capacity = capacity;
        this.map = new LinkedHashMap<Integer, Integer>();
    }

    public int get(int key) {
        if(!map.containsKey(key)){
            return -1;
        }
        //先删除旧位置, 再放入新位置
        Integer value = map.remove(key);
        map.put(key, value);
        return value;
    }

    public void put(int key, int value) {
        if(map.containsKey(key)){
            map.remove(key);
            map.put(key, value);
            return;
        }
        map.put(key, value);
        //如果 size() 超出 capacity, 删除最近最久未用的元素, 也即删除最前面的一个元素
        if(map.size() >capacity){
            Integer tempKey = map.entrySet().iterator().next().getKey();
            map.remove(tempKey);
        }
    }
}
```



#### 3) 有序数组转平衡二叉搜索树

```java
class Solution {
    public TreeNode sortedArrayToBST(int[] nums) {
        return helper(nums, 0, nums.length - 1);
    }

    public TreeNode helper(int[] nums, int left, int right) {
        if (left > right) {
            return null;
        }

        // 总是选择中间位置左边的数字作为根节点 - 二分思想
        int mid = (left + right) / 2;
        TreeNode root = new TreeNode(nums[mid]);
        root.left = helper(nums, left, mid - 1);
        root.right = helper(nums, mid + 1, right);
        return root;
    }
}
```



#### 4) 判断是否平衡二叉树

```java
class Solution {
    public boolean isBalanced(TreeNode root) {
        if (root == null) {
            return true;
        } else {
            return Math.abs(height(root.left) - height(root.right)) <= 1 && isBalanced(root.left) && isBalanced(root.right);
        }
    }

    public int height(TreeNode root) {
        if (root == null) {
            return 0;
        } else {
            return Math.max(height(root.left), height(root.right)) + 1;
        }
    }
}
```





#### 5) 快速幂 n^k

思路: $2^{100} \ = \ 2^(50*2) \ = \ = 2^(25*2*2) \ ... \ = \ 递归m次$   复杂度 - $O(log_2N)$

```java
public static int fastPower(int x, int n) {
    if (n == 0) return 1;
    int result = fastPower(x, n >> 1);
    result *= result;
    return (n % 2) == 0 ? result : result * x;
}
```



#### 6) 括号匹配(有效的括号)

```java
 public boolean isValid(String s) {
        if(s.length() % 2 == 1){
            return false;
        }
        HashMap<Character, Character> map = new HashMap<Character, Character>();
        map.put(')', '(');
        map.put(']', '[');
        map.put('}', '{');
        //栈
        Deque<Character> stack =new LinkedList<Character>();
        for(int i = 0; i < s.length();i++){
            char c = s.charAt(i);
            if(map.containsKey(c)){
                if(stack.isEmpty() || stack.peek() != map.get(c)){
                    return false;
                }
                stack.pop();
            } else{
                stack.push(c);
            }
        }
        return stack.isEmpty();
    }
```



#### 7) [无重复字符的最长子串](https://leetcode.cn/problems/longest-substring-without-repeating-characters/)

**示例 1:**

```
输入: s = "abcabcbb"
输出: 3 
解释: 因为无重复字符的最长子串是 "abc"，所以其长度为 3。
```

**示例 2:**

```
输入: s = "bbbbb"
输出: 1
解释: 因为无重复字符的最长子串是 "b"，所以其长度为 1。
```

**示例 3:**

```
输入: s = "pwwkew"
输出: 3
解释: 因为无重复字符的最长子串是 "wke"，所以其长度为 3。
     请注意，你的答案必须是 子串 的长度，"pwke" 是一个子序列，不是子串。
```

```java
    public int lengthOfLongestSubstring(String s) {
        if(s.length() == 0){
            return 0;
        }
        HashMap<Character, Integer> map = new HashMap<>();
        int left = 0;
        int max = 0;
        for(int i = 0;i < s.length();i++){
            //出现重复, 需要跳转到之前的重复位置继续滑动
            if(map.containsKey(s.charAt(i))){
                left = Math.max(left, map.get(s.charAt(i)) + 1);
            }
            map.put(s.charAt(i), i);
            //
            max = Math.max(max, i - left + 1);
        }
        return max;
    }
```



#### 8) [最长公共子序列](https://leetcode.cn/problems/qJnOS7/)



<img src="imgs/image-20231101120953527.png" alt="image-20231101120953527" style="zoom: 50%;" />

**示例 1：**

```
输入：text1 = "abcde", text2 = "ace" 
输出：3  
解释：最长公共子序列是 "ace" ，它的长度为 3 。
```

**示例 2：**

```
输入：text1 = "abc", text2 = "abc"
输出：3
解释：最长公共子序列是 "abc" ，它的长度为 3 。
```

**示例 3：**

```
输入：text1 = "abc", text2 = "def"
输出：0
解释：两个字符串没有公共子序列，返回 0 。
```



```java
public int longestCommonSubsequence(String text1, String text2) {
    int m = text1.length();
    int n = text2.length();
    int [][]dp = new int[m+1][n+1];
    for(int i = 1;i <= m;i++){
        char c1 = text1.charAt(i - 1);
        for(int j = 1; j <= n;j++){
            char c2 = text2.charAt(j - 1);
            if(c1 == c2){
                dp[i][j] = dp[i-1][j-1] + 1;
            } else{
                dp[i][j] = Math.max(dp[i][j-1], dp[i-1][j]);
            }
        }
    }
    return dp[m][n];
}
```



#### 9) 判断链表是否有环且输出环的入口

```java
public ListNode detectCycle(ListNode head) {
    ListNode fast = head, slow = head;
    while (true) {
        if (fast == null || fast.next == null) {
            return null;
        }
        fast = fast.next.next;
        slow = slow.next;
        if (fast == slow) {
            break;
        }
    }
    //赋值
    fast = head;
    while(fast != slow){
        fast = fast.next;
        slow = slow.next;
    }
    return slow;
}
```







### 3 排序算法

> `不稳定` *快选希堆(快选稀队), 其余稳定*
>
> `时间复杂度`
>
> - $O(nlog_2n)$   *快归堆(快归队)*
>
> `空间复杂度`
>
> - $O(1)$   *查堆选希冒(插队选稀猫)*

<img src="imgs/image-20230909185243519.png" alt="image-20230909185243519" style="zoom:67%;" />



#### 1) 冒泡排序

```java
public static void bubbleSort(int []array){
    for (int i = 0; i < array.length - 1; i++) {
        for (int j = 0; j < array.length - i - 1; j++) {
            if(array[j] < array[j+1]){
                int temp = array[j];
                array[j] = array[j+1];
                array[j+1] = temp;
            }
        }
    }
}
```



#### 2) 快速排序

```java
public static void quickSort(int []array, int low, int high){
    if(low >= high){
        return;
    }
    int left = low, right = high;
    int key = array[left];
    while(left != right){
        while(key <= array[right] && left < right){
            right--;
        }
        while(key >= array[left] && left < right){
            left++;
        }
        if(right > left){
            int temp = array[left];
            array[left] = array[right];
            array[right] = temp;
        }
    }
    quickSort(array, low, left - 1);
    quickSort(array, left + 1, high);
}
```



#### 3) 插入排序

```java
public static void insertSort(int []array) {
    for (int i = 1; i < array.length; i++) {
        int key = array[i];
        //已排序元素下标
        int index = i - 1;
        //当前元素大于插入位置元素时, 整体后移直到找到小于插入位置元素的下标进行插入
        while(index >= 0 && array[index] > key){
            array[index + 1] = array[index];
            index--;
        }
        //插入元素
        array[index + 1] = key;
    }
}
```



#### 4) 选择排序

`选择最小的插入到前面, 维护有序和无序数组`

```java
import javax.swing.tree.TreeNode;
import java.util.*;

public class Main {
    public static void selectionSort(int []arr){
        for(int i = 0;i < arr.length; i++){
            int index = i;
            for(int j = i+1; j< arr.length; j++){
                if(arr[index] > arr[j]){
                    index = j;
                }
            }
            //swap
            if(index != i){
                int temp = arr[i];
                arr[i] = arr[index];
                arr[index] = temp;
            }
        }
        for(int i = 0; i < arr.length; i++){
            System.out.print(" " + arr[i]);
        }
    }


    public static void main(String args[]){
        selectionSort(new int[] {
            1,2,3,6,2,5,6,8,3,4,9,1
        });
    }

}
```



#### 5) 堆排序

```java
import java.util.Arrays;

public class Main {
    public static void main(String[] args) {
        int[] array = {9, 8, 7, 6, 5, 4, 3, 2, 1};
        Arrays.stream(array).forEach(System.out::println);
        heapSort(array);
        System.out.println("------------");
        Arrays.stream(array).forEach(System.out::println);
    }

    public static void swap(int []arr,int a ,int b){
        int temp=arr[a];
        arr[a] = arr[b];
        arr[b] = temp;
    }

    private static void maxHeap(int[] array, int heapSize, int index) {
        //左右节点 - 找最大的交换
        int left = index * 2 + 1;
        int right = index * 2 + 2;

        //找最大的节点交换
        int largerNode = index;
        if(left < heapSize && array[left] > array[index]){
            largerNode = left;
        }
        if(right < heapSize && array[right] > array[largerNode]){
            largerNode = right;
        }
        //如果子节点大于父节点则交换, 判断是否影响后续节点的平衡
        if(index != largerNode){
            swap(array, index, largerNode);
            maxHeap(array, heapSize, largerNode);
        }

    }

    private static void buildMaxHeap(int[] array) {
        if(array == null || array.length < 2){
            return;
        }
        //最后一个非叶子结点开始调整, 直到堆顶
        int noLeafNode = (array.length-1)/2;
        for(int i = noLeafNode; i >= 0; i--) {
            maxHeap(array, array.length, i);
        }
    }

    public static void heapSort(int[] array){
        if(array == null || array.length < 2){
            return;
        }

        buildMaxHeap(array);

        for(int i = array.length - 1; i >= 1; i--){
            //交换堆底和堆顶元素
            swap( array, 0, i);
            //调整堆
            maxHeap(array, i, 0);
        }
    }
}
```



#### 6) 归并排序

```java
import java.util.*;

public class Main {
    public static void main(String[] args) {
        int[] array = new int[] { 5, 69, 12, 3, 56, 789, 2, 5648, 23 };
        mergeSort(array, 0, array.length-1);
        Arrays.stream(array).forEach(System.out::println);
    }

    public static void mergeSort(int []array,int left, int right){
        if(array == null || right == left){
            return;
        }
        int mid = left + (right - left) / 2;
        mergeSort(array, left, mid);
        mergeSort(array, mid + 1, right);
        merge(array, left, mid, right);
    }

    public static void merge(int []array,int left, int mid, int right){
        int []temps = new int[right - left + 1];
        //左右指针 - 左边数组和右边数组的起始 index
        int lp = left;
        int rp = mid + 1;
        int i= 0;
        while(lp <= mid && rp <= right){
            if(array[lp] <= array[rp]){
                temps[i++] = array[lp++];
            } else{
                temps[i++] = array[rp++];
            }
        }
        //剩余部分直接填充
        while(lp <= mid) temps[i++] = array[lp++];
        while(rp <= right) temps[i++] = array[rp++];
        //填充回去
        i = left;
        for(int j = 0;j < temps.length;j++){
            array[left + j] = temps[j];
        }
    }
}
```





### 5 多线程

#### 1) 奇偶线程

`synchronized`

```java
import java.util.*;

public class Main {
    private static int count = 0;
    private static final Object object = new Object();

    public static void main(String[] args) {
        new Thread(new printer(), "偶数线程，").start();
        new Thread(new printer(), "奇数线程，").start();
    }

    static class printer implements Runnable {
        @Override
        public void run() {
            while (count <= 100) {
                synchronized (object) {
                    // 打印数字，并立即释放锁
                    System.out.println(Thread.currentThread().getName() + "打印:" + count++);
                    object.notify();
                    // 此处判断，是为了打印完了100个数字后，程序能够正常结束，否则程序将一直等待下去，耗费系统资源。
                    if (count <= 100) {
                        try {
                            object.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                }
            }
        }
    }
}
```

`volatile + yield() 礼让`

```java
import java.util.*;

class OddEven {
    int n;
    volatile boolean flag = true;// flag为true则打印奇数，否则打印偶数

    public OddEven(int n) {
        this.n = n;
    }

    public void printOdd() {
        for (int i = 1; i <= n; i = i + 2) {
            while (!flag) {// 注意此判断在for循环里面，因为每次输出都要判断是否是该本线程输出
                Thread.yield();
            }

            System.out.println(i);
            flag = false;
        }
    }

    public void printEven() {
        for (int i = 2; i <= n; i = i + 2) {
            while (flag) {
                Thread.yield();
            }

            System.out.println(i);
            flag = true;
        }
    }
}

public class Main {
    public static void main(String args[]) {
        int n = 100;
        OddEven eddEven = new OddEven(n);

        Thread threadA = new Thread(new Runnable() {
            @Override
            public void run() {
                eddEven.printEven();
            }
        });

        Thread threadB = new Thread(new Runnable() {
            @Override
            public void run() {
                eddEven.printOdd();
            }
        });

        threadA.start();
        threadB.start();
    }
}
```

`ThreadLocal`



### 6 动态规划

#### 1) **爬楼梯**

```java
public int climbStairs(int n) {
    if(n <= 1)
        return 1;
    int []dp = new int[n];
    dp[0] = 1;
    dp[1] = 2;

    int res = 0;
    for(int i = 2;i < n;i++){
        dp[i] = dp[i-1] + dp[i-2];
    }
    return dp[n-1];
}

public int climbStairs(int n) {
    if(n == 1){
        return 1;
    } 

    int pre = 0;
    int next = 1;
    int res = 0;
    for(int i = 1;i <= n;i++){
        res = pre + next;
        pre = next;
        next = res;
    }
    return res;
}
```



#### 2) [斐波那契数](https://leetcode.cn/problems/fibonacci-number/)

解法: `递归` `动态规划` `矩阵连乘法` - 方程(二维矩阵的乘法)

```java
public int fib(int n) {
    if(n == 0){
        return 0;
    } else if(n == 1){
        return 1;
    }

    int pre = 0;
    int next = 1;
    int res = 0;
    for(int i = 2;i <= n;i++){
        res = pre + next;
        pre = next;
        next = res;
    }
    return res;
}
```



### 7 图

#### 1) 最小生成树

`Prim`: 已知所有点和边, 找最小代价边加入集合, 直到最小生成树生成

![image-20231030140207166](imgs/image-20231030140207166.png)

`Kruskal`: 已知所有顶点, 从起始顶点出发找任一点通路, 将最小代价边加入集合, 直到最小生成树生成



#### 2) 最短路径

`Dijkstra`: 从给定顶点v0出发更新权值序列, 直到遍历完所有图, 从序列中找最短

`Floyd`: 多源最短路径算法。 初始化单源(不经过中间节点)权值矩阵, 每次加入一个新点(作为中继点), 更新权值矩阵, 直到添加完所有节点则得到最短路径矩阵。



## 常见场景题

### 1 一亿个数找 top N

**方案**

- **全部排序** 

  *Hash 去重复 + 全部排序*

  缺点: 内存占用高 时间开销高 无用功

- **局部淘汰法**

  *Hash 去重复 + 局部淘汰*

  `数组`

  保存前N个数并得出最小数, 取最小数与后续数字比较如果小于后续数字则插入, 维护N大的容器。  $O(n+m^2) \ \ m为容器大小$

  `最小堆`

  读入N个数字构建最小堆, 遍历后续数字, 维护最小堆     $时间复杂度为O（nmlogm），空间复杂度是10000（常数）$

- **分治法**

  *Hash 去重复 + 分治*

  数据划分为M份, 在M份中找出最大的N个数字, 最后从M*N个数字里面找最大的N个数字





### HR 话术

### 1 项目担任什么角色，怎么和大家沟通的

问出这个问题, 是想 **考你的团队合作和沟通能力** 。

这里如果多个人一起开发项目的话, 比如2个人分Java的前后端或者多个人划分不同的任务。假定是前后端分开开发的, 这里不要说自己是当场沟通或者通过通讯工具沟通协调的, 可能过于简单且效率比较低。一般开发肯定会写文档, 不管是接口文档、编码规范以及其他的要求等, 这样的效率会高很多。

推荐: 假定前后端分人开发的, 前端和后端通过文档的方式说明自己所需的接口封装类型(属于那种请求、需要什么格式的数据、如何返回等), 前端和后端都应该有一个对应的接口文档, 最好通过一个在线文档来实现。我的项目中使用了swagger3实现接口文档, 具体的后台数据请求方式已经在代码中标注, 这里补全了对应的接口描述和规范约束等。



### 2 手上有哪些 Offer

**看你进入公司的意愿是不是很强 - 接受offer的几率有多大**

不管你目前有多少个 Offer, 尽量说手中有 1-2 个offer, 这样才能突出你自己的竞争力, 不然 HR 会觉得你自身有问题, 然后阐述一下你对手上的offer不太喜欢, 吹一下他们公司就好。

子问题: 你对你手上offer不满意的点在哪里?

*公司比较小-平台比较低, 对以后的职业发展和技术长进有缺陷* - `贵公司的平台比较好, 以后的发展能够得到保证` - `技术氛围比较好`

**不要说** 加班多 压力大 996 出差多





## 其它

### 1 MyBatis plus 和 MyBatis 的区别

`简化的 CRUD 方法` `内置代码生成器` `分页插件` 

`条件构造器` 可以通过链式调用的方式来构建复杂的查询条件，包括等于、不等于、大于、小于、模糊查询等。这样可以在代码中更加直观地组装查询条件，避免手动拼接 SQL 语句。



### 2 分布式事务

分布式事务是指涉及多个独立系统或服务的事务操作。 在分布式系统上一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务节点上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。 eg: 用户下单, 订单表创建, 库存表库存--, 需要保证两步操作一定同时操作成功或失败，否则业务就会出现问题。

分布式事务有何需要满足 ACID 特性, 只是将多个执行单位看做一个整体, 在这个整体中实现该特性。

- **CAP** 

  WEB 服务无法同时满足一下3个属性, 一个分布式系统最多只能满足 CAP 中的2项

  - 一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效)。更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，不能存在中间状态。
  - 可用性(Availability) ： 每个操作都必须以可预期的响应结束。系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。
  - 分区容错性(Partition tolerance) ： 即使出现单个组件无法可用，操作依然可以完成。分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。

- 保证一致性

  `2PC`   *准备* *提交*   两阶段提交(准备阶段/提交-回滚阶段) - A 发起事务执行通知请求要参与的事务 - 是否准备好(取消/执行) 事务准备完毕后提交/回滚。

  `3PC`   *询问* *准备* *提交*    询问是否都准备好 准备所需的资源(超时则取消事务) 提交/回滚事务 

  `消息队列`  将事务操作转化为消息发送和消费的过程。(消息队列保证)

  `TCC`   *Try - Confirm - Cancel*   资源的预留和锁定 - 确认操作(提交成功与否) - 撤销操作(回滚) 

  `本地消息表`   存储各系统本地的事务, 根据执行情况选择执行方案



### 3 Linux 常用命令

```cmd
ls：列出目录中的文件和子目录。
cd：切换目录。
pwd：显示当前工作目录的路径。
mkdir：创建一个新目录。
rm：删除文件或目录。
cp：复制文件或目录。
mv：移动文件或目录，或者重命名文件或目录。
cat：显示文件内容。
grep：在文件中搜索指定的模式。
find：在文件系统中搜索文件。
ps：显示当前运行的进程。
kill：发送信号给进程以终止它。
chmod：修改文件或目录的权限。
chown：修改文件或目录的所有者。
tar：打包和解包文件。
ssh：通过安全的Shell连接到远程服务器。
sort [-r | -n] filename: 对文件内容进行排序; 逆序 - 数值顺序
top: 实时监视系统性能; 提供了一个交互式的界面, 监视包括CPU使用率、内存使用率、进程数量等
```



- **创建|编辑文件**

  创建与编辑命令相同

  `torch filename`  `vi filename` `nano filename` 

- **查看日志 | 文件**

  `tail -n <行数> <日志文件路径>`    tail命令查看日志文件的末尾几行      *grep ''*   过滤关键字

  ```java
  tail  -n  10   test.log   查询日志尾部最后10行的日志;
  tail  -n +10   test.log   查询10行之后的所有日志;
  tail  -fn 10   test.log   循环实时查看最后1000行记录(最常用的)
  tail -fn 1000 test.log | grep '关键字'
  ```

  `   less <日志文件路径>`  逐页查看日志文件, 箭头键向上或向下滚动，按q键退出

  `head -n <行数> <日志文件路径>`    看前多少行日志

  ```cmd
  head -n  10  test.log   查询日志文件中的头10行日志;
  head -n -10  test.log   查询日志文件除了最后10行的其他所有日志;
  ```

  `cat filename`   从第一行到最后一行连续显示在屏幕上

  `more `   基于`vi`编辑器文本过滤器，它以全屏幕的方式按页显示文本文件的内容，支持vi中的关键字定位操作。

  `less`   用less可以随意浏览文件，而more仅能向前移动，不能向后移动，而且 less 在查看之前不会加载整个文件。

  

  





### 4 Docker 如何实现不同容器之间的隔离

- `命名空间`

  调用Linux内核的方法，实现各种资源的隔离

  Docker 使用 Linux 命名空间来隔离不同的系统资源，例如进程、网络、文件系统等。每个容器都有自己的命名空间，使得容器中的进程只能看到自己的资源，无法感知其他容器的存在。

  *隔离文件系统、网络、进程通信、用户组*

- `Cgroups`

  Cgroups是Linux内核提供的资源限制和隔离的机制，全称：Control groups。调用 cgroups 的接口实现了**不同容器对物理资源的控制**, 如: CPU、内存、进程设备访问、网络等



### 5 Tomcat 如何实现不同项目的隔离

`每个项目都会打包成独立的war包, 运行使用独立的类加载器加载(独立的文件夹), 项目所需依赖放在各自的目录下 `   *不同类加载器* *不同依赖目录* *不同war包*

1. 使用独立的Web应用程序（WAR）：每个项目应该被打包为独立的WAR文件。每个WAR文件包含了项目所需的所有资源，包括依赖的JAR文件。将每个项目的WAR文件放置在Tomcat的`webapps`目录中。
2. 使用独立的类加载器：在Tomcat的`conf/Catalina/[host]`目录下，为每个项目创建一个单独的文件夹（例如，`conf/Catalina/localhost/app1`和`conf/Catalina/localhost/app2`）。在每个项目的文件夹中，创建一个`context.xml`文件，并在其中指定项目的独立类加载器。
3. 避免类库冲突：确保每个项目使用自己的依赖库，不与其他项目共享。将项目所需的JAR文件放置在各自项目的`WEB-INF/lib`目录下，而不是放置在Tomcat的共享库中。如果有共享的依赖库，可以将其放置在Tomcat的`lib`目录下，以供所有项目使用。



### 6 Git 常用命令

![image-20231011234506960](imgs/image-20231011234506960.png)



### 7 Python 常用的包

`numpy` `torch` `TensorFlow` `pandas` `matplotlib` `requests 请求` `threading 线程` `urllib 网络请求` `re 正则` `ffmpy - ffmpeg 视频;链接`

*疫情通自动打卡脚本* *自动登录QQ的脚本* *爬虫爬取网站视频* *爬虫爬取豆瓣影评* *爬虫爬取京东商品信息* *爬虫爬取网站图片等* *爬取喜马拉雅声音* *Redis数据到MySQL数据的迁移* 



### 8 MyBatis # 和 $ 的区别

**#**

- 可以防止SQL注入攻击。

- 在使用 `#` 符号时，将参数值作为 **预编译的参数** 传递给数据库驱动程序。 MyBatis在处理#{}时，会将SQL语句中的#{}替换为?，即占位符，然后使用PreparedStatement的set方法来赋值

- `#`符号可以防止恶意用户通过参数值插入恶意的SQL代码。

  ```java
  SELECT * FROM users WHERE id = #{userId}
  // 当执行这个查询时，MyBatis会将`#{userId}`替换为实际的参数值，并使用预编译的语句将参数值传递给数据库驱动程序。
  ```

**$**

- 不提供防止SQL注入攻击的保护。

- 在使用 `$` 符号时，MyBatis会将 **参数** 值直接替换到SQL语句中，不进行预编译处理。 MyBatis在处理${}时，会直接将SQL语句中的${}替换为参数的值。

- `$` 符号可以用于动态生成列名、表名等。   \#{} 会添加 '', 报错误

- 实现对查询结果的动态排序

  ```java
  SELECT * FROM ${tableName}
  // 当执行这个查询时，MyBatis会将`${tableName}`替换为实际的参数值，并直接将参数值插入到SQL语句中，没有进行预编译处理。
  ```



### 9 MyBatis 分页插件

实现原理如下：

1. 在 MyBatis 的配置文件中配置分页插件，并将其添加到 MyBatis 的插件链中。
2. 在执行 SQL 语句之前，分页插件会拦截要执行的 SQL 语句，并根据传入的参数计算分页参数，例如起始位置、每页大小等。
3. 通过分页参数，分页插件会构造出一条新的 SQL 语句，该语句可以在数据库中进行分页查询，例如 MySQL 中的 LIMIT 语句。
4. 执行构造出的 SQL 语句，获取分页后的结果。
5. 将分页后的结果返回给调用方。







## 前端知识

### 1 VUE

#### 1) 环境搭建与启动

- `安装 node.js`  node -v 检查版本 (可以切换镜像, 提高下载速度)
- `安装 vue-cli 脚手架`  与node版本有所关联  vue-version 检查版本
- `vue create project-name` 创建 vue 工程
- `选择相关配置  编译器、检查器、路由、代码检查等`
- `npm run serve`  运行vue工程   通过 npm run 检查可运行的项目 *注意: 这里需要切换到vue项目根目录才可运行, 否则找不到*

router  路由



#### 2) 跨域请求

- `不同域名之间的请求`： 从 example.com 的页面向 api.test.net 发起请求。

- `不同子域之间的请求`： 从 [www.example.com](http://www.example.com/) 的页面向 api.example.com 发起请求。

- `不同端口号之间的请求`： 从 example.com:3000 的页面向 example.com:8080 发起请求。

- `不同协议之间的请求`： 从 [https://example.com](https://example.com/) 的页面向 [http://example.com](http://example.com/) 

- axios | Proxy 代理(Vue 跨域请求处理)



#### 3) RESTful API

> REST（Representational State Transfer）是一种设计和构建网络应用程序的软件架构风格。它是一种基于 HTTP 协议的通信方式，通过使用统一的接口和资源标识符（URI）来进行通信。REST API（RESTful API）是基于 REST 架构风格设计的应用程序接口。它通过 HTTP 协议定义了一组操作，允许客户端通过发送 HTTP 请求与服务器进行交互，并进行资源的创建、读取、更新和删除（CRUD）操作。

以下是 REST API 的一些关键概念和特点：

1. 资源（Resources）：在 REST 中，每个数据实体都被视为一个资源，通过 URI 进行唯一标识。资源可以是任何事物，如用户、订单、文章等。
2. 统一的接口（Uniform Interface）：REST API 使用统一的接口来进行通信，包括使用 HTTP 方法（GET、POST、PUT、DELETE 等）对资源进行操作，以及使用 URI 标识资源。
3. 状态无关（Stateless）：服务器不会保存客户端的状态信息，每个请求都是独立的，并不依赖于之前的请求。客户端的每个请求都需要提供足够的信息来进行处理。
4. 资源的表征（Representation）：资源的表征指的是以某种格式（如 JSON、XML）表示资源的数据。客户端和服务器之间通过资源的表征进行交互和传输。
5. 按需加载（Cacheable）：REST API 支持缓存，服务器可以在响应中设置缓存头信息，使得客户端可以缓存响应结果，提高性能和减轻服务器负载。

REST API 在 Web 开发和移动应用程序开发中得到了广泛应用。它具有简洁、灵活、可扩展的特点，使得不同平台的应用程序可以通过使用统一的接口进行通信。开发人员可以使用各种编程语言和框架来构建 REST API，如 Node.js、Python、Java、Ruby 等，并使用工具和库来简化开发过程，如 Express、Django、Spring Boot 等。通过使用 REST API，应用程序可以实现前后端分离、微服务架构、跨平台通信等目标，提供灵活、可伸缩和可维护的解决方案。同时，REST API 的设计也需要考虑安全性、性能优化、版本控制等方面的问题，以确保应用程序的稳定性和可靠性。



### 2 JavaScript

> 概念: 一种高级、动态、弱类型的编程语言，常用于在网页中实现交互效果、处理数据、控制页面行为等。它是一种脚本语言，可以直接嵌入到 HTML 页面中，由浏览器解析和执行。 `解释语言`

#### 1) 概念 | 特点

**概念**

1. 弱类型语言：JavaScript 是一种弱类型语言，不需要显式声明变量的类型，可以在运行时自动进行类型转换。
2. 动态脚本语言：JavaScript 是一种脚本语言，可以直接嵌入到 HTML 页面中，在浏览器中解析和执行。
3. 客户端脚本语言：JavaScript 在浏览器中执行，用于实现网页的交互效果和动态行为。
4. 事件驱动：JavaScript 基于事件和回调机制，可以响应用户的交互操作，如点击按钮、提交表单等。
5. 原型继承：JavaScript 使用原型继承来实现对象之间的继承关系，通过原型链进行属性和方法的继承。

**特点**

1. 跨平台性：JavaScript 可以在几乎所有现代浏览器中运行，并且可以在服务器端使用 Node.js 运行，实现前后端一致性。
2. 动态性：JavaScript 允许在运行时修改和添加对象的属性和方法，以及动态生成 HTML 内容，实现页面的动态更新。
3. 客户端交互：JavaScript 可以处理用户的交互行为，如表单验证、按钮点击事件、页面元素的显示和隐藏等，实现交互性和动态效果。
4. 异步通信：JavaScript 支持使用 Ajax 技术进行与服务器的异步通信，实现无需刷新页面的数据交换和更新。
5. 大量的库和框架：JavaScript 生态系统非常丰富，有大量的开源库和框架可供选择，如 React、Vue.js、Angular 等，加速了开发过程并提供了更多的功能扩展。



#### 2) 数据类型

1. 基本数据类型（Primitive Types）：包括字符串（String）、数字（Number）、布尔值（Boolean）、空值（Null）和未定义（Undefined）。
2. 对象类型（Object Types）：包括对象（Object）、数组（Array）、函数（Function）和日期（Date）等。
3. 引用类型（Reference Types）：包括对象、数组和函数等，它们在内存中以引用的方式存储和访问。  `typeof `



#### 3) 闭包

闭包（Closure）是指在函数内部创建并返回一个内部函数，并且该内部函数可以访问其外部函数的变量和作用域。闭包可以捕获外部函数的变量，并且在外部函数执行完毕后仍然可以访问和操作这些变量。闭包常用于创建私有变量、实现函数柯里化、延迟函数执行等场景。



#### 4) 原型链 | 继承

原型链（Prototype Chain）是 JavaScript 中实现继承的机制。每个对象都有一个内部属性 [[Prototype]]，当访问对象的属性时，如果该对象本身没有该属性，那么会通过原型链向上查找，直到找到该属性或到达原型链的末尾（null）。

**继承方法**

- 原型链

  可以通过将子类的原型对象指向父类的实例来实现原型链继承

  ```javascript
  function Parent() {
    this.name = 'Parent';
  }
  
  function Child() {
    this.name = 'Child';
  }
  
  Child.prototype = new Parent();
  
  var child = new Child();
  console.log(child.name); // 输出 "Child"
  ```



#### 5) 冒泡

事件冒泡（Event Bubbling）是指当一个元素上的事件被触发时，事件会从该元素开始向祖先元素逐级传播，直到达到文档对象。事件冒泡的默认行为使得可以在祖先元素上捕获和处理事件。

事件捕获（Event Capturing）是指当一个元素上的事件被触发时，事件会从文档对象开始向下传播，直到达到触发事件的元素。事件捕获阶段可以用于在事件到达目标元素之前捕获事件并进行处理。要阻止事件冒泡，可以使用 `event.stopPropagation()` 方法。例如：

```javascript
element.addEventListener('click', function(event) {
  event.stopPropagation();
});
```



#### 6) 同步异步

同步（Synchronous）和异步（Asynchronous）是指代码执行的方式。

同步代码按照程序的顺序一步一步执行，每个代码块完成后再执行下一个代码块。

异步代码不会阻塞后续代码的执行，而是在某个事件触发或者条件满足时执行。JavaScript 中处理异步操作的常用方式包括回调函数、Promise 和 async/await 等。



#### 7) 异常处理

处理 JavaScript 中的异常和错误可以使用 try-catch-finally 语句块。try 代码块用于包裹可能发生错误的代码，catch 代码块用于捕获和处理异常，finally 代码块用于执行无论是否发生异常都需要执行的代码。例如：

```javascript
try {
  // 可能发生错误的代码
} catch (error) {
  // 处理异常的代码
} finally {
  // 无论是否发生异常都会执行的代码
}
```



#### 8) AJAX

AJAX（Asynchronous JavaScript and XML）是一种通过 JavaScript 在后台与服务器进行数据交换的技术。它允许在不刷新整个页面的情况下，通过异步方式加载和发送数据。要使用 JavaScript 发起 AJAX 请求，可以使用原生的 XMLHttpRequest 对象或者使用现代的 fetch API 或 axios 等第三方库。以下是使用原生 XMLHttpRequest 对象发起 AJAX 请求的示例：

```javascript
var xhr = new XMLHttpRequest();
xhr.open('GET', 'https://api.example.com/data', true);

xhr.onreadystatechange = function() {
  if (xhr.readyState === 4 && xhr.status === 200) {
    var response = JSON.parse(xhr.responseText);
    // 处理响应数据
  }
};
xhr.send();
```



#### 9) 跨域请求

处理 JavaScript 中的跨域请求可以通过

1. 设置服务器端的 CORS（跨域资源共享）头部信息来允许跨域请求
2. 使用代理服务器进行请求转发。
3. 使用 JSONP（JSON with Padding）技术来绕过跨域限制。**原理**是通过在页面中动态创建一个 `<script>` 标签，将请求的 URL 设置为目标数据的地址，并指定一个回调函数作为查询参数传递给服务器。服务器在返回数据时，将数据作为参数传递给回调函数，并在页面中执行该回调函数，以便在页面中获取数据。JSONP 只支持 GET 请求，并且需要服务器端进行特殊的处理，以便将数据包装在回调函数中返回给客户端。此外，JSONP 也存在一些安全性和可靠性的问题，因为它需要明文传递回调函数的名称，存在被恶意利用的风险。
4. `$.ajax` 请求是基于 jQuery 的 AJAX 方法。它是 jQuery 提供的一种简化的方式来发起 AJAX 请求，并提供了丰富的配置选项和回调函数。



### 3 Nodejs

> 概念: 可以快速构建网络服务及应用的平台，是用Javascript语言构建的服务平台，**可用于后端建立服务器**。Chrome JavaScript 运行时建立的平台，它是对 Google V8 引擎进行了封装的运行环境。  `运行在服务端的 JavaScript`

#### 1) 特点与应用

1. `异步非阻塞 I/O`：Node.js 采用事件驱动和非阻塞 I/O 模型，使得它能够高效处理大量并发请求。这使得 Node.js 特别适合构建实时应用、聊天应用、游戏服务器等需要处理大量并发连接的场景。
2. `单线程和事件循环`：Node.js 采用单线程模型，并通过事件循环机制实现异步操作。这使得开发人员能够编写高效且可扩展的代码，而不必担心传统多线程编程中的锁和线程同步问题。
3. `跨平台`：Node.js 可以在多个操作系统上运行，包括 Windows、macOS 和 Linux。这使得开发人员能够使用相同的代码在不同的平台上构建应用程序。
4. `快速构建原型`：Node.js 提供了一系列丰富的内置模块和第三方模块，使得开发人员可以快速构建原型和快速开发应用。同时，Node.js 生态系统非常活跃，有大量的第三方库和工具可供选择。
5. `前后端一致性`：由于 Node.js 使用 JavaScript 作为开发语言，前端开发人员可以直接在后端使用相同的语言和技术栈进行开发，这简化了全栈开发过程，并促进了前后端之间的协作。

**应用场景**

`撘服务器处理请求`  `后端开发` `包管理工具 npm` 

1. `服务器端应用程序`：Node.js 可以用于构建各种类型的服务器端应用程序，包括 Web 应用程序、RESTful API、实时通信应用程序等。
2. `前端构建工具`：Node.js 提供了许多工具和模块，如包管理器 npm，使得前端开发人员能够更好地管理和构建前端项目。
3. `命令行工具`：Node.js 提供了一些内置模块，使得开发人员可以编写命令行工具，用于自动化任务、脚本编写等。
4. `实时应用程序`：由于 Node.js 的事件驱动和非阻塞模型，它特别适合构建实时应用程序，如聊天应用、实时协作工具、游戏服务器等。
5. `微服务架构`：Node.js 的轻量级和高性能特性使其成为构建微服务架构的理想选择。它可以与其他服务进行通信，并处理并发请求。



#### 2) nodejs 和 java 区别

- **Node.js比Java更快**

  node.js 开发快，运行的效率也算比较高，但是如果项目大了就容易乱，而且javascript不是静态类型的语言，要到运行时才知道类型错误，所以写的多了之后免不了会出现光知道有错但是找不到哪儿错的情况，所以测试就得些的更好更详细。

  java开发慢，但是如果项目大、复杂的话，用java就不容易乱，管理起来比node.js省。

- Node.js 前后端都采用 Javascript，代表未来发展的趋势，而 java 则是现在的最流行的服务器端编程语言。

- Node.js 由 C/C++ 编写的基于 Chrome V8 引擎的 JavaScript `运行环境`; Java EE 是 `编译语言`

- Java 严格来说是一种与浏览器无关的服务器端语言，而 Node JS 可以在客户端和服务器端有效地使用。nodejs 前后端都用的是 `javascript`, 更方便。



